{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: confusion matrix, Precison, Recall, F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the field of machine learning and specifically the problem of *statistical classification*, a **confusion matrix, also known as an error matrix**, is a specific table layout that allows visualization of the performance of an algorithm, typically a supervised learning one (in unsupervised learning it is usually called a matching matrix): <img src=\"wikipedia-confusion.png\">\n",
    "\n",
    "Interpretations (taken from [there](https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62))\n",
    "\n",
    "**True Positive:**\n",
    "*Interpretation: You predicted positive and it’s true.*\n",
    "You predicted that a woman is pregnant and she actually is.\n",
    "\n",
    "**True Negative:**\n",
    "*Interpretation: You predicted negative and it’s true.*\n",
    "You predicted that a man is not pregnant and he actually is not.\n",
    "\n",
    "**False Positive: (Type 1 Error)**\n",
    "*Interpretation: You predicted positive and it’s false.*\n",
    "You predicted that a man is pregnant but he actually is not.\n",
    "\n",
    "**False Negative: (Type 2 Error)**\n",
    "*Interpretation: You predicted negative and it’s false.*\n",
    "You predicted that a woman is not pregnant but she actually is.\n",
    "\n",
    "**The F1 score** can be interpreted as a *weighted average of the precision and recall*, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal.\n",
    "\n",
    "Why is this so important?\n",
    "\n",
    "High scores for both(precicion and recall) show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).\n",
    "\n",
    "A system with high recall but low precision returns many results, but most of its predicted labels are incorrect when compared to the training labels. A system with high precision but low recall is just the opposite, returning very few results, but most of its predicted labels are correct when compared to the training labels. An ideal system with high precision and high recall will return many results, with all results labeled correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Moons dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dependencies\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report  \n",
    "from sklearn.metrics import confusion_matrix  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (1000, 2)\n",
      "Labels shape (1000,)\n"
     ]
    }
   ],
   "source": [
    "X, y = make_moons(n_samples = 1000, noise = 0.275)\n",
    "X = scale(X)\n",
    "print(\"X shape: \", X.shape)\n",
    "print(\"Labels shape\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1: Desriptive characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is descriptive statistics?** Descriptive statistics involves summarizing and organizing the data so they can be easily understood.\n",
    "For elementary theory and intuitive interpreation see [here](https://towardsdatascience.com/understanding-descriptive-statistics-c9c2b0641291)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X mean:  -1.9539925233402755e-16\n",
      "X median:  0.011443085578461798\n",
      "X and y mode:  [[-2.22832973 -2.72338303]] [0]\n"
     ]
    }
   ],
   "source": [
    "#mean\n",
    "print(\"X mean: \", X.mean())\n",
    "#median\n",
    "print(\"X median: \", np.median(X))\n",
    "#mode -- X has bimodal distribution\n",
    "print(\"X and y mode: \", stats.mode(X)[0], stats.mode(y)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of X 1.0\n",
      "Mean absolute deviation of X [1.08866909 1.17328649]\n",
      "Variance of X 1.0\n",
      "Q1 quantile of X :  -0.7548718755258662\n",
      "Q2 quantile of X :  0.011443085578461798\n",
      "Q3 quantile of X :  0.7580688035501697\n",
      "100th quantile of X :  -1.3863686145592549\n",
      "IQR of X: 1.5129406790760358\n",
      "Pearson First Coefficient of Skewness of X: \n",
      " [[[ 2.22832973  2.72338303]]\n",
      "\n",
      " [[-1.         -1.        ]]]\n",
      "Pearson Second Coefficient of Skewness of X:  -0.034329256735385984\n"
     ]
    }
   ],
   "source": [
    "#let's look at Measure of Spread / Dispersion -- variability of given data\n",
    "# 1) standard deviation:\n",
    "print(\"Standard deviation of X\", np.std(X))\n",
    "# 2) mean absolute deviation:\n",
    "print(\"Mean absolute deviation of X\", stats.median_absolute_deviation(X))\n",
    "# 3) variance:\n",
    "print(\"Variance of X\", (np.std(X)) ** 2)\n",
    "# 4) quartiles:\n",
    "print(\"Q1 quantile of X : \", np.quantile(X, .25)) \n",
    "print(\"Q2 quantile of X : \", np.quantile(X, .50)) \n",
    "print(\"Q3 quantile of X : \", np.quantile(X, .75)) \n",
    "print(\"100th quantile of X : \", np.quantile(X, .1)) \n",
    "# 5) interquantile range(IQR = Q3 - Q1) :\n",
    "print(\"IQR of X:\",  np.quantile(X, .75) - np.quantile(X, .25))\n",
    "# 6) skewness:\n",
    "#  6.1) mode:\n",
    "print(\"Pearson First Coefficient of Skewness of X: \\n\", (np.mean(X) - stats.mode(X, axis = 0 ))/np.std(X))\n",
    "#  6.2) median:\n",
    "print(\"Pearson Second Coefficient of Skewness of X: \", 3 * (np.mean(X) - np.median(X))/np.std(X))\n",
    "# 7) features correlation:\n",
    "#print(\"Correlation between features of X: \\n\", np.corrcoef(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2: Classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  750\n",
      "Test size:  250\n"
     ]
    }
   ],
   "source": [
    "#having read the task, i unserstood that we need only test and train sets -- no validation and dev sets!\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)\n",
    "print(\"Train size: \", len(y_train))\n",
    "print(\"Test size: \", len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#running base classificators\n",
    "log_reg_model = LogisticRegression()\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "decision_tree_model = DecisionTreeClassifier()\n",
    "decision_tree_model.fit(X_train, y_train)\n",
    "\n",
    "random_forest_model = RandomForestClassifier()\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "native_bayes_model = BernoulliNB()\n",
    "native_bayes_model.fit(X_train, y_train)\n",
    "\n",
    "svc_model = SVC(kernel = 'rbf')\n",
    "svc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log. Regression: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       115\n",
      "           1       0.85      0.86      0.86       135\n",
      "\n",
      "    accuracy                           0.84       250\n",
      "   macro avg       0.84      0.84      0.84       250\n",
      "weighted avg       0.84      0.84      0.84       250\n",
      "\n",
      "KNN: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       115\n",
      "           1       0.90      0.94      0.92       135\n",
      "\n",
      "    accuracy                           0.91       250\n",
      "   macro avg       0.91      0.91      0.91       250\n",
      "weighted avg       0.91      0.91      0.91       250\n",
      "\n",
      "Decision Tree: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89       115\n",
      "           1       0.89      0.93      0.91       135\n",
      "\n",
      "    accuracy                           0.90       250\n",
      "   macro avg       0.90      0.90      0.90       250\n",
      "weighted avg       0.90      0.90      0.90       250\n",
      "\n",
      "Random Forest: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       115\n",
      "           1       0.97      0.92      0.94       135\n",
      "\n",
      "    accuracy                           0.94       250\n",
      "   macro avg       0.94      0.94      0.94       250\n",
      "weighted avg       0.94      0.94      0.94       250\n",
      "\n",
      "Naive Bayes: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77       115\n",
      "           1       0.80      0.81      0.80       135\n",
      "\n",
      "    accuracy                           0.79       250\n",
      "   macro avg       0.79      0.79      0.79       250\n",
      "weighted avg       0.79      0.79      0.79       250\n",
      "\n",
      "SVC: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92       115\n",
      "           1       0.93      0.93      0.93       135\n",
      "\n",
      "    accuracy                           0.92       250\n",
      "   macro avg       0.92      0.92      0.92       250\n",
      "weighted avg       0.92      0.92      0.92       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#making predictions\n",
    "y_log_reg = log_reg_model.predict(X_test)\n",
    "y_knn = knn_model.predict(X_test)\n",
    "y_decision_tree = decision_tree_model.predict(X_test)\n",
    "y_random_forest = random_forest_model.predict(X_test)\n",
    "y_native_bayes = native_bayes_model.predict(X_test)\n",
    "y_svc = svc_model.predict(X_test)\n",
    "\n",
    "print(\"Log. Regression: \\n\", classification_report(y_true = y_test, y_pred = y_log_reg))\n",
    "print(\"KNN: \\n\", classification_report(y_true = y_test, y_pred = y_knn))\n",
    "print(\"Decision Tree: \\n\", classification_report(y_true = y_test, y_pred = y_decision_tree))\n",
    "print(\"Random Forest: \\n\", classification_report(y_true = y_test, y_pred = y_random_forest))\n",
    "print(\"Naive Bayes: \\n\", classification_report(y_true = y_test, y_pred = y_native_bayes))\n",
    "print(\"SVC: \\n\", classification_report(y_true = y_test, y_pred = y_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model refinements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 294 candidates, totalling 882 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 882 out of 882 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=7,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=42, splitter='best')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking for the best estimator for Decision tree classifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}\n",
    "grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state = 42), params, verbose = 1)\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unneccesary tree visualization:\n",
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(grid_search_cv.best_estimator_, \n",
    "                out_file = (\"moons_tree.dot\"),\n",
    "                feature_names = None, \n",
    "                class_names = None,\n",
    "                filled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20000 candidates, totalling 60000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.02, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=0.01, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 60000 out of 60000 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "#TODO:\n",
    "params = {'l1_ratio': list(np.linspace(0.01, 1, 100)),\n",
    "          'C' : list(np.linspace(0.01, 1, 100)), 'penalty': ['l1', 'l2']}\n",
    "grid_search_cv = GridSearchCV(LogisticRegression(), params, verbose = 1, cv = 3)\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "best_linear_reg = grid_search_cv.best_estimator_  \n",
    "print(best_linear_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log. Regression with L2: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       115\n",
      "           1       0.85      0.86      0.86       135\n",
      "\n",
      "    accuracy                           0.84       250\n",
      "   macro avg       0.84      0.84      0.84       250\n",
      "weighted avg       0.84      0.84      0.84       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_linear_reg.predict(X_test)\n",
    "print(\"Log. Regression with L2: \\n\", classification_report(y_true = y_test, y_pred = y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
