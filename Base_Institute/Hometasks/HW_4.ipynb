{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHfyz7liCDbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recall_(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def f1_score (y_true, y_pred):\n",
        "    precision = precision_(y_true, y_pred)\n",
        "    recall = recall_(y_true, y_pred)\n",
        "    return 2 * ((precision * recall)/(precision + recall + K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivEn2-wthwBF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "42f55057-af2a-4477-df6d-fc9d68c9477a"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import keras.backend as K\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.datasets import imdb\n",
        "\n",
        "max_features = 20000\n",
        "# cut texts after this number of words (among top max_features most common words)\n",
        "maxlen = 80\n",
        "batch_size = 32\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen = maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen = maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 512, mask_zero = True))\n",
        "model.add(LSTM(512, dropout = 0.1, recurrent_dropout = 0.1, return_sequences = True))\n",
        "model.add(LSTM(256, dropout = 0.1, recurrent_dropout = 0.1, return_sequences = False))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss = 'binary_crossentropy',\n",
        "              optimizer = 'adam',\n",
        "              metrics = [recall_, precision_, f1_score])\n",
        "\n",
        "print('Train...')\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size = batch_size,\n",
        "          epochs = 6,\n",
        "          validation_data = (x_test, y_test))\n",
        "score, prec, recall, f1 = model.evaluate(x_test, y_test,\n",
        "                            batch_size = batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test (precision, recall, f1-score):', prec, recall, f1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "25000 train sequences\n",
            "25000 test sequences\n",
            "Pad sequences (samples x time)\n",
            "x_train shape: (25000, 80)\n",
            "x_test shape: (25000, 80)\n",
            "Build model...\n",
            "Train...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/6\n",
            "25000/25000 [==============================] - 609s 24ms/step - loss: 0.5562 - recall_: 0.7173 - precision_: 0.7242 - f1_score: 0.6906 - val_loss: 0.4908 - val_recall_: 0.6984 - val_precision_: 0.8442 - val_f1_score: 0.7584\n",
            "Epoch 2/6\n",
            "25000/25000 [==============================] - 600s 24ms/step - loss: 0.3692 - recall_: 0.8293 - precision_: 0.8559 - f1_score: 0.8316 - val_loss: 0.3782 - val_recall_: 0.8434 - val_precision_: 0.8270 - val_f1_score: 0.8305\n",
            "Epoch 3/6\n",
            "25000/25000 [==============================] - 606s 24ms/step - loss: 0.2528 - recall_: 0.9007 - precision_: 0.8980 - f1_score: 0.8954 - val_loss: 0.3996 - val_recall_: 0.7778 - val_precision_: 0.8647 - val_f1_score: 0.8138\n",
            "Epoch 4/6\n",
            "25000/25000 [==============================] - 597s 24ms/step - loss: 0.1754 - recall_: 0.9337 - precision_: 0.9370 - f1_score: 0.9327 - val_loss: 0.5138 - val_recall_: 0.8077 - val_precision_: 0.8481 - val_f1_score: 0.8222\n",
            "Epoch 5/6\n",
            "25000/25000 [==============================] - 606s 24ms/step - loss: 0.1132 - recall_: 0.9605 - precision_: 0.9593 - f1_score: 0.9583 - val_loss: 0.5045 - val_recall_: 0.8255 - val_precision_: 0.8284 - val_f1_score: 0.8220\n",
            "Epoch 6/6\n",
            "25000/25000 [==============================] - 597s 24ms/step - loss: 0.0665 - recall_: 0.9781 - precision_: 0.9782 - f1_score: 0.9773 - val_loss: 0.6361 - val_recall_: 0.8687 - val_precision_: 0.7922 - val_f1_score: 0.8239\n",
            "25000/25000 [==============================] - 66s 3ms/step\n",
            "Test score: 0.6360893849086762\n",
            "Test (precision, recall, f1-score): 0.8686743378639221 0.7921833992004395 0.8239357471466064\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Es3bKNoYCEMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}