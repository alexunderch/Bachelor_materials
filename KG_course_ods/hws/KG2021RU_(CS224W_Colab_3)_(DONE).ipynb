{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "KG2021RU_(CS224W_Colab_3) (DONE).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexunderch/Bachelor_materials/blob/main/KG_course_ods/hws/KG2021RU_(CS224W_Colab_3)_(DONE).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXWJLEm2UWS"
      },
      "source": [
        "![](https://habrastorage.org/webt/wm/bs/md/wmbsmdxsduiamoki0tpt8vgfvvq.png)\n",
        "\n",
        "# Заимствовано с гордостью!\n",
        "перевод публично доступных [материалов](https://colab.research.google.com/drive/1AjLbfuz9qXE5yglPOifUKhOHkzAuHmOF?usp=sharing#scrollTo=8gzsP50bF6Gb) курса [cs224w](http://web.stanford.edu/class/cs224w/)\n",
        "\n",
        "# **CS224W - Colab 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gzsP50bF6Gb"
      },
      "source": [
        "В предыдущем блокнотике мы сконструировали графовую нейронную сеть с помощью встроенного в PyTorch Geometric слоя GCN - `GCNConv`. В этом блокнотике мы реализуем архитектуры **GraphSAGE** ([Hamilton et al. (2017)](https://arxiv.org/abs/1706.02216)) и **GAT** ([Veličković et al. (2018)](https://arxiv.org/abs/1710.10903)). Затем скормим нашим сетям набор данных CORA, стандартный тест для сетей цитирования.\n",
        "\n",
        "Затем воспользуемся [DeepSNAP](https://snap.stanford.edu/deepsnap/), библиотекой Python, помогающей эффективно обучать глубокие модели на графах в разнообразных условиях и применять трансформации к данным.\n",
        "\n",
        "Наконец, с помощью функционала DeepSNAP для трансдуктивного разбиения рёбер, сконструируем простую графовую нейронную сеть для предсказания свойств рёбер(задача предсказания связей или link prediction).\n",
        "\n",
        "**Обратите внимание**:  \n",
        "Убедитесь в том, чтобы **последовательно запускать все ячейки с кодом в рамках каждой секции**, таким образом промежуточные переменные будут переданы в последующую ячейку.\n",
        "\n",
        "Развлекайтесь с Colab 3 :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSaetj53YnT6"
      },
      "source": [
        "# Устройство\n",
        "Вам может потребоваться графический ускоритель для этого блокнота.\n",
        "\n",
        "Пожалуйста выберите `Среда выполенения (Runtime)` и затем `Сменить среду выполенения (Change runtime type)`. Выберите **GPU** для `Аппаратный ускоритель (hardware accelerator)`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67gOQITlCNQi"
      },
      "source": [
        "# Установка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_m9l6OYCQZP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3627e2cd-7a38-4793-8e3f-61456af65fe8"
      },
      "source": [
        "# !pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
        "# !pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
        "# !pip install -q torch-geometric\n",
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.11.0+cu113.html\n",
        "!pip install -q git+https://github.com/snap-stanford/deepsnap.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-1.11.0+cu113.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 12.4 MB/s \n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_sparse-0.6.13-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 43.7 MB/s \n",
            "\u001b[?25hCollecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 35.3 MB/s \n",
            "\u001b[?25hCollecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (750 kB)\n",
            "\u001b[K     |████████████████████████████████| 750 kB 40.6 MB/s \n",
            "\u001b[?25hCollecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.4.tar.gz (407 kB)\n",
            "\u001b[K     |████████████████████████████████| 407 kB 12.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.8)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.4-py3-none-any.whl size=616603 sha256=bfc1e92cbb4d45e4d9f7cbf2490f6d1aac74a27ecd647d81d04483c14f31b45c\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/a6/a4/ca18c3051fcead866fe7b85700ee2240d883562a1bc70ce421\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-spline-conv, torch-sparse, torch-scatter, torch-geometric, torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0 torch-geometric-2.0.4 torch-scatter-2.0.9 torch-sparse-0.6.13 torch-spline-conv-1.2.1\n",
            "  Building wheel for deepsnap (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRfgbfTjCRD_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0f17733c-91a7-4463-ac6d-60910ec66b8c"
      },
      "source": [
        "import torch_geometric\n",
        "torch_geometric.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoXlf4MtYrbz"
      },
      "source": [
        "# 1 Слои GNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQy2RBfgYut4"
      },
      "source": [
        "## Реализация модулей слоёв\n",
        "\n",
        "В colab 2 мы реализовали сеть, использовав GCN для задач классификации вершин и графов. Однако, сам модуль GCN - часть официальной библиотеки. Для данной задачи мы предоставим вам конструкцию общего назначения - Graph Neural Network Stack, в которую можно подключить ваши собственные модули GraphSAGE и GAT. Мы применим нашу реализацию к классификации вершин на стандартном наборе данных цитирования CORA. В этом наборе данных вершины соответствуют документам и рёбра отражают неориентированные цитаты. Каждой вершине назначена метка класса. Свойства вершины - представление содержимого в виде мешка слов (bag-or-words). В наборе данных CORA 2708 вершин, 5429 рёбер, 7 классов для вершин и 1433 признака на вершину."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4ne6Gw-CT5G"
      },
      "source": [
        "## GNN Stack Module\n",
        "\n",
        "Ниже представлена реализация обобщённого модуля графовой нейронной сети, в который можно подключать любые слои, включая **GraphSage**, **GAT**, и пр. Данный модуль предоставлен для вашего удобства и ваша реализация слоёв **GraphSage** и **GAT** будет работать как подключаемые компоненты в GNNStack Module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys8vZAFPCWWe"
      },
      "source": [
        "import torch\n",
        "import torch_scatter\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "import torch_geometric.utils as pyg_utils\n",
        "\n",
        "from torch import Tensor\n",
        "from typing import Union, Tuple, Optional\n",
        "from torch_geometric.typing import (OptPairTensor, Adj, Size, NoneType,\n",
        "                                    OptTensor)\n",
        "\n",
        "from torch.nn import Parameter, Linear\n",
        "from torch_sparse import SparseTensor, set_diag\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
        "\n",
        "class GNNStack(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, args, emb=False):\n",
        "        super(GNNStack, self).__init__()\n",
        "        conv_model = self.build_conv_model(args.model_type)\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.convs.append(conv_model(input_dim, hidden_dim))\n",
        "        assert (args.num_layers >= 1), 'Number of layers is not >=1'\n",
        "        for l in range(args.num_layers-1):\n",
        "            self.convs.append(conv_model(args.heads * hidden_dim, hidden_dim))\n",
        "\n",
        "        # post-message-passing\n",
        "        self.post_mp = nn.Sequential(\n",
        "            nn.Linear(args.heads * hidden_dim, hidden_dim), nn.Dropout(args.dropout), \n",
        "            nn.Linear(hidden_dim, output_dim))\n",
        "\n",
        "        self.dropout = args.dropout\n",
        "        self.num_layers = args.num_layers\n",
        "\n",
        "        self.emb = emb\n",
        "\n",
        "    def build_conv_model(self, model_type):\n",
        "        if model_type == 'GraphSage': return GraphSage\n",
        "        elif model_type == 'GAT':\n",
        "            # When applying GAT with num heads > 1, one needs to modify the \n",
        "            # input and output dimension of the conv layers (self.convs),\n",
        "            # to ensure that the input dim of the next layer is num heads\n",
        "            # multiplied by the output dim of the previous layer.\n",
        "            # HINT: In case you want to play with multiheads, you need to change the for-loop when builds up self.convs to be\n",
        "            # self.convs.append(conv_model(hidden_dim * num_heads, hidden_dim)), \n",
        "            # and also the first nn.Linear(hidden_dim * num_heads, hidden_dim) in post-message-passing.\n",
        "            return GAT\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "          \n",
        "        for i in range(self.num_layers):\n",
        "            x = self.convs[i](x, edge_index)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout)\n",
        "\n",
        "        x = self.post_mp(x)\n",
        "\n",
        "        if self.emb == True:\n",
        "            return x\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    def loss(self, pred, label): return F.nll_loss(pred, label)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syDtxjxoCZgq"
      },
      "source": [
        "## GraphSage - реализация\n",
        "\n",
        "Приступим к реализации слоёв! В данной части вы ознакомитесь с тем, как реализовать слой в PyTorch, основанный на передаче сообщений (Message Passing). Вы реализуете функции **forward**, **message** и **aggregate**.\n",
        "\n",
        "В общем, функция **forward** - выполняет непосредственно передачу сообщений. Вся логика на каждой итерации происходит в **forward**, в которой вызывается функция **propagate** для передачи информации от соседей центральной вершине. Общая парадигма: pre-processing -> propagate -> post-processing.\n",
        "\n",
        "Вспомните процесс передачи сообщений, рассмотренный в homework 1 (возможно, когда-то будет доступна широкой публике). Затем **propagate** вызывает функции **message**, которая трансформирует информацию от соседей в сообщения, **aggregate**, которая аггрегирует все сообщения от соседних вершин в одну, и  **update**, которая создаёт эмбеддинги вершин в следующей итерации.\n",
        "\n",
        "Наша реализация несколько отличается от описанной и мы не будем явно реализовывать **update**, но вынесем логику обновления вершин в функцию **forward**. Более конкретно, после того, как информация передана, мы можем произвести некоторые операции на выходе из **propagate**. Выход **forward** - это эмбеддинги после текущей итерации.\n",
        "\n",
        "Кроме того, тензоры, отправленные в **propagate()** можно сопоставить с вершинами $i$ и $j$, добавляя _i или _j к имени переменной, например, x_i и x_j. Обратите внимание, мы в общем случае обозначаем $i$ как центральные вершины, аггрегирующие информацию и $j$ - соседние вершины, следуя наиболее распространённой нотации.\n",
        "\n",
        "Пожалуйста, обратитесь к комментариям для более подробных инструкций. Также стоит упомянуть, что мы добавим **skip connections** нашей GraphSage. Фомально, правило обновления примет следующий вид:\n",
        "\n",
        "\\begin{equation}\n",
        "h_v^{(l)} = W_l\\cdot h_v^{(l-1)} + W_r \\cdot AGG(\\{h_u^{(l-1)}, \\forall u \\in N(v) \\})\n",
        "\\end{equation}\n",
        "\n",
        "Для простоты мы используем аггрегацию усреднением (mean aggregations), где:\n",
        "\n",
        "\\begin{equation}\n",
        "AGG(\\{h_u^{(l-1)}, \\forall u \\in N(v) \\}) = \\frac{1}{|N(v)|} \\sum_{u\\in N(v)} h_u^{(l-1)}\n",
        "\\end{equation}\n",
        "\n",
        "Кроме того, после каждой итерации мы применим $\\ell$-2 нормализацию.\n",
        "\n",
        "Для того, чтобы выполнить задание корректно, нам следует понимать как взаимодействуют между собой различные функции. В **propagate** мы можем отправить какие угодно параметры. Например, подадим на вход $x$:\n",
        "\n",
        "... = propagate(..., $x$=($x_{central}$, $x_{neighbor}$), ...)\n",
        "\n",
        "Здесь $x_{central}$ и $x_{neighbor}$ представляют собой свойства **цнтральных** вершин и **соседних** (или инцидентных им) вершин. Если мы будем использовать одинаковое представление от центральных и соседних вершин, тогда $x_{central}$ и $x_{neighbor}$ могут быть идентичны.\n",
        "\n",
        "Предположим, $x_{central}$ и $x_{neighbor}$ одной размерности N * d, где N - количество вершин, а d - размерность вектора свойств вершины.\n",
        "\n",
        "Тогда в функцию сообщений (message function) мы сможем принять параметры $x\\_i$ и $x\\_j$. Обыкновенно $x\\_i$ обозначает \"центральные вершины\", а $x\\_j$ - \"соседние вершины\". Обратите внимание на размерность: $x\\_i$ и $x\\_j$ - одинаковой размерности E * d (**не N!**). $x\\_i$ получается конкатенацией эмбеддингов центральных вершин для всех рёбер через таблицу соответствия (lookup) из $x_{central}$ мы отправили в propagate. Подобным образом, $x\\_j$ получается конкатенацией эмбеддингов соседних вершин всех рёбер сопоставлением из таблицы соответствия (lookup) $x_{neighbor}$, отправленных в propagate.\n",
        "\n",
        "Рассмотрим пример. Пусть у нас 4 вершины, таким образом $x_{central}$ и $x_{neighbor}$ иеют размерность 4 * d. У нас два ребра (1, 2) и (3, 0). Таким образом, $x\\_i$ получается как $[x_{central}[1]^T; x_{central}[3]^T]^T$, и $x\\_j$ получается как $[x_{neighbor}[2]^T; x_{neighbor}[0]^T]^T$\n",
        "\n",
        "<font color='red'>Для последующих вопросов НЕ используйте никакие из публично доступных вариантов реализации.</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwG4HqCFCaOD"
      },
      "source": [
        "class GraphSage(MessagePassing):\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, normalize = True,\n",
        "                 bias = False, **kwargs):  \n",
        "        super(GraphSage, self).__init__(**kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.normalize = normalize\n",
        "\n",
        "        self.lin_l = None\n",
        "        self.lin_r = None\n",
        "\n",
        "        ############################################################################\n",
        "        # ЗАДАЧА: Ваш код здесь!\n",
        "        # Реализйте слои, необходимые для функций message и update. \n",
        "        # self.lin_l - это линейная трансформация, которую вы примените к эмбеддингам\n",
        "        #              для центральной вершины.\n",
        "        # self.lin_r - это линейная трансформация, которую вы примените к аггрегированным\n",
        "        #              сообщениям от соседей.\n",
        "        # Наша реализация ~2 строки кода, но не волнуйтесь, если ваша будет отличаться.\n",
        "        self.lin_l = torch.nn.Linear(in_channels, out_channels, bias = bias)\n",
        "        self.lin_r = torch.nn.Linear(in_channels, out_channels, bias = bias) #one dimension\n",
        "        ############################################################################\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.lin_l.reset_parameters()\n",
        "        self.lin_r.reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index, size = None):\n",
        "        \"\"\"\"\"\"\n",
        "\n",
        "        out = None\n",
        "\n",
        "        ############################################################################\n",
        "        # ЗАДАЧА: Ваш код здесь!\n",
        "        # Реализуйте прохождение сообщений (message passing) и пост-процессинг (update).\n",
        "        # 1. Сначала вызовите функцию propagate для передачи сообщений.\n",
        "        #    1.1 Здесь вы найдёте более подробную информацию: \n",
        "        #        https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html\n",
        "        #    1.2 Мы используем одинаковые представления для центральных (x_central) и \n",
        "        #        соседних (x_neighbor) вершин, это означает, что вы передадите x=(x, x) \n",
        "        #        в функцию propagate.\n",
        "        # 2. Обновите эмбеддинги вершин вместе с skip connection.\n",
        "        # 3. Если установлен параметр normalize, проведите L-2 нормализацию (определена в \n",
        "        #    torch.nn.functional)\n",
        "        # Наша реализация ~5 строк кода, но не волнуйтесь, если ваша будет отличаться.\n",
        "\n",
        "        out_message = self.propagate(edge_index, x = (x, x), size = size)\n",
        "        out = self.lin_l(x) + self.lin_r(out_message)\n",
        "        if self.normalize: out = F.normalize(out, p=2., dim=-1)\n",
        "        \n",
        "        ############################################################################\n",
        "\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j):\n",
        "\n",
        "        out = None\n",
        "\n",
        "        ############################################################################\n",
        "        # ЗАДАЧА: Ваш код здесь!\n",
        "        # Реализуйте вашу функцию message здесь.\n",
        "        # Наша реализация ~1 строка кода, но не волнуйтесь, если ваша будет отличаться.\n",
        "        out = x_j\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        return out\n",
        "\n",
        "    def aggregate(self, inputs, index, dim_size = None):\n",
        "\n",
        "        out = None\n",
        "\n",
        "        # Ось, по которой индексировать вершины / The axis along which to index number of nodes.\n",
        "        node_dim = self.node_dim\n",
        "\n",
        "        ############################################################################\n",
        "        # ЗАДАЧА: Ваш код здесь! \n",
        "        # Реализуйте вашу функцию aggregate.\n",
        "        # Подробнее о использовании torch_scatter.scatter: \n",
        "        # https://pytorch-scatter.readthedocs.io/en/latest/functions/scatter.html#torch_scatter.scatter\n",
        "        # Наша реализация ~1 строка кода, но не волнуйтесь, если ваша будет отличаться.\n",
        "        out = torch_scatter.scatter(src = inputs, index = index, \n",
        "                                    dim = node_dim, dim_size = dim_size,\n",
        "                                    reduce = 'mean')\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        return out\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjcfF3RACdLD"
      },
      "source": [
        "## GAT - реализация\n",
        "\n",
        "Механизмы внимания (attention) демонстрируют наилучшие (state-of-the-art) результаты во многих задачах, основанных на последовательностях, таких как машинный перевод или векторные представления предложений. Одно из основных преимуществ механизмов внимания - их способность сконцентрироваться на наиболее релевантных частях входной информации для принятия решения. В данной задаче мы посмотрим как использовать механизм внимания для классификации вершин графа с использованием графовых нейронных сетей с вниманием (Graph Attention Networks (GATs)).\n",
        "\n",
        "Строительный блок графовой нейронной сети с вниманием - это слой графового внимания, который представляет собой вариант функции аггрегации. Пусть $N$ - количество вершин и $F$ - размерность вектора признаков для каждой вершины. Входом каждого слоя графового внимания является множество свойств вершин: $\\mathbf{h} = \\{\\overrightarrow{h_1}, \\overrightarrow{h_2}, \\dots, \\overrightarrow{h_N}$\\}, $\\overrightarrow{h_i} \\in R^F$. Выходом каждого слоя графового внимания является новый набор свойств вершин, который может иметь новую размерность $F'$: $\\mathbf{h'} = \\{\\overrightarrow{h_1'}, \\overrightarrow{h_2'}, \\dots, \\overrightarrow{h_N'}\\}$, with $\\overrightarrow{h_i'} \\in \\mathbb{R}^{F'}$.\n",
        "\n",
        "Теперь мы опишем эту трансформацию входных признаков в признаки более высокого уровня, производимые каждым слоем графового внимания. Сначала происходит общее для всех вершин линейное преобразование, параметризованное матрицей весов $\\mathbf{W} \\in \\mathbb{R}^{F' \\times F}$. Далее, запускается самосознание (self-attention) для вершин. Мы используем один на всех механизм внимания:\n",
        "\\begin{equation} \n",
        "a : \\mathbb{R}^{F'} \\times \\mathbb{R}^{F'} \\rightarrow \\mathbb{R}.\n",
        "\\end{equation}\n",
        "\n",
        "Этот механизм вычисляет коэффициенты внимания, которые отражают важность признаков вершины $j$ для вершины $i$:\n",
        "\\begin{equation}\n",
        "e_{ij} = a(\\mathbf{W_l}\\overrightarrow{h_i}, \\mathbf{W_r} \\overrightarrow{h_j})\n",
        "\\end{equation}\n",
        "Наиболее общая формулировка влияния позволяет каждой вершине влиять на все прочие, что исключает всю информацию о структурных связях. Для того, чтобы воспользоваться структурой графа в механизмах внимания, мы можем воспользоваться вниманием с маской (masked attention). Во вниманиии с маской мы вычисляем лишь $e_{ij}$ для вершин $j \\in \\mathcal{N}_i$, где $\\mathcal{N}_i$  является каким-то окружением вершины $i$ в графе.\n",
        "\n",
        "Для простоты сравнения коэффициентов между различными вершинами мы нормализуем коэффициенты между $j$ using с помощью функции softmax:\n",
        "\\begin{equation}\n",
        "\\alpha_{ij} = \\text{softmax}_j(e_{ij}) = \\frac{\\exp(e_{ij})}{\\sum_{k \\in \\mathcal{N}_i} \\exp(e_{ik})}\n",
        "\\end{equation}\n",
        "\n",
        "Для этой задачи наш механизм внимания  $a$ будет однослойный перцептрон, параметризуемый вектором весов $\\overrightarrow{a} \\in \\mathbb{R}^{F'}$,с нелинейной функцией активации вида LeakyReLU (с наклоном 0.2 для отрицательных входных значений). Пусть $\\cdot^T$ обозначает операцию транспонирования и $||$ обозначает конкатенацию. Коэффициенты, вычисляемые нашим механизмом внимания, могут быть записаны как:\n",
        "\n",
        "\\begin{equation}\n",
        "\\alpha_{ij} = \\frac{\\exp\\Big(\\text{LeakyReLU}\\Big(\\overrightarrow{a_l}^T \\mathbf{W_l} \\overrightarrow{h_i} + \\overrightarrow{a_r}^T\\mathbf{W_r}\\overrightarrow{h_j}\\Big)\\Big)}{\\sum_{k\\in \\mathcal{N}_i} \\exp\\Big(\\text{LeakyReLU}\\Big(\\overrightarrow{a_l}^T \\mathbf{W_l} \\overrightarrow{h_i} + \\overrightarrow{a_r}^T\\mathbf{W_r}\\overrightarrow{h_k}\\Big)\\Big)}\n",
        "\\end{equation}\n",
        "\n",
        "Для последующих вопросов, обозначим $\\alpha_l = [...,\\overrightarrow{a_l}^T \\mathbf{W_l} \\overrightarrow{h_i},...]$ и $\\alpha_r = [..., \\overrightarrow{a_r}^T \\mathbf{W_r} \\overrightarrow{h_j}, ...]$.\n",
        "\n",
        "В каждом слое GAT, после вычисления коэффициентов внимания для этого слоя, функция аггрегации может быть вычислена как взвешенная сумма сообщений от соседей, где веса задаются $\\alpha_{ij}$.\n",
        "\n",
        "Теперь мы воспользуемся нормализованными коэффициентами внимания для вычисления линейной комбинации признаков, соответствующих им. Эти аггрегированные признаки будут служить в качестве выходных признаков для каждой вершины.\n",
        "\n",
        "\\begin{equation}\n",
        "h_i' = \\sum_{j \\in \\mathcal{N}_i} \\alpha_{ij} \\mathbf{W_r} \\overrightarrow{h_j}.\n",
        "\\end{equation}\n",
        "\n",
        "Для стабилизации процесса обучения самовнимания (self-attention), мы воспользуемся вниманием с несколькими головами (multi-head attention). Для этого мы используем $K$ независимых механизмов внимания или ``голов'' (heads), производящих выходные признаки, как в показано в уравнениях выше. Затем мы конкатенируем эти выходные представления:\n",
        "\n",
        "\\begin{equation}\n",
        "    \\overrightarrow{h_i}' = ||_{k=1}^K \\Big(\\sum_{j \\in \\mathcal{N}_i} \\alpha_{ij}^{(k)} \\mathbf{W_r}^{(k)} \\overrightarrow{h_j}\\Big)\n",
        "\\end{equation}\n",
        "\n",
        "где $||$ - конкатенация, $\\alpha_{ij}^{(k)}$ - нормализованные коэффициенты внимания, вычисленные $k$-м механизмом внимания $(a^k)$ и $\\mathbf{W}^{(k)}$ - соответствующий вход матрицы весов линейной трансформации. Обратите внимание, что для данных условий $\\mathbf{h'} \\in \\mathbb{R}^{KF'}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4j45gTpCeXO"
      },
      "source": [
        "class GAT(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels, heads = 2,\n",
        "                 negative_slope = 0.2, dropout = 0., **kwargs):\n",
        "        super(GAT, self).__init__(node_dim=0, **kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.heads = heads\n",
        "        self.negative_slope = negative_slope\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.lin_l = None\n",
        "        self.lin_r = None\n",
        "        self.att_l = None\n",
        "        self.att_r = None\n",
        "\n",
        "        ############################################################################\n",
        "        # ЗАДАЧА: Ваш код здесь!\n",
        "        # Задайте слои, необходимые для функции message ниже.\n",
        "        # self.lin_l - это линейная трансформация, которую вы применяете к эмбеддингам\n",
        "        # ДО передачи сообщений.\n",
        "        # Обратите внимание на размерность линейных слоёв, поскольку мы используем \n",
        "        # многоголовое внимание.\n",
        "        # Наша реализация ~1 строка кода, но не волнуйтесь, если ваша будет отличаться.\n",
        "        self.lin_l = torch.nn.Linear(in_channels, out_channels * heads)\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        self.lin_r = self.lin_l\n",
        "\n",
        "        ############################################################################\n",
        "        # ЗАДАЧА: Ваш код здесь!\n",
        "        # Задайте параметры внимания \\overrightarrow{a_l/r}^T во вступительной части выше.\n",
        "        # Вам придётся иметь дело с многоголовыми сценариями.\n",
        "        # Используйте nn.Parameter вместо nn.Linear\n",
        "        # Наша реализация ~2 строки кода, но не волнуйтесь, если ваша будет отличаться.\n",
        "        self.att_l = torch.nn.Parameter(torch.Tensor(1, heads, out_channels))\n",
        "        self.att_r = torch.nn.Parameter(torch.Tensor(1, heads, out_channels))\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        nn.init.xavier_uniform_(self.lin_l.weight)\n",
        "        nn.init.xavier_uniform_(self.lin_r.weight)\n",
        "        nn.init.xavier_uniform_(self.att_l)\n",
        "        nn.init.xavier_uniform_(self.att_r)\n",
        "\n",
        "    def forward(self, x, edge_index, size = None):\n",
        "        \n",
        "        H, C = self.heads, self.out_channels\n",
        "\n",
        "        ############################################################################\n",
        "        # ЗАДАЧА: Ваш код здесь!\n",
        "        # Реализуйте передачу сообщений (message passing), а также пре- и пост-обработку (update).\n",
        "        # 1. Сначала примените линейное преобразование к эмбеддингам вершин, разбейте его\n",
        "        #    между несколькими головами. Мы используем одинаковые представления для \n",
        "        #    начальных и конечных вершин, но применяем различные линейные веса (W_l и W_r)\n",
        "        # 2. Вычислите вектора alpha для центральных (alpha_l) и соседних вершин (alpha_r).\n",
        "        # 3. Вызовите функцию propagate для передачи сообщений.\n",
        "        #    3.1 Припомните передать alpha = (alpha_l, alpha_r) в качестве параметра.\n",
        "        #    3.2 Подробнее здес: https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html\n",
        "        # 4. Приведите выход обратно к размерности N * d.\n",
        "        # Наша реализация ~5 строк кода, но не волнуйтесь, если ваша будет отличаться.\n",
        "        x_l = self.lin_l(x).view(-1, H, C); x_r = self.lin_r(x).view(-1, H, C)\n",
        "\n",
        "        alpha_l = torch.mul(self.att_l, x_l)\n",
        "        alpha_r = torch.mul(self.att_r, x_r)\n",
        "\n",
        "        out = self.propagate(edge_index, \n",
        "                             x = (x_l, x_r), \n",
        "                             size = size, \n",
        "                             alpha = (alpha_l, alpha_r))\n",
        "        out = out.view(-1, H * C)\n",
        "        ############################################################################\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "    def message(self, x_j, alpha_j, alpha_i, index, ptr, size_i):\n",
        "\n",
        "        ############################################################################\n",
        "        # ЗАДАЧА: Ваш код здесь!\n",
        "        # Реализуйте вашу функцию message. Вставка внимания в сообщение вместо\n",
        "        # обновления слегка нетривиальна.\n",
        "        # 1. Вычислите окончательные веса внимания, используя alpha_i и alpha_j,\n",
        "        #    а затем - примените leaky Relu.\n",
        "        # 2. Вычислите softmax для соседей для всех вершин. Используйте \n",
        "        #    torch_geometric.utils.softmax вместо стандартного из Pytorch.\n",
        "        # 3. Примените dropout к весам внимания (alpha).\n",
        "        # 4. Перемножьте эмбеддинги и веса внимания. Для самоконтроля, размерность\n",
        "        #    результата должна быть E * H * d.\n",
        "        # 5. ptr (LongTensor, optional): Если задан, вычисляет softmax, основываясь\n",
        "        #    на отсортированном входе в формате CSR. Вы можете просто отправить его в softmax.\n",
        "        # Наша реализация ~5 строк кода, но не волнуйтесь, если ваша будет отличаться.\n",
        "\n",
        "        att = alpha_i + alpha_j\n",
        "\n",
        "        att = torch_geometric.utils.softmax(\n",
        "                                            F.leaky_relu(att, negative_slope = self.negative_slope),\n",
        "                                            ptr if ptr else index)\n",
        "        att = F.dropout(att, self.dropout, training = self.training)\n",
        "\n",
        "        out = torch.mul(x_j, att)\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "    def aggregate(self, inputs, index, dim_size = None):\n",
        "\n",
        "        ############################################################################\n",
        "        # ЗАДАЧА: Ваш код здесь! \n",
        "        # Реализуйте вашу функцию аггрегации здесь.\n",
        "        # Иструкции по использованию torch_scatter.scatter: https://pytorch-scatter.readthedocs.io/en/latest/_modules/torch_scatter/scatter.html\n",
        "        # Обратите внимание, параметр \"reduce\" отличается от такового в GraphSage.\n",
        "        # Наша реализация ~1 строка кода, но не волнуйтесь, если ваша будет отличаться.\n",
        "\n",
        "        out = torch_scatter.scatter(inputs, index = index, \n",
        "                                    dim = self.node_dim, dim_size = dim_size, \n",
        "                                    reduce = \"sum\")\n",
        "        ############################################################################\n",
        "    \n",
        "        return out"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2dkgSuWCheU"
      },
      "source": [
        "## Построение оптимизаторов\n",
        "\n",
        "Данная функция предоставлена для вас. **Для оценивания задания, пожалуйста используйте оптимизатор Adam**, но вы, разумеется, вольны экспериментировать с выбором прочих оптимизаторов в образовательных целях."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_TIQ8NPCjBP"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def build_optimizer(args, params):\n",
        "    weight_decay = args.weight_decay\n",
        "    filter_fn = filter(lambda p : p.requires_grad, params)\n",
        "    if args.opt == 'adam':\n",
        "        optimizer = optim.Adam(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    elif args.opt == 'sgd':\n",
        "        optimizer = optim.SGD(filter_fn, lr=args.lr, momentum=0.95, weight_decay=weight_decay)\n",
        "    elif args.opt == 'rmsprop':\n",
        "        optimizer = optim.RMSprop(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    elif args.opt == 'adagrad':\n",
        "        optimizer = optim.Adagrad(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    if args.opt_scheduler == 'none':\n",
        "        return None, optimizer\n",
        "    elif args.opt_scheduler == 'step':\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.opt_decay_step, gamma=args.opt_decay_rate)\n",
        "    elif args.opt_scheduler == 'cos':\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.opt_restart)\n",
        "    return scheduler, optimizer"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBYdWFwYCkwY"
      },
      "source": [
        "## Обучение и тестирование\n",
        "\n",
        "Данная функция предоставлена для вас. **Для оценивания задания, пожалуйста оставьте её в первозданном виде**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tZMWRc8CmGg"
      },
      "source": [
        "import time\n",
        "\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def train(dataset, args):\n",
        "    \n",
        "    print(\"Node task. test set size:\", np.sum(dataset[0]['train_mask'].numpy()))\n",
        "    test_loader = loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True)\n",
        "\n",
        "    # build model\n",
        "    model = GNNStack(dataset.num_node_features, args.hidden_dim, dataset.num_classes, \n",
        "                            args)\n",
        "    scheduler, opt = build_optimizer(args, model.parameters())\n",
        "\n",
        "    # train\n",
        "    losses = []\n",
        "    test_accs = []\n",
        "    for epoch in range(args.epochs):\n",
        "        total_loss = 0\n",
        "        model.train()\n",
        "        for batch in loader:\n",
        "            opt.zero_grad()\n",
        "            pred = model(batch)\n",
        "            label = batch.y\n",
        "            pred = pred[batch.train_mask]\n",
        "            label = label[batch.train_mask]\n",
        "            loss = model.loss(pred, label)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            total_loss += loss.item() * batch.num_graphs\n",
        "        total_loss /= len(loader.dataset)\n",
        "        losses.append(total_loss)\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "          test_acc = test(test_loader, model)\n",
        "          test_accs.append(test_acc)\n",
        "        else:\n",
        "          test_accs.append(test_accs[-1])\n",
        "    return test_accs, losses\n",
        "\n",
        "def test(loader, model, is_validation=True):\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        with torch.no_grad():\n",
        "            # max(dim=1) returns values, indices tuple; only need indices\n",
        "            pred = model(data).max(dim=1)[1]\n",
        "            label = data.y\n",
        "\n",
        "        mask = data.val_mask if is_validation else data.test_mask\n",
        "        # node classification: only evaluate on nodes in test set\n",
        "        pred = pred[mask]\n",
        "        label = data.y[mask]\n",
        "            \n",
        "        correct += pred.eq(label).sum().item()\n",
        "\n",
        "    total = 0\n",
        "    for data in loader.dataset:\n",
        "        total += torch.sum(data.val_mask if is_validation else data.test_mask).item()\n",
        "    return correct / total\n",
        "  \n",
        "class objectview(object):\n",
        "    def __init__(self, d):\n",
        "        self.__dict__ = d\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7-h7jIsCns4"
      },
      "source": [
        "## Приступим же к обучению!\n",
        "\n",
        "Мы будем работать с набором данных CORA над классификацией вершин.\n",
        "\n",
        "Данная функция предоставлена для вас. **Для оценивания задания, пожалуйста не изменяйте параметров, заданных по умолчанию.** Однако, вы, разумеется, вольны экспериментировать с выбором конфигураций в образовательных целях или просто ради забавы!\n",
        "\n",
        "**Сообщите ваши лучшие значения для доли верных ответов и функции потерь.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qe9B45l9Cpz2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "outputId": "95a5ee5c-c552-4eec-860e-d865c4b20f2f"
      },
      "source": [
        "def main():\n",
        "    for args in [\n",
        "        {'model_type': 'GraphSage', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, 'batch_size': 32, 'hidden_dim': 32, 'dropout': 0.5, 'epochs': 500, 'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 'weight_decay': 5e-3, 'lr': 0.01},\n",
        "    ]:\n",
        "        args = objectview(args)\n",
        "        for model in ['GraphSage', 'GAT']:\n",
        "            args.model_type = model\n",
        "\n",
        "            # Match the dimension.\n",
        "            if model == 'GAT': args.heads = 2\n",
        "            else: args.heads = 1\n",
        "\n",
        "            if args.dataset == 'cora':\n",
        "                dataset = Planetoid(root='/tmp/cora', name='Cora')\n",
        "            else: raise NotImplementedError(\"Unknown dataset\") \n",
        "            test_accs, losses = train(dataset, args) \n",
        "\n",
        "            print(\"Maximum accuracy: {0}\".format(max(test_accs)))\n",
        "            print(\"Minimum loss: {0}\".format(min(losses)))\n",
        "\n",
        "            plt.title(dataset.name)\n",
        "            plt.plot(losses, label=\"training loss\" + \" - \" + args.model_type)\n",
        "            plt.plot(test_accs, label=\"test accuracy\" + \" - \" + args.model_type)\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n",
            "/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node task. test set size: 140\n",
            "Maximum accuracy: 0.724\n",
            "Minimum loss: 0.12758198380470276\n",
            "Node task. test set size: 140\n",
            "Maximum accuracy: 0.762\n",
            "Minimum loss: 0.031095759943127632\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeXhURdq37+olnT1kAdlJGHZCSNgREWQXR1wYUVRURgRx0HcWncENHEZcXpThRccFFFDHAQUFFEGQbYCPRUiMrFHCToCQhex7d31/nE7Tne4kndAkpFP3dfWVdFWdOk+fdH7nOU9VPSWklCgUCoXCe9HVtwEKhUKhuL4ooVcoFAovRwm9QqFQeDlK6BUKhcLLUUKvUCgUXo4SeoVCofBylNArFAqFl6OEXtHoEUI8KIQ4IITIE0JcFEJsEELcUt92KRSeQgm9olEjhPgzsAB4DbgJaAu8B9xVw34MnrdOofAMSugVjRYhRAgwB/iDlPJrKWW+lLJUSvmtlPI5IYRJCLFACHHB+loghDBZjx0qhDgvhPibEOISsFQIESqEWCeESBNCXLH+3rpeP6RCgRJ6ReNmIOALrK6k/kVgABAL9AT6AS/Z1TcHwoB2wFS0/6el1vdtgULg3ethuEJRE4TKdaNorAghHgLellI2r6T+BPC0lHK99f1o4EMpZaQQYiiwCQiWUhZVcnwssE1KGXpdPoBC4SYqrqhozGQAEUIIg5SyzEV9S+CM3fsz1rJy0uxFXgjhD/wTGAOUi3uQEEIvpTR71nSFwn1U6EbRmNkDFAN3V1J/AS0MU05ba1k5FR+H/wJ0BvpLKYOBW63l4tpNVShqj/LoFY0WKWW2EGIW8C8hRBlaKKYUGAHcBiwHXhJC7EcT9VnAv6voMggtLp8lhAgDZl9P+xUKd1EevaJRI6V8G/gz2iBrGnAOmAGsAV4FDgAHgUNAgrWsMhYAfkA6sBf4/roZrlDUADUYq1AoFF6O8ugVCoXCy1FCr1AoFF6OEnqFQqHwcpTQKxQKhZdzQ06vjIiIkJGRkfVthkKhUDQY4uPj06WUTV3V3ZBCHxkZyYEDB+rbDIVCoWgwCCHOVFanQjcKhULh5VQr9EKINkKIbUKIo0KII0KI/3HRRgghFgohkoUQB4UQvezqHhVCHLe+HvX0B1AoFApF1bgTuikD/iKlTBBCBAHxQogfpJRH7drcDnS0vvoD7wP97ZaB90FbQh4vhPhGSnnFo59CoVAoFJVSrdBLKS8CF62/5wohjgGtAHuhvwv4VGrLbPcKIZoIIVoAQ4EfpJSZAEKIH9Ay+y336KdQKDxMaWkp58+fp6jIZQZihaLe8PX1pXXr1hiNRrePqdFgrBAiEogD9lWoaoWWI6Sc89ayyspd9T0VbfMG2rZtWxOzFAqPc/78eYKCgoiMjEQIlXxScWMgpSQjI4Pz588TFRXl9nFuD8YKIQKBr4A/SilzamFjlUgpF0kp+0gp+zRt6nKGkEJRZxQVFREeHq5EXnFDIYQgPDy8xk+abgm9EMKIJvKfSym/dtEkBWhj9761tayycoXihkeJvOJGpDbfS3dm3QjgY+CYlHJ+Jc2+AR6xzr4ZAGRbY/sbgVHWTZNDgVHWMo9jsUje3Xqc//6adj26VygUigaLOx79IGASMEwIkWh9jRVCPCmEeNLaZj1wEkgGFgNPAVgHYf8B7Le+5pQPzHoanU7w4c6jbDhy4np0r1DUKVlZWbz33nu1Onbs2LFkZWVV2WbWrFls3ry5Vv1XJDIykvT0dI/0VRPmz59Ply5d6NGjBz179uTPf/4zpaWlHun7lVde4a233nJZN3fuXLp3705MTAyxsbHs21dxyPLGw51ZN7uoZis062ybP1RStwRYUivrakBeSR6i7VwSsocBA6736RSK60q50D/11FNOdWVlZRgMlf/rrl+/vtr+58yZc0321TcffPABmzZtYu/evTRp0oSSkhLmz59PYWGh02wUs9mMXq/3yHn37NnDunXrSEhIwGQykZ6eTklJiUf6vp54zcrYQJ9Amui6kiq3U1SmpsQpGjYzZ87kxIkTxMbG8txzz7F9+3YGDx7MuHHj6NatGwB33303vXv3pnv37ixatMh2bLmHffr0abp27coTTzxB9+7dGTVqFIWFhQA89thjrFq1ytZ+9uzZ9OrVix49epCUlARAWloaI0eOpHv37kyZMoV27dpV67nPnz+f6OhooqOjWbBgAQD5+fnccccd9OzZk+joaL744gvbZ+zWrRsxMTE8++yzNbo+c+fO5f3336dJkyYA+Pj4MHPmTIKDgwEIDAzkL3/5Cz179mTPnj3MmTOHvn37Eh0dzdSpUynfcGno0KH8z//8D7GxsURHR/Pjjz/aznH06FGGDh1K+/btWbhwIQAXL14kIiICk8kEQEREBC1bavvFV3aO/fv327z/5557jujoaEC7AT333HP07duXmJgYPvzwwxpdg5pwQ+a6qS1dAoazJz+Bg2kH6deiX32bo/AS/v7tEY5e8OxEs24tg5l9Z/dK69944w0OHz5MYmIiANu3bychIYHDhw/bptUtWbKEsLAwCgsL6du3L+PHjyc8PNyhn+PHj7N8+XIWL17MhAkT+Oqrr3j44YedzhcREUFCQgLvvfceb731Fh999BF///vfGTZsGM8//zzff/89H3/8cZWfKT4+nqVLl7Jv3z6klPTv358hQ4Zw8uRJWrZsyXfffQdAdnY2GRkZrF69mqSkJIQQ1Yaa7MnJySEvL6/K6YX5+fn079+ft99+G4Bu3boxa9YsACZNmsS6deu48847ASgoKCAxMZEdO3bw+9//nsOHDwOQlJTEtm3byM3NpXPnzkyfPp1Ro0YxZ84cOnXqxIgRI7j//vsZMmQIADNmzHB5jsmTJ7N48WIGDhzIzJkzbTZ+/PHHhISEsH//foqLixk0aBCjRo2q0bRJd/Eajx6ge3gPAA5c+rmeLVEoPE+/fv0cRGDhwoX07NmTAQMGcO7cOY4fP+50TFRUFLGxsQD07t2b06dPu+z73nvvdWqza9cuHnjgAQDGjBlDaGholfbt2rWLe+65h4CAAAIDA7n33nvZuXMnPXr04IcffuBvf/sbO3fuJCQkhJCQEHx9fXn88cf5+uuv8ff3r+nlsLFx40ZiY2OJjIxk9+7dAOj1esaPH29rs23bNvr370+PHj3YunUrR44csdVNnDgRgFtvvZWcnBzbTeeOO+7AZDIRERFBs2bNSE1NJTAwkPj4eBYtWkTTpk25//77WbZsWaXnyMrKIjc3l4EDBwLw4IMP2s67adMmPv30U2JjY+nfvz8ZGRku/4aewKs8+p4tW2FJDueHEz/yVNwT9W2OwkuoyvOuSwICAmy/b9++nc2bN7Nnzx78/f0ZOnSoy7nV5SEG0MSvPHRTWTu9Xk9ZWZlH7e7UqRMJCQmsX7+el156ieHDhzNr1ix+/PFHtmzZwqpVq3j33XfZunWrw3GjR48mNTWVPn368NFHH9nKg4ODCQwM5NSpU0RFRTF69GhGjx7Nb3/7W1u83NfX1xaXLyoq4qmnnuLAgQO0adOGV155xeFaVZyuWP6+4rUrvy56vZ6hQ4cydOhQevTowSeffMIDDzxQ5TlcIaXknXfeYfTo0TW9pDXGqzz6IZ2aEm5sz/GsX7mco+L0ioZLUFAQubm5ldZnZ2cTGhqKv78/SUlJ7N271+M2DBo0iC+//BLQvM8rV6pOUTV48GDWrFlDQUEB+fn5rF69msGDB3PhwgX8/f15+OGHee6550hISCAvL4/s7GzGjh3LP//5T37+2fkpfOPGjSQmJjqIfDnPP/8806dPt3nfUspKhbW8PCIigry8PNvYRDnlYwa7du2yPW1Uxi+//OLgdScmJtKuXbtKz9GkSROCgoJsM3NWrFhhO3b06NG8//77tplCv/76K/n5+ZWe+1rwKo9eCMHojj1ZfvwA3x46zeODutS3SQpFrQgPD2fQoEFER0dz++23c8cddzjUjxkzhg8++ICuXbvSuXNnBgzw/Eyz2bNnM3HiRD777DMGDhxI8+bNCQoKqrR9r169eOyxx+jXTxsfmzJlCnFxcWzcuJHnnnsOnU6H0Wjk/fffJzc3l7vuuouioiKklMyfX9kSHddMnz7dFoc3mUwEBgYyaNAg4uLinNo2adKEJ554gujoaJo3b07fvn0d6n19fYmLi6O0tJQlS6qeIJiXl8fTTz9NVlYWBoOBDh06sGjRoirP8fHHH/PEE0+g0+kYMmSI7UYyZcoUTp8+Ta9evZBS0rRpU9asWVOj6+A2Usob7tW7d29ZW74/9b2MXhYtZ6z6ptZ9KBRHjx6tbxPqnaKiIllaWiqllHL37t2yZ8+e9WyR5xkyZIjcv3//dT1Hbm6u7ffXX39dPvPMM9fcp6vvJ3BAVqKpXuXRA3Ro0gGA41fUwimF4lo4e/YsEyZMwGKx4OPjw+LFi+vbpAbJd999x+uvv05ZWRnt2rWzDd7WJV4n9M0DmgNwKS8VKaXKV6JQ1JKOHTvy008/1bcZ15Xt27df93Pcf//93H///df9PFXhVYOxAP4Gf4zCRKEli6RLlQ9mKRQKRWPB64ReCEFT/wh0hjw2HL5U3+YoFApFveN1Qg9wU0Az/P0LOHbR42nzFQqFosHhlUIf4ReB3pjHmYzrMydVoVAoGhJeKfThvuGYRTZnMgqwWGR9m6NQ1JhrSVMMsGDBAgoKCjxoUcOgrKyMF154gY4dOxIbG0tsbCxz5871WP/2yeDssVgsPPPMM0RHR9OjRw/69u3LqVOnPHbea8UrhT7UN5QSmU9xWRmpuWqFrKLh4Q1C7+lUCu7w0ksvceHCBQ4dOkRiYiI7d+50maNeSonFYvHYeb/44gsuXLjAwYMHOXToEKtXr7Zl1rwR8EqhDzQGar/oijhxWYVvFA2PimmKAebNm2dLaTt79mzAdQrghQsXcuHCBW677TZuu+02p74rS6ebnJzMiBEj6NmzJ7169eLECW0typtvvmnb3KM8++LQoUM5cOAAAOnp6URGRgKwbNkyxo0bx7Bhwxg+fDh5eXkMHz7clgJ57dq1Njs+/fRTYmJi6NmzJ5MmTSI3N5eoqCibMOfk5Di8r46CggIWL17MO++8g6+vL6ClknjllVcAOH36NJ07d+aRRx4hOjqac+fOMX36dPr06UP37t1t1xS01M1//etf6dGjB/369SM5OdlWt2PHDm6++Wbat29v8+4vXrxIixYt0Ok0SW3durUtCVxl51i/fj1dunShd+/ePPPMM/z2t7+1/U1///vf069fP+Li4hyuWW3xunn0AEE+2jJtoS/il9RcbukYUc8WKRo0G2bCpUOe7bN5D7j9jUqrK6Yp3rRpE8ePH+fHH39ESsm4cePYsWMHaWlpTimAQ0JCmD9/Ptu2bSMiwvm7X1k63YceeoiZM2dyzz33UFRUhMViYcOGDaxdu5Z9+/bh7+9PZmb1G8QlJCRw8OBBwsLCKCsrY/Xq1QQHB5Oens6AAQMYN24cR48e5dVXX2X37t1ERESQmZlJUFAQQ4cO5bvvvuPuu+9mxYoV3HvvvU4biVRGcnIybdu2rTJNw/Hjx/nkk09sKSPmzp1LWFgYZrOZ4cOHc/DgQWJiYgAICQnh0KFDfPrpp/zxj39k3bp1gCbqu3btIikpiXHjxvG73/2OCRMmcMstt7Bz506GDx/Oww8/bEvH4OocnTp1Ytq0aezYsYOoqChbBs3y9sOGDWPJkiVkZWXRr18/RowY4ZDUrqa4s2fsEiHEZSHE4Urqn7PbYvCwEMIshAiz1p0WQhyy1h2otZU1JNBH8+ibBJj55ZKaeaNo+GzatIlNmzYRFxdHr169SEpK4vjx4y5TAFeHq3S6ubm5pKSkcM899wBa/hd/f382b97M5MmTbWmEw8LCqu1/5MiRtnZSSl544QViYmIYMWIEKSkppKamsnXrVu677z7bjai8/ZQpU1i6dCkAS5cuZfLkyTW/WFaWLl1KbGwsbdq04dy5cwC0a9fOIS/Ql19+Sa9evYiLi+PIkSMcPXrUVlcuvhMnTmTPnj228rvvvhudTke3bt1ITU0FNA/+l19+4fXXX0en0zF8+HC2bNlS6TmSkpJo3769Le20vdBv2rSJN954g9jYWFtW0rNnz9b6OoB7Hv0y4F3gU1eVUsp5wDwAIcSdwJ+k476wt0kp63RDyfLQTdsIHb+m5tXlqRXeSBWed10hpeT5559n2rRpTnWuUgBXRnUpe93FYDDYYtwVj7f3PD///HPS0tKIj4/HaDQSGRlZ5fkGDRrE6dOn2b59O2az2bYbUzlms5nevXsDMG7cOIctETt06MDZs2fJzc0lKCiIyZMnM3nyZKKjozGbzU62nTp1irfeeov9+/cTGhrKY489Vmn6Yvvf7dMXl4e9ystvv/12br/9dm666SbWrFlD+/btqzyHK6SUfPXVV3Tu3LnKdjWhWo9eSrkDcHdD74nA8muyyAOUh25CAsykqnTFigZIxTTFo0ePZsmSJeTlaY5LSkoKly9fdpkC2NXx5VSWTjcoKIjWrVvbsicWFxdTUFDAyJEjWbp0qW1gtzx0ExkZSXx8PIDLWSjlZGdn06xZM4xGI9u2bePMmTMADBs2jJUrV5KRkeHQL8AjjzzCgw8+6NKb1+v1JCYmkpiY6LTvrb+/P48//jgzZsywfU6z2Vzpnq45OTkEBAQQEhJCamoqGzZscKgvT1/8xRdf2DYOqYyEhAQuXLgAaDNwDh48SLt27So9R+fOnTl58qRtk5fyc4H2t37nnXdsNxFPpKHwWIxeCOEPjAFm2BVLYJMQQgIfSikXuTxYO34qMBWgbdu212RLuUfv61tKRl6JynmjaHBUTFM8b948jh07ZhOcwMBA/v3vf5OcnOyUAhhg6tSpjBkzhpYtW7Jt2zZbv1Wl0/3ss8+YNm0as2bNwmg0snLlSsaMGUNiYiJ9+vTBx8eHsWPH8tprr/Hss88yYcIEFi1a5JRC2Z6HHnqIO++8kx49etCnTx+6dNFSh3fv3p0XX3yRIUOGoNfriYuLsyX7euihh3jppZccwhnuMnfuXF5++WWio6MJCgrCz8+PRx99lJYtW9qEuJyePXsSFxdHly5daNOmDYMGDXKov3LlCjExMZhMJpYvr9p/vXz5Mk888QTFxcWAthvYjBkzbCmQK57Dz8+P9957jzFjxhAQEODwd3j55Zf54x//SExMDBaLhaioKNv4QK2pLK2l/QuIBA5X0+Z+4NsKZa2sP5sBPwO3unO+a0lTLKWUaQVpWqrib9+R7f62Tmbll1xTf4rGh0pTXH+sXLlSPvzww/VqQ7t27WRaWtp1PUd5+mKLxSKnT58u58+f7/ax9Zmm+AEqhG2klCnWn5eFEKuBfsAOD57TJeWhG4NRu7um5RUT4u/eyL1Coag/nn76aTZs2MD69evr25TrzuLFi/nkk08oKSkhLi7O5fiLp/CI0AshQoAhwMN2ZQGATkqZa/19FDCnki48io/OB4POgE6vCX1GXjEdmgXWxakVCsU18M4779S3CQCVbqLuSf70pz/xpz/96bqfB9wQeiHEcmAoECGEOA/MBowAUsoPrM3uATZJKe1XJ90ErLbGxg3Af6SU33vO9CptJsgYhNRpGyGn57kejFEoFIrGQLVCL6WsdkRESrkMbRqmfdlJoGdtDbtWAn0CsaAJ/SU180ahUDRivDIFAmgzb0osBUQEmlS6YoVC0ajxWqEP8gkirzSP6FbBHE7Jrm9zFAqFot7wWqEPNAaSW5JLdMsQjl/Oo6jUXN8mKRRucy3ZK8eOHUtWVlaVbWbNmsXmzZtr1X9FIiMjSU+v08XvAMyfP58uXbrYEq79+c9/dkiAlpiYiBCC77/XhgbvueceYmNj6dChAyEhIbY0xrt3765z2+sa7xV6n0CbR2+2SH5R+8cqGhBVCX116X/Xr19fbYrcOXPmMGLEiFrbV9988MEHbNq0ib1793Lo0CH2799Ps2bNKCwstLVZvnw5t9xyi22x0+rVq0lMTOSjjz5i8ODBthW2N998c319jDrDa4U+yCeIvJI8urfUkjwdvqDCN4qGQ8U0xdu3b2fw4MGMGzeObt26AVpyrd69e9O9e3cWLbq66Lzcwz59+jRdu3bliSeeoHv37owaNcomhPYbaERGRjJ79mxbKuGkpCQA0tLSGDlyJN27d2fKlCm0a9euWs99/vz5REdHEx0dzYIFCwDXqZTLP2O3bt2IiYnh2WefrdH1mTt3Lu+//77thubj48PMmTMJDg4GtIWgK1euZNmyZfzwww+1yufjTXhlmmLQQjf5pfm0bGIixM/IkQtqQFZRO9788U2SMpM82meXsC78rd/fKq2vmKZ4+/btJCQkcPjwYVvGwyVLlhAWFkZhYSF9+/Zl/PjxhIeHO/Rz/Phxli9fzuLFi5kwYQJfffUVDz/8sNP5IiIiSEhI4L333uOtt97io48+4u9//zvDhg3j+eef5/vvv+fjjz+u8jPFx8ezdOlS9u3bh5SS/v37M2TIEE6ePOmUSjkjI4PVq1eTlJSEEKLaUJM9OTk55OXl2a6DK3bv3k1UVBS/+c1vbKmPx48f7/Y5vA2v9uglkoKyAlqE+JKWW1zfJikU10S/fv0cxG3hwoX07NmTAQMGcO7cOY4fP+50TFRUFLGxsQD07t270oVA9957r1ObXbt28cADDwAwZswY20YalbFr1y7uueceAgICCAwM5N5772Xnzp0uUymHhITg6+vL448/ztdff21Lg1wbNm7cSGxsLJGRkbZ4+/Lly222P/DAA9XmqvF2vNajDzBq6UjzS/MJ8TOSU+jeLjUKRUWq8rzrEvsUu9u3b2fz5s3s2bMHf39/W97yitin1NXr9Q4xbFft9Hq9x7cA7NSpk8tUyj/++CNbtmxh1apVvPvuu2zdutXhuNGjR5OamkqfPn346KOPbOXBwcEEBgZy6tQpoqKiGD16NKNHj+a3v/0tJSUlmM1mvvrqK9auXcvcuXORUpKRkWFLX9wY8VqPvnzzkdySXIL9jGQroVc0ICpLM1xOdnY2oaGh+Pv7k5SUxN69ez1uw6BBg/jyyy8BbTOMK1euVNl+8ODBrFmzhoKCAvLz81m9ejWDBw92mUo5Ly+P7Oxsxo4dyz//+U9+/vlnp/42btxoGzytyPPPP8/06dNtIR8ppe1Gt2XLFmJiYjh37hynT5/mzJkzjB8/ntWrV1/rJWmweK1HX56qOL80n2BfI7lFdb9RsUJRWyqmKa6YCnjMmDF88MEHdO3alc6dOzvsmuQpZs+ezcSJE/nss88YOHAgzZs3r9Ij7tWrF4899hj9+vUDtN2i4uLi2Lhxo1Mq5dzcXO666y6KioqQUjJ//vwa2TZ9+nTy8/Pp378/JpOJwMBABg0aRFxcHH/84x9tO2WVM378eN5//30eeeSRml8IL0BIux1SbhT69Okjyzceri0/Xf6JRzY8wocjPmRzQhNWHjjHob+P9pCFCm/n2LFjdO3atb7NqFeKi4vR6/UYDAb27NnD9OnTbYPDivrF1fdTCBEvpezjqr3XevT+Bm1wJ78sn2C/CHKLyzBbJHqd2oBEoXCHs2fPMmHCBCwWCz4+PixevLi+TVLUEu8VeqMm9AWlBQT7arnoc4tKaeLvU59mKRQNho4dO3pkGztF/eO1g7E2j9466wZQA7IKhaJR4rVCXz69sqCsgGCr0OcUqgFZhULR+PBaoTfpTeiEjoLSAptHn1WoNiBRKBSNj2qFXgixRAhxWQhxuJL6oUKIbCFEovU1y65ujBDiFyFEshBipicNrw4hBAGGAArKCggL0OLymflK6BUKRePDHY9+GTCmmjY7pZSx1tccACGEHvgXcDvQDZgohOh2LcbWFD+jHwWlBYRbhT5DbSmoaCBcS5pigAULFlBQUOBBixoGZWVlvPDCC3Ts2NGWhnju3LkObdasWYMQwpa8rX///sTGxtK2bVuaNm1qO64u9o2tK6oVeinlDiCzFn33A5KllCellCXACuCuWvRTa/wN/rbBWL1OkJGv8t0oGgbeIPSeTqXgDi+99BIXLlzg0KFDJCYmsnPnTocc9eCcvnjfvn0kJiYyZ84c7r//flv64sjIyDq3/3rhqRj9QCHEz0KIDUKI7tayVsA5uzbnrWV1RoBRC93odIJQfx8VulE0GCqmKQaYN28effv2JSYmhtmzZwOuUwAvXLiQCxcucNttt3Hbbbc59T1nzhz69u1LdHQ0U6dOpXzRZHJyMiNGjKBnz5706tWLEydOAPDmm2/aNveYOVOLwA4dOpTyRY3p6ek2UVy2bBnjxo1j2LBhDB8+nLy8PIYPH25Lgbx27VqbHZ9++ikxMTH07NmTSZMmkZubS1RUlE2Yc3JyHN5XR0FBAYsXL+add97B19cX0FJJvPLKK7Y2eXl57Nq1i48//pgVK1a41a834Il59AlAOyllnhBiLLAG6FjTToQQU4GpAG3btvWAWdpc+oJSzauJCPQhXYVuFLXg0muvUXzMs2mKTV270PyFFyqtr5imeNOmTRw/fpwff/wRKSXjxo1jx44dpKWlOaUADgkJYf78+Wzbto2IiAinvmfMmMGsWdpQ2qRJk1i3bh133nknDz30EDNnzuSee+6hqKgIi8XChg0bWLt2Lfv27cPf35/MzOof7hMSEjh48CBhYWGUlZWxevVqgoODSU9PZ8CAAYwbN46jR4/y6quvsnv3biIiIsjMzCQoKMiWUvjuu+9mxYoV3HvvvRiNRreuaXJyMm3btq0yTcPatWsZM2YMnTp1Ijw8nPj4eHr37u1W/w2Za/bopZQ5Uso86+/rAaMQIgJIAdrYNW1tLausn0VSyj5Syj5Nmza9VrMAbIOxAGEByqNXNFw2bdrEpk2biIuLo1evXiQlJXH8+HGXKYCrY9u2bfTv358ePXqwdetWjhw5Qm5uLikpKbYcMb6+vvj7+7N582YmT55sSyMcFhZWbf8jR460tZNS8sILLxATE8OIESNISUkhNTWVrVu3ct9999luROXtp0yZwtKlSwFYunQpkydPrvnFspEQMDIAACAASURBVLJ06VJiY2Np06YN585pwYXGmr74mj16IURzIFVKKYUQ/dBuHhlAFtBRCBGFJvAPAA9e6/lqgq/Bl6IyLaNdWICP2nxEUSuq8rzrCiklzz//PNOmTXOqc5UCuDKKiop46qmnOHDgAG3atOGVV16p1e5LBoMBi8Vi69Me+3TKn3/+OWlpacTHx2M0GomMjKzyfIMGDeL06dNs374ds9lMdHS0Q73ZbLZ54OPGjWPOnDm2ug4dOnD27FlbOuLJkyczefJkoqOjMZvNZGZmsnXrVg4dOoQQArPZjBCCefPmIYR3p0ZxZ3rlcmAP0FkIcV4I8bgQ4kkhxJPWJr8DDgshfgYWAg9IjTJgBrAROAZ8KaU8cn0+hmv8DH42jz4i0ER6nhqMVTQMKqYpHj16NEuWLCEvLw+AlJQULl++7DIFsKvjyykX2YiICPLy8mzbCQYFBdG6dWvWrFkDaAnNCgoKGDlyJEuXLrUN7JaHbiIjI4mPjwew9eGK7OxsmjVrhtFoZNu2bZw5cwaAYcOGsXLlSjIyMhz6BXjkkUd48MEHXXrzer3eNlhqL/IA/v7+PP7448yYMcP2Oc1mMyUlJTY7J02axJkzZzh9+jTnzp0jKiqKnTt3Vmq/t1CtRy+lnFhN/bvAu5XUrQfW1860a6eiR59bVEZJmQUfg9euE1N4CRXTFM+bN49jx44xcOBAAAIDA/n3v/9NcnKyUwpggKlTpzJmzBhatmzJtm3bbP02adKEJ554gujoaJo3b07fvn1tdZ999hnTpk1j1qxZGI1GVq5cyZgxY0hMTKRPnz74+PgwduxYXnvtNZ599lkmTJjAokWLnFIo2/PQQw9x55130qNHD/r06UOXLl0A6N69Oy+++CJDhgxBr9cTFxfHsmXLbMe89NJLTJxYpfS4ZO7cubz88stER0cTFBSEn58fjz76KC1btmT58uX87W+Om8iMHz+e5cuXc+utt9b4XA0Jr01TDDA/fj6fH/2c+EnxfL7vDC+uPsze54fTPMTXA1YqvBmVprj+WLVqFWvXruWzzz6rb1NuWFSaYjv8DH6UWEowW8xXF03lFyuhVyhuUJ5++mk2bNjA+vX1FgjwSrxb6PV+ABSZiwgP1PbEVKtjFYobl3feeae+TfBKvDpY7WvQPPfCskKV70ZRY27EsKZCUZvvpVcLvZ9B8+gLywptoRs180bhDr6+vmRkZCixV9xQSCnJyMiwrfx1F68O3ZR79EVlRbQONOJn1HMhq+ZzhhWNj9atW3P+/HnS0tLq2xSFwgFfX19at25do2O8WujLPfqisiKEELQL9+dMRn49W6VoCBiNRqKiourbDIXCIzSK0E2RWfPi24X7cyaz8aVuVSgUjRuvFnpf/dXBWIDI8ADOZhRgtqi4q0KhaDx4t9AbHIW+dagfJWaLykuvUCgaFY1C6MvTIIT4azNv1CbhCoWiMeHVQm8/vRIg2Fcbe84pcm8jA4VCofAGvFroy2P0xWYtVBPsp21gkFOohF6hUDQevFroTQYt7cFVj94q9EUqdKNQKBoPXi30Rp0RvdDbefTW0I3y6BUKRSPCq4UewKQ32QZjr3r0SugVCkXjweuF3tfga/PofY16fAw6NetGoVA0KtzZSnCJEOKyEOJwJfUPCSEOCiEOCSF2CyF62tWdtpYnCiGufSeRWuCrvyr0oHn1yqNXKBSNCXc8+mXAmCrqTwFDpJQ9gH8AiyrU3yaljK1s55PrjclwNXQDWpw+W8XoFQpFI8KdPWN3CCEiq6jfbfd2L1CztGrXmYoefai/D1dUTnqFQtGI8HSM/nFgg917CWwSQsQLIaZWdaAQYqoQ4oAQ4oAnU8PaD8YCNA00kZarUiAoFIrGg8eEXghxG5rQ22+zfouUshdwO/AHIUSlW61LKRdJKftIKfs0bdrUU2ZpoRvzVaFvFmzishJ6hULRiPCI0AshYoCPgLuklBnl5VLKFOvPy8BqoJ8nzlcT/PR+DqGbpoEmsgtLKS4z17UpCoVCUS9cs9ALIdoCXwOTpJS/2pUHCCGCyn8HRgEuZ+5cTyoOxjYN0lbLqvCNQqFoLFQ7GCuEWA4MBSKEEOeB2YARQEr5ATALCAfeE0IAlFln2NwErLaWGYD/SCm/vw6foUpMepODR98s+KrQtw71r2tzFAqFos5xZ9bNxGrqpwBTXJSfBHo6H1G3VJx1ExGoCX16npp5o1AoGgdevzLWaR69r8pgqVAoGhdeL/S+el+KzEVIqW0fGGTNSZ+rVscqFIpGgvcLvcEXi7RQZtHy2wRZPfpclapYoVA0Erxe6E16LSZfPpfex6DD16gjt1gJvUKhaBx4vdBX3GUKNK9exegVCkVjweuFvnyXKfsB2SBfgwrdKBSKRoPXC70rj16lKlYoFI0Jrxf6ijF6UB69QqFoXHi90PsaNI++4lx65dErFIrGQqMR+uIyu9CNn0FtJ6hQKBoNXi/0rkI3YQE+XCkowWKR9WWWQqFQ1BleL/SuBmObBpowWyRXClS+G4VC4f14vdC7ml4ZEaQSmykUisaD9wu9NXRT0aMHlZNeoVA0Drxe6P0MfkAFoS/ffCSvyOUxCoVC4U14vdCXe/SFZYW2MlvoJleFbhQKhffj9UJv0BkwCINjrhuTAR+9jvR8FbpRKBTej1tCL4RYIoS4LIRwueer0FgohEgWQhwUQvSyq3tUCHHc+nrUU4bXhIqbjwghCPQ1kK8yWCoUikaAux79MmBMFfW3Ax2tr6nA+wBCiDC0PWb7A/2A2UKI0NoaW1sq7hsLEGDSk19srmtTFAqFos5xS+illDuAzCqa3AV8KjX2Ak2EEC2A0cAPUspMKeUV4AeqvmFcF/wMfg4ePUCAj8p3o1AoGgeeitG3As7ZvT9vLaus3AkhxFQhxAEhxIG0tDQPmaUR7BNMTkmOQ1mQCt0oFIpGwg0zGCulXCSl7COl7NO0aVOP9h3mG0ZGYYZDWYDJQH6JEnqFQuH9eEroU4A2du9bW8sqK69Twv3CySxyjDwFmAzkqdCNQqFoBHhK6L8BHrHOvhkAZEspLwIbgVFCiFDrIOwoa1mdEuYbRkZRBlJeTWIWZDJwMj2fU+n5dW2OQqFQ1CnuTq9cDuwBOgshzgshHhdCPCmEeNLaZD1wEkgGFgNPAUgpM4F/APutrznWsjol3DecYnMxBWUFtrIAkwGA297aXtfmKBQKRZ1icKeRlHJiNfUS+EMldUuAJTU3zXOE+YUBkFGYQYAxAAB/H319mqRQKBR1xg0zGHs9CfcNB3CI02cVXN1hKrtA7TalUCi8l0Yh9OVefF5pnq0sq/CquJ/KUHF6hULhvTQKoS/PYGm/aOqvozvTq20TAM4ooVcoFF5MoxJ6+wyWbcL8+eDh3gBqhaxCofBqGq3Qw9WZN2qFrEKh8GYahdD7GrR9YysKvb+PHiGU0CsUCu+mUQl9xcRmQggCfAzkqSyWCoXCi2kUQm/UGTHoDE4ePUCgyUBesZpeqVAovJdGIfQAfno/iszOe8SqvPQKhcLbaTxCb/CrwqNXMXqFQuG9NBqh9zX4uhZ6lZdeoVB4OY1G6Cvz6LXBWCX0CoXCe2k0Qu9r8HWadQMqdKNQKLyfRiP0lcboVehGoVB4OY1G6Cvz6EP9fcguLKW4TM28USgU3kmjEfrKPPrfNAvEIlE7TSkUCq/F3R2mxgghfhFCJAshZrqo/6cQItH6+lUIkWVXZ7ar+8aTxtcEH50PJZYSp/JONwUC8GtqnlOdQqFQeAPV7jAlhNAD/wJGAueB/UKIb6SUR8vbSCn/ZNf+aSDOrotCKWWs50yuHT56H0rMzkIfFRGATsCB05mM69myHixTKBT1QWFiIldWfAF2e0kDYDQQ8eR0fFq3qh/DrgPubCXYD0iWUp4EEEKsAO4CjlbSfiIw2zPmeQ4fvQ+lZudUByaDnrtiW/HpnjM8fksU7cID6sE678FSWEjO9xuRJc431cBbBmFs5T3/PLVFWizkbtmCOfOKU51vdHf8unevB6saH5mf/ZucTZswNmt2tVBKSi9cwNShA+GPPVZvtnkad4S+FXDO7v15oL+rhkKIdkAUsNWu2FcIcQAoA96QUq6p5NipwFSAtm3bumFWzagsdAMwsV9bVv+UwtnMAiX010jO+g1cfPFFl3WBw4fT5l/v1rFF9Yc5L5/0999DFjqODZWmXiZvyxbXBxmN+Hbt6lTsFxND85dcX1dF7Sg+eZKAgQNou2iRrUxKSVKPGJc34YaMW5uD14AHgFVSSvspLO2klClCiPbAViHEISnliYoHSikXAYsA+vTpIyvWXysGnYEScwlSSoQQDnVNg0wApOUWe/ScBfv3c276U8hS5yeJ8GlTafrUUx493/Wg6Jdfyf76a6DCn0RvIOyRSRibN3coLjl3FvR6Omz+AXRXN2BPW7CA3E2bKD55Eipcf2OrVuh8fNyyR5rNnLrvPkpOnHSqM7ZoQfi0aQiD49daHxZK4KBBbvXvSfJ37SLz4yXoQkIQOsfhsNAHHyR82jSHMllSTPoHH1B2Oc2hvPTsWa6sWMFNM//m9Nnqk9KUFCwuntx8WrdGGI3X3L85O5uyzEynckNoKPomTa6pb2mxUHLqFAH9+jmUCyEwhIZSlplxTf1XR/7evZSlpTuVC5MPwaNGefx87nxrUoA2du9bW8tc8QDwB/sCKWWK9edJIcR2tPi9k9Bfb3z0PkgkZmnGIBw/dkSgJjK1FvqUeNjyD5COUzRzNqYhS0sImzTJoTzv/+0ma/kKQsaNAxxFz9CsqZPoybIyLr74IqWplx3PKyWl589jzs52MsnYqhWRK790W0ArI/Pjj8n+9lt0/n4O5Zb8AnR+vjR9+mmH8tKUCxibN8fYooVDedDwYWSvXs3JsXc4nSNozBhaL/inU7k5JwdzTq5DWdGRIxQfPUbw2LEYW149h5SS7LXfcPH5511+jvbr12NqH1X1h/Uwpee1B+EOWzajDwx065iWc+c6lWWtWsXFl16m9OJFfNq0cXHU9aM0JYUrX3wJFsfvdsmZM+T+sNnlMU3uv58Wf3/lms4rS0s5MXoM5qwspzpdUBAdd+5A5+vrVl9ZX68m+xvHeSCyrBRZVIRP+/ZO7fVhYS49ektJCfm7diFLnB03/359MYSFuWVP8cmTnH1ssss6fUREvQn9fqCjECIKTeAfAB6s2EgI0QUIBfbYlYUCBVLKYiFEBDAI+F9PGF5TfPSa4JWYSzDoHD92oMmAr1FHel7thL5w3Qekf3EIaQp2LE8pICAqnGbPPutQ7tt5DSnPPc+JESOd+gro3Z22n69y7Oenn8he+w2mLl3QBTiGlkxdu2Bs2dLhKaUsI5OcdevI3bgR/34uo2xO6Pz90AcFOZUX/bSLgJsKaTvU8d5+Yn1TinatByehT8HY0nlQO/C222j97jtYCh3XMlz5/HOKf/3Vqb05L4/jQ29DFhQ41Qk/P1q8+g90/v4O5U2feorSy443w9KUC5ybMoXCxEQnoU9b+A5Xli937t9opPW77+AXE+PY1+XLZK1ciSxzXGAnhCDkrrvwadfOobzkzFn0wYHoz+9wOgctYyHYvcF/YxstlFly9uw1C332t9+S/c23TuXC5EPzF190ukFn/uc/ZH68BGEyOR6g0xE6aZLTNcpes4ac778n8NbBjk9uFgvFySewFLvIIDtgIAH9HT3roqQkzFlZhP3+9w6hrOLjx8lYtIiiI0fw793b4ZiLL88id7PzzceclYVPu3bow8Mdz3vzzQTe4vykpw8LxeziSSJ79RouzXY9/Bhy1zhavvmmQ5ksKyPzk08x5zk7KwhB5Irl6IIdNUPo9VwPqhV6KWWZEGIGsBHQA0uklEeEEHOAA1LK8lvlA8AKKR2GsLsCHwohLGhTOd+wn61Tl/joNKEvtTjfjYUQRASaau3RX9mYQP5lE6ZunRzKTc2SCe3kPHc/qPkVWt2ciaVM5/DPUHDZSHb8Ec49/DvQX33UL72YDgYD7f79b/SB1Y8hyJIS8nbu5MJzf3X7MwgfH1ot/D/8eva8Wmg2U3LxCgFdfeCu9xza+x2cT96xk6Q91NmhvPiIjqABcVRE6PUEjRjhVF509ChX/vMfp5BayYkTyIICwiZPxtSxo8Mxpl8XoXvP+Ry6wGaYOo0B/dWwgY9FovP1IWvVSkovXbzaWEoyli7F1KEDfj2iHfrJXvcdl+bOJXDIEIfyvM1bKDp6FCqEYbBYKDpylBZvvO5QXJKUiNGQCSsmOtlKq97wxFbnchf4tNXEPX/HDrBYHOqMrVphcuGVXprzD3J/+MGpvCwjA2OLm5xCH0VHjpHTp4/TAGTxr8cxdelC+zWr3bJV3ySEc09M5fwfZrhu4OLaZS5ZSviUKQ7f+aKjmkxUDA+WXblCxqJFZCz+iPx9+2zlsrSUrFWr8O/XD9NvHK+HLiSEiClTnJykyjCEhVN4+JBTeeHBn9E3aULbTz9xKL/89tsU7D/g1D7vv//l8rx52v94hXBl0Ijhjv9r1xm3An5SyvXA+gplsyq8f8XFcbuBHtdgn8ew9+hd0TTIRHqe67pyCtZ/QubHi6gYr87/NY+gnm1p9fkXjgdsfxO2vw5fTHL4Q4sLPxHcswU885NDedDhzZQ+NZXS5ESnc4d3N6L3cy8MI3x8aLvoQ4qSfnGrPUDGRx9x/snpLut8W4dB3EMOZQH3FZA9Zz7p8c7t/YJS3T6vsVUrZHEx5owMDBERtvLik6cACL1/Aj6RkVcPKMyCg49Bm/7QtItdTxJO/hd2OD4wCiDwpibkJPxEYcJPjnUmH1q8+iq+nR1v0IZmzUhb8H8U/XzQ0ViDnpbD9YR0cPynvbwfMv77X44PvNnp8wW3K4OHvwZ/O2/y2Dew821Y8ZDDOAagfaZ2N2Mf0jNYLOiCAsn85FMyP/nUsb1OR/i0qQ5PN7K0lCvLl+PXuxemKEfR06cnEB62C73R8TucfLoZBeuW0aSV49+u+HAC/gPcH98IuOUW2n+3DkuRs+dubNkSQ2ioQ1nppUucnvgg6f/6l1N733bhGHc4OisGwL9DBHnbt5O3fbvjZwsJoeW8/3WcRVML9GFhmNPSyd+716G88KdEfLt3x7eT4/cl8OabSf3vDs4//bTD37P411/RN2lCx507PDJmcS3cOCM71xmjTrvQ9jNvio4eJf/HHwEYdfQcV/JLyTAcQ+fvT5Px450eo7KW/ovcYzn4NHEsNzYxEvqgYxwegC53QNI6SK8QmjD6w4CnnO7y+ugRtPtqAxTlOLa/mAjrn4WFvRy8VQBu6g73feLkKfm1b45fE+ewB3mpkOM8xBL4l9+SmxYKwrEfsfefBMW2dmofMvEJgif83rn/dX9GHFkFe5z/cQlrD76OnqTRqH3WvO3b8Ym6Glop2LcPjEaMrSucO+uM9nPgH6DbXY51UoJ09HixmGn5/iBapjmHhxAgvr0TNjp6ehFGP8JXzIbgCmGSzbMQOecgcrhDcXjuOoxt45DR9zu2/2U9gcWboP1QR0EPaQOnd0FGsmN7cwkcXevKTNrfcRNld33pMKQjLRYu/eNVMt7/wOkYXWAgrd5+G+NNNzlWfDQSijpB3ykOxX7HPiXn51R+fXqZU1++aetg4c4KRungN7dBaGQFWwWmrndCk9849eMKY/PmdNiy2Xkue95lmN8FzqWDb8jV8pJ82vY+B4v/HzSrMDtJCKdB7yo5uxf2f0xFx814JRVLQYHLOHrw2LFOZYFDBpO9YinFRxKc6sJHdUMcWORUTqs+0Na9sKonaDxCbxVIe4/+0muvUXhAc0mHWssuW0cYjPFvEtjWUVRLL6XjF9WayO9cxFxd0TwantxZfTt7mnZ2LmvVC66chtxLjuWFVzTv8MtJjv8MUsKxb6HEMTZYFUYg7JG1mijZk/oqhLj2kFzGE7veAT99AhtfcOu8Pjl64CYuvvSyU52pa1fnWSZXrELfpJ1Te+0RuYJNOj1i8nrnmy3ApUNwfr9z+YWfEGumOZcDjHgFbvmTQ5E+9yKhhVfgYcenHr7aBudaOHvtAeHw+CbX/V9OgoIKMz5+WY9xz7sYO7SAIEfhjvpqlcs1C8JgcD1DJ+cCRN0K/ac6FDd9+w58N25wElxRkEpI+AkwVRDQ/MvwowsBA4hfCv0c+6e0AI6tg2Ln76ToNBpG/t2x8FKidlP73VJoN9DBfjG/K6z/C4RXuJkENIXhs5yvd2XsfR9+WQ8hjs5EWNBF/O5tAREVbiQ6ge+dA6mIT8Ehovr/5FSucRg2rnIuFnqI6ORc7h8Gk9c7l18jjUboXcXoLdk5BA4ZQsu35vHetmQ+2HGCA8/05/SoURRfzCOwl+MAUUlJIQGd6i6uZkOnh9HOszEwl8F/7oOLPzvXNY+GW/7s/ATgEwARHR0994IMWBgHl485Cr2UUJCuCZO7dBoFL6SApUJGUItZ679C6Mz083IiLd9gufc/YLCbRSElPuFGuFghfHJeewIj1IXQV0ZgU+1VkchBwJPO5SX52g2gopepM2gho4o06wrxy6x/BzuXO/245r3XhGZdnMsspbDnXUhLchJ6odMh3Jx9gsUMuRddDgL7tG5F+ONTXBxUBSX5zn/n07tg5WPaE2hFmrSFFhUWyeenwf9bAMmbHb+T+emaGLao8P8W3BJ6TICzexyfTMuKtL66jdPGP9zh8lHoMBIm/sehWBxbh/+ml8BS4buXcxESm0C7Xo7llw5rtv/lVzC4EV4tLYId87Sn64rYO2wepPEIvTVGb7861pKfj75JCPqgIJo0CyPfcIHc4DAMfhaKZTu4/zNbW1lSQtkrsRijXNyF6wu9ASa5N0hWJaZg8AvThMSe4lxNmP0jXB9XGT6VDHpFuor1SvwOfgHbxuM41dRFGKYc/wjwC3Vd5wl8ApyfbKripmjNY/3wVue6Xo9cuz3lYxE739JCgeVIizYukem8poCACHhyFwTaPY3lpWpTgN2c7VMtrv7OXe6Av56EMhcTG/xCnb3tsmLY9DJknXUsD26lPcn6OM6sAmD8YueyrHOwIBpSEpyFvrRQeyK2x1IGGSecw38AXX+rvSryn/vh3I/O5ZePQthvXDsTrvANgTvecq+th2g8Qm/16O1j9JbcbHQZh2Hji9ySns+LhlQM36/DFFJC9oFz5MTazeyQEqTEWMfzmOsEITQxObIG7GPZZus/a0ANhb4mRA2BUa9qg6wVCWoOQS2cyys+stc3Pe7TwgauBvrbOQ/Q1pjAm6DdIC3UdKnCbJDA5nDz09rTRjnmEti9EFZPg2bdrpbnWxdiBV/nNBSmIO3lDgYTjPXAjOuQ1tp12vk2HP7asS79F+dwWDnNY1yXu6JNP/j1e3jVcZEgZUXQ9c6a2VvHNBqhdxWjN+fno8s4CPGJtLVIJurN+Cbr8esXiCnod+DrOMdVZzIRNHxYndpdZ/R9XAs/2KPz1x5tI2+5fufV6TWhasgYfLSQ1fVCiJrHbfPTtfGbih5oUAtofkNMhPMsQmihSvsnnnJa99WEuOITiMEPOjhP+a2UuEegpMD1DT1mQs3srWMaj9DrHIXeUlICFtC16AQvbCElo4Bb521j3p0x3NenDX5VdeaN9Pid9lJ4B/e8r70aEwOe1F7Xi8CmMNx50kBDoNFsPGKL0VsHYy352kYjOn/tLt8kQLsRZBc6L6hSKBSKhkzjEfoKMXpLvjbHXGddaRroY0AnlNArFArvo/EIfYVZNxZr/gldoBaH1+kEQb5GJfQKhcLraDRC7xSjz9JShOqCrg64hvgpoVcoFN5H4xF6vWMKBEt2udBfXaCghF6hUHgjjWLWTdEvv1B26CduPWQhOC+BrCQ/ivbvAkAXfHXhTYifkRwl9AqFwstoFEKf8pe/UJJ8Ai1x6jouYp1rq5MYml9dkBPsZ+BitnNaYYVCoWjINAqhlwWFBI0cyTNd47m51c080+sZOLMb3XfTMDS7uhxcC92UVdGTQqFQNDwah9CXFKDLP4VfqJGkwp/wSf63tizaJB2WagdbQzfHU3O5UlBKvyj3tgZTKBSKG5nGIfQFWYjUFNpmGkgwmSDpDa3CP9wh70frUH9KzBZG/lNLQ3z6Def9TRUKhaKh4dasGyHEGCHEL0KIZCHETBf1jwkh0oQQidbXFLu6R4UQx62vRz1pvNtYQDTtRNtBz3HRaKTk5TR4JVvLsud3dSOMQb+pQTpehUKhaCBU69ELIfTAv4CRwHlgvxDiGxd7v34hpZxR4dgwYDbQB20bl3jrsc5brF9HpJSg1xHhH4FEklWcRTN/5800oiICaBniy4Vs523QFAqFoqHijkffD0iWUp6UUpYAKwAXSZxdMhr4QUqZaRX3H4AxtTP1GrBouyH56rUNGorKXAu5EIJBHa6m5LVYpMt2CoVC0ZBwR+hbAefs3p+3llVkvBDioBBilRCiPGm7u8cihJgqhDgghDiQlpbmhlnuIy2AXo+fQctJWVhW+RTKwZ2ubh5QWGr2qB0KhUJRH3hqZey3QKSUMgbNa/+kph1IKRdJKftIKfs0bermTi1udw5Cp8ekNwFQZK48NDM2ujm3WL36/GI11VKhUDR83BH6FMB+W6XW1jIbUsoMKWX53mEfAb3dPbYukBIw6PA1VB26ATDodfyut7ZZcJ4Sepek57nYJk6hUNywuCP0+4GOQogoIYQP8ADwjX0DIYT9fm/jgGPW3zcCo4QQoUKIUGCUtazOkFKCFAi9wRa6qUroAQJM2hh1QYkK3VTkm58v0OfVzcSfyaxvUxQKhZtUK/RSyjJgBppAHwO+lFIeEULMEUKMszZ7RghxRAjxM/AM8Jj12EzgH2g3i/3AHGtZ3WHWxNp+MHbG1hkkX0mu9JAAH20DY+XRO/PjKW3vzaMXcurZEoVC4S5uxeillOullJ2klL+RUs61dc8yDgAAIABJREFUls2SUn5j/f15KWV3KWVPKeVtUsoku2OXSCk7WF9Lr8/HqML2UmuSMr3eFroBWJ60vNJjyj36BxbtpdRsua72NTQEAgA1IUmhaDh4f5riUi0tsTAYHITeoKt8CUGASW/7fXVCCp/uOX29rGtwCE3ntZCYQqFoEHh9CgRZZh041F2dXgnVCf3Vur9+dRCARwZGXhf7Gho6oTx6haKh4fUevSzRhF4YDLbplVC10AeanOvU4ilH1NVQKBoOXi/0lF4V+qrE3Z4gXyNvju/hUJarBmYBFbpRKBoiXi/0suzqYKw9BaUFVR53d5zjAt7sArXzFFwdjFUoFA0Hrxd6e4/enoKyqoXeZHC8MWQVlnjWrgbKVY++fu1QXH9KytSMM2/B64VeWmfdYN0cvJzqPPqKZCmPHgBdudCrKL1Xs+nIJTq9tIFjF9V6CW/A64WesqvTK+3JL82v9tBtzw7l8yn9AchSm4YDWoZPULNuvJ0txy4DkHguq54tUXgCrxf68gVT5UL/1bivaBXYqtrQDWj56TvdpG01mJZbTJmLxVMFJWVEzvyOVfHnPWh19ZSaLczbmER2Hd+AyiP0KnTj3eisymBRf2ivoBEIvTV0YxX6TqGd6BLWxS2PHrQNwwH+se4ov/tgj1P95RxtDGDhluO1tvFf25K5/0Pnvqtiw+FL/GvbCd78Pqn6xh6k3KM3W2oevz1/pUClTmggqCc378Lrhf5q6OZqjN7f4F9lTnp7fAw6WjXRFlq5eowtH5y8Fs9n3sZf2HcqE3MN/qtKrQNlRfWUeK3EXPPPe8ub2xi7cOd1sObakFKy6cglt9ZKSCnZlnTZNr3UbJEun/Sq6+PzfWcorIe/nbuZR3VqGq1X4fVCL8vKPfqrQh9sCiarOMvtL3FURECldeUzEzzx/1CT9L+22S/XftoaUe7J30g5gApKysgtqn0IK/FcFlM/i2fzsVT++2vVm96sjD/P5GX7WXlAC9VN+yyeDi9uqNH5dh5P58XVh5m7vuJunNeX7w9fpM+rmzlwuvq8gracRg3EpT+bUUCR3UZBBSVlKimhHV4v9JRqf2x7j75VYCvyS/O5Uuze1rWv36stnjIZtMuVU1RKr3/8wO7kdIqtQl8Tb9wee4FKyXLvKQNqtnApNaeIvnM3czw1t8b22XP0Qo7t85beQFPvbv3f7fR4ZVOtj88p0r4jUz+L59ElP3IyLa/StheztBTXZzK10N/mY6k1Pl/509+ZjJrN/LpW9pzQMo8eSsmutq3O9qR6PS3yDBaL5NZ52/jD5wm2sjELdhI9u04zot/QeL3QS7NVSO1m3bQNagvAudxzrg5xok2YP8+O6kRxmYXiMjNHL+SQmV/CvE2/UFymeRG1Dd2cSr86VnChJkJv9bjcOev3hy+RllvMst2na2jdVZIv5zF24U4+3XMGuDaPvqpQh8UiHTwzd7jWjVAqhlCq8gQNeu26l1mkw3E1CXHorSqaW3Tjepw6nfvfr/qmwPp92ZJ02VZ2NlO7idb1ZIUbFe8XetuCKR9bWZsgbdOrszln3e4nNEA7/kp+qU2ILBKKS62hm1ral5l/dSFWudD/mprL7f+3063VuO7oS/nTRnlCstqQlusopqXX4OrlF1cu5J/vO8Ot/7utVk9ItY0n1+TGYtBdDWkcv/z/2zvv+CiK/o+/J7l0kpCQ0FuAIL2GIkWKIEVBbBSx8aDyKCr+bCiPvT2oiKhYEFQQUfoDCCi9SUkIEEIPKUASCElIr3e5m98fe7t3m7uEICAa7/N65ZXb2dnZmd3Zb5/v2DSk0ivQcEqsc+bPNi2oT6cqs0AVJK7U/3AjUFTJc4xMvPQn9uSvi2pP6ClTwyvtTDf+DRAIknKTqtxMsK9C6LMKjWQWWImzlJRYJfo/QmTMFqmTONQInk82xXHiQh47T1dsL74SiVrVNtyuYfaCqzHdFBgdP8wSk5lVh1I5e6mI9PxSUrKrZtawJ0R5JWXsjMtgcVTVGTg4bgJf2YpQVRovs0iy7RjxlThW1fvdqD2JjVWYO+pcUZnSXxnOGKaPh7Ky/UJu5bvJ3Ug0e2Udjy7Y/6fcq0qEXggxVAhxSggRL4R42cn554QQx4UQsUKILUKIJnbnzEKIGOvfmvLXXm9ouW7sCL2XuxcdQjvwe+rvVW5HlegzCko1U4FZSk2iv1IBdFHkWZpPW6+ZU3w93TXpXuUZqgD+9i/HeWBepO56VYKsym01if4qKH1ROeJ8NaabAicmi6+2J/DskhhWHz4PQGJG1cJfNaYLdHxrIw99F8XLK49cUX/KE+nKtpAss9iibeyZdNEVaAXF1mfp7DlcDxjLLDz98yFOX1R8D1UxGanjVAUZe5SYzDpN9EbD/n2pPi+VIef9hU03FgmbT6RfvuI1wGUJvRDCHfgCGAa0AcYJIdqUq3YIiJBSdgCWAx/anSuWUnay/o3kz0aZ1RnroU+BMKjxIE5knWDT2U18uP9Dskoqj0RoUNMHNwH/XniA73crmkBhqVkjuFdqo1ejNg6dU0I2w0L8uFTu41GJ6Xe7k/g9PlO5j0VisUgboa/CfdUPu6KqS/af4801xyqVSstLTaY/EF5ZUVsWi9TKVBNRQiUOUXucz3Xu17gS0095ib78se6c9RmZzBZyi4x25VUn2mob+aVlVxW+mFVoZFclWp+Kg+ey+eXwefZazRhVIfSq1F/qRKJ/6Lsouryz6Qp7e/1grxn1nr4VsPU/7yqisaoTqiLRdwfipZSJUkojsBi4076ClHKblFLVtfcBDa9tN/84bBK9p668W91uAEzbNY2Fxxfy/dHKdzlsFOzLumf6El6nBhetJpakzEKeXRIDXFkYmsUiibOLgPH3NhDq72WT6K1yem6RSRe7X2a28OgP0TSbtl7bu7Uqd1UlT2cqrpSSqSuOMH/PGQ6eqzgKqTxxqIr6bw/751NQWkZ2oVFzRL+0IpZvf9eb0RKsEn1GfikPfxdFer6igsem5OhMM9MqkN4vWbWu+PR8/r3wQKV2+NJy5yqrazO7mPUSvdHM1pMXeW5pTIXX2tqwPbu0PJtpQUrJxxtPcfaSc20mPb+Ek2l5GnNYtO8sD38XddnQ0vLaV1WIn7ZOw4lEH5WkCEXX2/SUW2Qiv8TE5EUHK3wmAIV2TDavpAyT2aKZ3/KKK+/jd78nOSziW7jvLGGvrMNsUdZX3Prx9itK8JZp1fqX7K/YhGgviBxNzb3uayqqQugbAPbhKSnWsoowEbAPLPYWQkQLIfYJIUb9gT5eFaQTGz0oK2S93L0oMSsfWk7p5XN6tK4XwIf3dnB67kpMN/P3nNGpmzV9PQj289QIvdpWdpGJUV/s1uplFhjZao0s2HDMGtZXyX0z8ktJyizUPuzlB1KITy9gT0Im76w9TmmZmanWHbSU9kuZseGUls4hLbeE0XP2kpBR4ESit5CWW8KoL3ZzMe/ydlB7glFYWsawT3cxYMZ2pJRO00eoIY7zfk9kR1wGS6KUKThy9m7NNCOlJDGjkOahjusc0q2awa7Tmfx2LI1jFazILTNbHCIzKjPdqB9kQWmZA6H/1/xoVh5M1ZhMhW3YMZIjKbZQx4SMQj7fGs/Kg6lOr3t2cQxDZ+3iqZ8OAcr7skhIznLUamJTcjh+Po9io9lBKleZtsUimfa/Ixw468jgK5PoVSTb+VFU81BcuRBei0XS9OV1fL0jocJ2nEFKSce3N9Lz/S2sO3KBN9cc084dPJdN05fXcdQaJlreuV9kd3w6PZ8piw85ZYZmi+Tttce5/XNlEd/a2POcSsvn/XUnkFIRkP794wESMgrJcPJOEzMK2F9uTcLJtDwi3t1MxLubmbriiC6qzh72c+COz3/nyUUHLvdIrgrX1BkrhHgAiAA+situIqWMAO4HZgkhmldw7eNWhhCdkXF5dbTK0Ew3eonew92DtrXaasdVXSnbqm4AkdNuZeeLA3TlBaVlDPx4O1MWH9LKCkvLWHEgxUE9/3J7PAD1A5U9bGv6eFLLz5NLhcpkUu2KieUmSZoTglqZrXzAjO0MmLFdR5AGzdzBYwui+fb3JB76Noql0TYie+BsNrO3xfPCssMAvLHmKFFJWWw9ke5gTzaZLSzcd4aY5Bx6vL+F7afS2XU6A5PZQonJzEvLD+scqvYSS0FJmTaWuIvOTTTq2LOsNvhAXz2jPpWWT5HRjNFs4e4uDRnVqb7uvMp8VObpzBRUYjLT6e1NLLCGjDrrq/3zNZktnLWG7RWU6Al9sdGMv7cSwnsyTSF2r6x01FTU+4JiRz5qZUCzt55m0Mwd2thTsotYG3ue99Yd16Q/lVmtO3KBc5eKtER7aiihitwiEyNn72b4Z7sYNHMHH27Qp8lQiV58RgE/RZ7T3jcoc7agtEyTYJ1J9CrO2a0DOJmWxy+HzztoNKqQ8fHGUxW24wwqsy20/jda59XQWTt5ffVRADYev6j12R72Ev7BczmsjjnPzrhMh3uo35n6eT710yGGzNqphdDO2hynCV3O/CkvLY/lvq/38rNVwzxwNpuhs/QrvyvSesqXbzuVoWNe1xpVIfSpQCO744bWMh2EEIOA/wAjpZQa+5NSplr/JwLbgc7ObiKl/EZKGSGljAgNDa3yAC4HaSX05U03AL3q99J+V5XQA9QJ8KZxLV+2Pt9PV56YUcim47YFNK+tOsrzyw6z9WQ6b/9ynE3HL2K2SLIKjTw9sAWdmwQBqkTvRYnJQpGxTEuJ/IvVManisJMUDJcKjfx29AJSKkvxd8dnEp+ezxfb4jUpvHyKZfXjiUzSSyM/RSoTNqSGJ1JKbZWoEE5s9GWSYqONCD7y/X4e/DaKp386xNtrj7M0OoUZG2wft72UbJ/bf9PxNIcxgaKN5JWYNEJdXsoeMmsn0VZJNKSGJ7PGdqZjo5p0DwsGYOKCaEpMZs3v8dLyWDq/rV9UlZhR6NScVWwyc+hcNkdTcwn/z6+axvHGmmPstD6TfKtErzrMi4xm6gQojHv8vEhmbz3Nz1HJvLP2OF/vSOBwcg5d3tnE80sPU2QsI9jPk3qB3iRnFVFYWsaMjXF2/Sqg74fbeOqnQ8zdlcSkhdGkZBeRW2xidIRiFX19zVHt2STbEXqzRZGEVaTmFDswU9WcoUqjoTVsW2z2/O8WOry5QWNwpSYLxUYzH288pTEoX08lokVlMD/uO6stwsouNDHTbn2J2keDW8WkZvPxi9z+2S7tGnCMfy8zS+LTCziZls/RVIXhfbblNFtPXnRwvjtLKb40OtmhTb1GZpsHHu5KX3+wEwCcxeOrwspHG04hpeTZJYcc6lTkDK6IAVyv5IhV2VtvPxAuhAhDIfBjUaRzDUKIzsAcYKiUMt2uPAgoklKWCiFCgN7oHbXXH2bnphuA+1vfz7FLx4jNiKWkzCYtF5cV031Rd57r+hwT2k2osOl6gT66Y0+DG0VGMy8uO8yrd7TRCOnEBdGA4lTd8/JALBJq+3tpRKhhkA+h/srHNuqL3RVKuW/Yqa8qDpzN5sDZbFZN7s3ZS4VMWexoI67KSsiQGp5aBIunuxsJGYVaaF1uscnBRh91JosAH8fp89sxG+FeFXOehkG+vDDkJp3d+9ejtjqLIs9R299LM7WA8hyNZRaSMgq18LjsIqMDUT5pzZVe0xr6unpyb8rMFi0lwfmcYk0jUNowUWa28MnmOMb3aMKZCuy+RcYy7vpyj3a8NvY8py/ma4wQFLNJoI+BegHenM8tochYpgtftSfc03+1SdQrDqbg4+FOsJ8n9Wv68L9DqfzvkF5uSswo1DnON59I10I5B7aqw9aTGWw/ZdN67SX6y5mNwGbWOnhWERxUTQRsZh3V2V9aZmberkQ+3xpPDS8Dj9/STKt7Ma+EgtIyXl11VCtLzSnms63xNAr2ZXj7ery4XDENGiqJ+Hph+WFyikwcOJtN/UAffoo6x8iOeg0tu8hIdpFjpM+/5kdrv4VQpHNnK8x3xGXw1ppjzBzTSSuzTz1+yW6eOIsoGj1nL6sn96Zjo5q2663vJKvQSKHRjK+H4/eQU2wis6CUGl4GcotNnErL55aWoRWaB708rk/E+2VblVKWAU8BG4ATwFIp5TEhxNtCCDWK5iOgBrCsXBhlayBaCHEY2AZMl1L+qQk+NInew1Gi9/f057OBn9GqVitNoi81l5JRpHxEC48vrLRt73Iv5Z4uiuti2YEUnvrpoMMiI4Be1qiAUH8vkqwOx94tQmhZpwZQsSnjctiXeKlC6aGyCJQZ93Vk6/P9qF/TxrQuFRrZk2BTdXOLTWQVOo6lKqFhs7fFc+JCnjaxuzcN1iKNQIlzfrBnE74a34X7uirSqmrSupBbrElN2YVGB8eraiMO8rW9W4O7Gz9OVPYQWBd7Qcd4APYkXOKLbQmM+mI3T9otmbfHxmP6tAYe7m7M2ZmoK1P9H+pzW3kwlbiLBYzr3phPx3bCGYRQGGqxyYy3hy1ZHtikZHAe9aPa0cNC/FjzVG/dudUxqWywjtOZec8e7m6CzIJSSkxmzZxVPtpLHR8oPg6VMf/315N8vDFOe5e5xaYKTQ1SKiZKtd/u7hUTepXR7IzLZMqSGL7ZmegQGHAms0j3bdzcrJZDO5+NVYwFqRWswVCfzcqDKeyJzyTHjnFUtLq6mZ3/Z1GkTcJXc+moebByi014e7o7XJ+WW8KtH++g53+3cPeXe3jouyjySkwVLpbzdL9BhB5ASrleStlSStlcSvmetex1KeUa6+9BUso65cMopZR7pJTtpZQdrf+/vS6jqKzvmo3eq8I6Pu4+GqGP+DGCCb8pUvzl9kcVditNX7itJQNuqq0d7zqdqYtMaRzsq7s21N+bCb2b4unuRt/wUMJr+2vnPrynA8feGsLhN27TVPUXh9xUaV+m/3pSc9TW9ncc67yHImhRu4Z23CMsmPE9GnN7+3o0C61BiJ36Xlpm4fXVx2hQ04emtXxZF3uBbaf+uN9k2Ke7+NSaxjmiaZDD+ckDWjCsfT3aNwy09l8h9OeyijTpKrvIxK7TGTrpMz5d+fCDytnvawcoY/l4UxzloToL050wYRWn0/XM1t4cZ4+LeaVENFVMRWroYrCfB31ahODr6U6jYL3GJyXc0lIxS3oZ3AmwjuWZW8PZ+/KtFfZHhZ+nO81D/agX6E1NuzHnlZQxaaHizEvN1kuz5QXpVnWVedbqtd80Iq36huwXn6l+BoDjdrtMfWH1L4Ei0dozbXtkFRmJTLSZBlWJPjYlh74fbuXEhTxiU3K4+b9bNGeyauICeG/dCV2fjWaLLhX4GyPbMHmA3t2nMvxk6zOoY50H6uIps0WSlFnIc0sPc/+8SA4n25iUGklXHvbMuMRkYd6uRBbuO6stblS/qZwiI5nWOXV7h3pse6E/AL/Enie32EROkUnTNA6dy3FYl6LiesX9V/+VsWardOTEdKPCx6AQejWWPr3YKqlewfqipwaGa+YXFSM61uf5wS15bnBLlk66WXeutr8Xt7WtS9x7wwj08cDHThoY3a0Rfl4GAn086NU8BIDOjWtyd5cGjOve2OHek/op6vS2UwohjPrPIAa1rqOrc3PzWsx7KAJPa2K2mr4evHdXe+2+zjJ0tqkfQKCvJ5cKjdT29+K5wS0BaBbix011/B3qq/i/QS0dylQmdGu5foFtIVcNL4Xw1bASwPfX20weCRkFZBeZeOhmbS0e8emF1rHotTVnjE7FPjvi4+nuxoz7OlZYtyro2SxYd1xmkdSq4UXM67ex88UBfDW+C1NuDQcgvHYNbglXCP3xC3mYrfaZ5qF+BPp6cHfnBg7MAaBt/QAAAnw8MLi7IYTQCLY94tMLeKKcltI9LFhLxgdKMIF9X4WwObw/2xqvu9aeqaqwNyllFpTy476zDnVA8fdE20XzZBYYeXlFLAv3niU5q5hhn+5i5OzdmmkuoNy97FNKTLk1nGYhfpqdfMZ9HWlVN4CBrWyC1YiO9QnyU77xb39PwtfTnWWTerH26T7smjqAHmHBnE4v0GmFP0XZ+n7KytgetptfAPWs2iUodvV3153gtVVHNUEh3Ero7/5yD6k5xTw1oAVf3N+FsBA/PA1uThnh/N1J7Drt6BwGdKutryWqPaHXwiudmG5U+Bh8SC1Ipd8SvXPVTVT+eGbsn4HB3zZx7KXiyGm38tnYTjx9azjP3BpO3UBv5k/opp0vzxQAFk7szs+P9dSVjercgB0v9qdX8xBmju7E1KGOkv0jvZpq7dWyruDt08Km2s55sCt+XgaahvgR+cqtNAr2YfKAFro22jcIdGj3hdtu0uKpJ/QO0yTu/NIyyqfNsXdMq4ynPJqH+tGlcU2n58BG6MubmtzdhLZStmsTm0agqts1y0n06mYxKuwJgn22yQ/ubc+9Xau25OPV21vzyRiFKTSt5UtIDS98Pd3p3DhIM7sB+FvH4GlQCPKw9vX4v8Et2fJ8P358tAfD29cDoFGwD1NubcmkW5oxrJ1SNnNMJ4dorjoBXvzyVB/u79FYF9p7V2fHCOdJC6MdylrXC6Cd3bstzyB6hAVTaDQTlZTlsHlO7+Yhumdnj1p+nhw8l0NqTjFTh7ZyOH8uq0iTpFUs3p/MsgqcjT2dmGIA3r+rPUPb1aWpVRBpFuKnvbPOjYK0ss/HddZpxW+OaEvjWr60axBISA0v+oaHkFVoZG/iJfqGh9C+QaBOiv9im8LkWtezMULQmwVj7cxUS/Yr4b7qs1UZk73ApEYuvXZHG933su1UBt/vPqO7j8pQnPkhrgWq4oz9+6DMyUNSNx7xrFjK8zZ4Oy13uwwfXHB8AT4NIf/EdMBGvPuGh2gRGPZoHqoQhLAQP7w9HO15fcOdRxs1qWWbPAHeHhjchLZEHRRTR1gtPzLySwm2EvqHezUlLLQGt4SH6ExMQX6e7HppoMM9WtVTPpKavh7kFJn46dEe3FTXX0vcdXNz24eYX2LCo5xNoFloDbqHBROVlKUb26N9wvDzMtAs1I/w2v4IIbizU33chODspUIe7tVUq6tqG+UJ/ZRbw5lpNcO0rOPPJ2M68tzSw0ipEEyPcnZN+/F+90gEA1vV4fvdSbz1i809VMPLoGkXNzerRfuGgaTnlbAqRh/ppKJeoA+3d6jHLeGheHu442Vwo8wi8fZwZ9m/e7EjLoNAHw8HCV+F+u4Bdr88EIObINTfi1eGt3boe/1AxcEbFuLHVw90wc1N8P5d7XX17uuqBMJ5Gdy1RXsJTtJG3FTHnwd6NuHRBdEkZRbSul4Ad3dpQKu6/tQN9EFKyb7ELJ752TFixNPgRut6AZo2Zo/uYcGa7X54+7raTmfT727PyoOpRJ3JolmoH2m5JU59AG+OaMPO05la288OaqmFS9pjXPdGCCFoUksxfdqbH93cBHteHqjNN0+DGyE1vMgsKOW2tnrNcWCrOpqDfMGE7mQUlNLj/S2AYk7bGZdBSA1PGgbpTayq8AH6xH4rDqYwqV8znXNWfS7l8UDPxszblUhGfikf3deB/1tyWHfeo+Y+Cuqtom/d2eQUXB+JvnoR+g+agEnviJEn/YBA8HBOzEGR6FXU9q1NepEy+cyy4hhii7SplqoU5u3hzurJvWluNxnt0SjYl0/HdqJfyz8ePurmJoh/fzhNX14HwDuj2uHuJmga4kvUmSxqeCvSrBDiiu7TsrY/T/Rvzj1dGtI81E8jlhFNgtmbeIm29QO07JolJgs9m9di5cFUtr/QX8uK+cO/ujtEE7ww5CYHpvbpWKcRtloIXpnFwqwxnTQCdl9EQ/7VJ4z9SVk0DPKlYZAvy6JT2JNwiSFt6jpt6+0721JkNNO/pSKR3mL3LOLeHUZusYkA67P6+XGbFjVrbGft2UZOu1UjBnWtElctO63NYB1WoI+HQ5RIZbC3+zrD3Icj+L8lMXz3SDcHwqPCzU0wpptixjOaLby03LbwbceL/VkUeY5Gwb6M7FQfX08DHRsGkpRZSE1fD2aOtjmLi4xl1PAykFFQSovaNYhPLyDA20BeSRke7m5M6teMkZ3qsydB2SwFFI1GHUMtP0+d/2ls98bsP5NN1JksGtT0YeHEHoyZs1fn9xjYqjaP9A7jkd5h2rNuXc+fHS/2p99H23XjFOVUx3blNM/65Z7liidu5vTFAgdzXpv6AfRpEULHRoG4uQnqBHjzy1N9iLuYz6XCUnbGZdC0lh9+Xvq5qpoRg3w9eO2ONjy31EaknxkY7rBesWGQrT8zR3e0CgXutKzjT6MgX+7q3JDU7GJdVFbNensoAXy8i0hKr1ggvRpUK0Kfdr6PLcrGitK8S0AGwsv5BwM2ib6uX11WjFxB75+VqIZ8Y8UbddjvOdu4lq1tew6fXpROoFcgXu62l3dnp8oWFV85Huyp2BQHt6nL0ugUB1tnVeHmJpyq4HMe6sqlAiMe7m5aYjdQVOon+jXXVGpQGJ1K1D8f15kVB1Ocai4VQQ3XrO3vzajODfDxdGf21nhCa3hhcHdjgJ0Z4b272jNnR4JOI7DHQzfry+3tzZ4GN6emMxVeBjdKyyw6rczeVnu90bZ+IBv/r9/lK1pR3l/SpJYf08ppCqovRmVuKnw9Dcwc3REPgxu3hIcSm5LD7K3xbDmZjqfBDW8Pd8JC/AgL8SM5q5ivdyTQvmFNAqzmsVb1/B2I8d1dGrDiYApe1jDSdg0COZ1ewOrJvfHxdNc9157NgknMKEQIQcMgX7qHBTPplmZ0bhyki11/+OamxKcXaPO9IjSp5afTgO3x46M9dMftGwbSvmGglsq4bf0AWtcLoGuTIM5lFZGRX4qfl4FDrw3G4C7w9/bA39uDx36Ipk6AF35eBt1iyI3/d4vuWdzdxWYWnDm6o8YUOjWymR/j3xvGnau/5Fw+NAv1QZqcC4lXi2pF6AtOZmMpcQwv8+ncGeFV8YetxtDf1eIuAjwDaBkRuaL6AAAahElEQVTUkrjsOIrKijCajexP20+r4FbU8rGZLwqMlYdBlppLGbV6FGNuGsNj7R/D16NiRvNHsO6ZPngZbER0cJs6LH68p6bilkd2STaZxZmEB4Vf0X0CvD004uBvp8Z6e7gTXolDdkTH+oy4AikXFD/BR/d2YEg7RUof0rYuQ9o6l9jDQvyYfo/zdBTOUJ7AVYbNz/XTlq63rFODuIsFlTKGG41gOwZcvwKG5GON8Xa29uE2u2fcuXEQXZsGseVkOkPKmT+GtK1D3MV83hzRhtlWm7YaaTY6oqG2EK9X81q8M6odg1or594Y0YZezWvRoWGgA1Ow90m5uwld0IL9uJqG+LFwop5QXyt0Dwvmi/u7MLBVbbw93FnxRC+eX3qYFQdTMFukTsBR/UHdwxRaYD+elpV8D/aaoOpw79Y0CIO7m5bbaljHIDoOurrggIpQrQh9iy2b/9B1qnTu56FIAotvX8yms5uYumsqXx/+mrlH5tIyqCUrRq7Qrsk3Vb4t3+H0w+Qb85l3ZB6LTiwianxUhXWT85NJK0zTEq1VBW3rOzpPyzu0TBYTw1YM44WIF3hz75sUmgo58vCVpfC1hzqp7R2i1xJCCO6LaHT5in8A9pEnl0OjYF8aWc0RPz7ag7i0Agc/wLXErpRddKvbrUJfkT22nNtCnwZ9dFqiyoRGRzTk1TvKJ5ZV4O9twN1N6GzOFeHRPs0Y262xjtCCwgS+e0SZow/f3JRio5kHrBL2h/faCJQQgtHd6lo39gmnpq9nhe+1POG/ERBCcHuHeroylSGWX8HatXEQb4xoo3Piz30owiF8ujI0Dvbl/bvaO/gR7K0E1xrVPuqmKjBZFBUxwFPxuHu4ezCoySAMwsDcI3MBiMuOo/2C9nRf1B0p5WUl+n0X9mm/L5de4c5Vd/KvDf+6miE4xfmC81wsusiLO1/UJlFl5qiq4OBrg1n06B+TrCzSwht73iAmPQaz5fpm61ORW5rL4pOLAXiif3N++Ff3K7q+tr83fcJDruiaVfGrWHRiUZXqnsw6yZNbnuSj/R9dtm5MegzPbnuWWQdm6cq9Pdw59tYQpt/doULN5YGeTZg/oRuGKjAsT4ObA5Evj6ZWjcrNzew0xfdbe97i7jV3k1t6fXK3XG88NaAFw9rV1ZzeKtzcBBN6h+Fv95wHt6nDTU7CXSuCEIL7ezTWRekBFJmu3x7CLkIPPNHxCUa3HM2wsGFamae7J9/c9o1D3eKyYlILUnUE01lO8ag0vQRfZFLMQEazLQLBaDYipdQYzbX+KJxtlZha4JgZUUpJXLbj4iJnCPbzvCK7uz0yizNZeXolD/76IE9uefKKro1Oi+aeNffoUlVUBZ8e/JT3It9j7/m9TB3aSueUvV54bfdrTI+aXqW6atbUpLzL73aWXZJdYV0/L0OlG8uE+ntVGNV1NXh++/P0W9IPKSU7U3by703/xiIt7EpVknulFaYxbdc09qdd252U9qTuYX3iel1Zbmkuj254lMTcxAquqjpq1fDiqwe6OiTTqwzJ+cmYzFceNaPSD5dEf51Ry6cWr938moPq3K1uN1aPWs2cQXOY0mWKVj5s5TAScm1pV49kHuE/v/+HDWeUXecvFV/iaOZRXVtTd02l7+K+9P65N/esuYct57YwYOkAlp9ertVJya88oZGUkpj0GG1iHM08ysO/PsySk0sYsnwIj298nKgLCoMxmU1Ot0qMzYh1kMAWn1rMPWvuYX/afvKN+ToN5GjmURYcW0BJWclVSxwqoQLYc17JJXMm9wwv7niRW5fdyoo4xTT2S8IvHMvU5/WZHjWduOw4EnIqTne7On410Wn6WHI1OupU9pVlTwTlw7vvl/u0vuQZ88gqybpmDLnUXKoxrouFF5m0aRI5JRWny7ZPpV1kKmLYimHsTNn5h+49+9BsVsevBhQC+fmhzyu9d0XYnrIdgA4/dGDylsnsPr+bfRf2aX09knmEXxJ/YfKWyZW2k16UzqMbHtXSj1SGc3nnmLR5ElN3TdUJWb8m/UpkWiRzY+de8TiuFqeyTjF85XAWHF+glb25500+OfDJZa9VbfQuQn8D0SywGb0a9KJhDf3CGvsXOH79eNYkrOGFHS8wYOkA+i/tj1maCfa2xdRuT95O+5D23NH8Ds7mneX57c+TZ8zjl4RftDrJ+ba0/wXGAp7c/CRv7HmDnSk72Z68nU1nN/Hgrw/yUfRHjPjfCMatG8fB9IO8G/ku5wvPs/fCXiZunAjAiFUj+CjaZg7wNSg2xHf2vUP/Jf0BhXAtOLaAr2K+AhRTT6+fezF+/Xjtunf2vcOM6Bl0W9SNvov76j6s8oxn67mtTI+ajsliYt6ReTrCDjgwmDJLGVN3TeW3M7+RXpTOm3vfxGQxMe33aYxdN1ZX1+Cm2Eyd+UY2ntnIohOLeHX3q0zYMIF8Y75GANXrtp7b6mBu25+2ny9jvuTj6I914bIqYtJjOJl1kpkHZpJZnMntK2+n35J+9FnchwXHFpBvzNdCcVWcyT2j/VaJeGJOIjOjZ2KymDSNTkpJxI8RPLf9OQDO5Z9jz/k9rE5QiG/5/qQXpXMi64R2bVx2HCkFKbyy6xWHfqcXpfPh/g8dmJ495sTO4dXdrwLw5JYn+Sb2G7Ylb6vQJGmRFqbunKozSVaESZsmab8jLyhbYNqHMJeUlVBcVqwJNlJK5sbOJTItkhWnVyClJPJCZIXmvd3nbXs0JOQk8MaeN4i8EMnp7NNaX8vDZDGRVuiYKfVwxmHGrxtPZrHzlaqgaN5lFucpC9S5r+bFOptnW237e+rvmvBXFRSVXT/TTbVyxl5P9G/UnzE3jWFwk8FMj5pOfI5tubhBGPhy0Jc8vulxbcI82elJYjNidfvSPtv1WdqFtMMgDCw+pdiND6XbFqr8dPInvj/2Pe/0foffkn7T1N+Vp1cCEFEnArh8srU8Y56DiaZjaEeOZh4l35SPRNJ+QXuH69RJqX4wZotZ99EYLUZiMmLoXLszFwou8Nbet9h9fjd1/erycb+PeXnXyxSXFZNdks36pPX4efgxrtU47fryhD85P9lB6zh+yXnOO5Vgl5f4TmWd4vkdz+vK3tr7FhvObODrQV9rzCUmI4ax68byvzv/R25pLrW8a+n8IkWmIp6PeF4XHaUSajfhxsrTK8kpzcHTzROjxciM6BnMiJ4BwCf9P2FQk0FYpIURq0Zo1yfkJLDi9Aq2J28noziDrclbSc1P5dBDh7R5oprtVBSXFZOQk8DYtWN5u/fbDG06lN9Tf9f5WbJLsrXnlmfMI7skmyDvIGLSYzC4GdhwZgMLjy9kycklbLlvCzW9a2p1fdx9dARFSqm979f3vM7b+97mx2E/4uXuRW2/2prfKiU/hfVJ61mftJ6RzUfybJdnOZN3xum7sodK6NVAh9/O/MaLO16kSUATzuad5eADB1kWt0z7HsosZXx/7Hs+OfAJY24ag8li4pnOz5BTmoOfhx9Td07V3feuNXcByjcS4qP4UhJzE8kqycIiLVrZB1EfsOTUEnaP282O5B1M+30ae8ftZWb0TGIzY/n68Ne82vNVrd3Xd79Oh9AOdArtxKRNk2gT0oYXI15kWdwypnSZgsHNwH9+/w9x2XHMGjCLzeeUQJBSc6k2joziDCzSor0fFaXmUp0zXZ0D11OiF1ezZ+X1QkREhIyOrlgaudHIKMrgu6PfsTphNfnGfObeNpee9XpyOOMwD6x/gADPAHaP282kTZPYc34P3et2J6ski+UjluPu5s76xPVM3TWVu1rcxf/i/+fQft8GfYm8EEmvBr1oGdQSg5uBOYfnOF3AZd/GHc3uYG3iWu1ci5otGNViFDOiZzD3trksO7WMjWc3OrThDAceOMC/NvyLwxn6VXydQjvRLqQdP5748bJttAxqSYhPCM91fY48Yx5HM48y88BMvhr0FU9sfoLBTQaz6WzFe4+qEUIlZSWMWzdOY67v9XkPX4MvbsKNKdumVHh9l9pdSClIoWlAU3o36K3Twur71ed8oX4V7PjW4xnYaCCta7Umz5jH0BVDded7N+jN14O+dmCSY24aw6s9XyUlP4VhK4dxObzX5z3O5J7RHP3lER4UrhHfD2/5kJd2vnTZNoeHDWd90nqH8sfaP8bE9hPxcvei35J+NK/ZnKndpjpoTM7Qq34v5gyew7wj8zidfVrXftOApk4JfdOApqQWpDowsKYBTfl2yLcODtrlI5bz4f4PNZ/W0KZDOZxxmAuFF7Q6wd7BDtpgj7o9OJB+wEHSVhkIKFqEGu3WeWFnh7rzh85n4oaJmKWZsMAw1oxSku4eyTjC/evvp5F/I52Wrfbjo1s+4tuj33IyS7+hC0DXOl35fODnJOQk8OCvDwLw9aCv6VW/F0IIVsWv4o09b7B8xHIt1Pnmn26mwKRoUkvvWErrWq0d2q0KhBAHrJs8OZ5zEfqrg8liwsNNcdiYLWZe3vUy97W8j+71uhN1IYpJmyaxdfRWHUc3mo0sj1vO3eF3022REq7WuXZnnXQP8G7vd7mzhbI975i1Y5xKu091eorZMbNpGdSSRcMXae0B/Hr3rzSo0YA8Yx6BXoHkG/PZfHYzI5uP5KWdL3Ei6wTd6nbjrhZ3aZNShUqMrxTe7t7a9owVIfqBaCJ+tM3H74d8T3J+Mq/veV1Xb+XIlYQHhfPg+geJyah4L9b7W91P/0b9WZu4ljO5ZzhfeJ4GNRpoTGpAowG83ett+i7pe8XjUWEQBjbdt4kQnxBi0mNIzk/mu6Pfaczn3pb3sjxu+WVauTr0btCbnJIcJFKbC3Nvm8uO5B38fPJnnSAQ5BVErjEXi7Rwc72beaDNA5qd/J7we1hxeoXTe/Rv1J/tydu14wltJ/D9Mdt+yuXn6ft93ue9yPdo7N8YN+HGqz1fpW2ttpTJMtYlrmP2odlcLLqIv6c/Xet0ZUfyDnwMNq1iSpcprIhbQUpB1TfcmNBuAreH3U5D/4bMPzafRv6NmH9sPsHewXx0y0c8tvExzSez6d5NLI9bzpzYOQ7tjG89nkUnFnFT0E2cyj7FxHYT6duwL8vilrEucZ1WLywwzKm/qzw6hXYiJiPGgQm2qNmCzOJMetXvpTHL9iHtaVurLd4Gb+Yfm6/VNbgZ2D129x9ad+Mi9H9hnMo6ha/Bl1kHZ7Hx7Ea61+1OVFoUPev1ZGb/mfh7KmFbd666k8TcRF7q9hINazSktm9t/D39uVRyiee2P8fM/jPpXLszaxPXsiN5BzW9ajKtx7QqxymPXzee2MxYBjUexJZzW6jrV5cLhRcwCAP3tryXxacW4ybcsEgLoT6hBHkHseSOJdyz5h5dlMOkDpN0H9XtzW7XfTSgSOqqVNwhpAPzh87H4GZgXdI6fA2+nC84zwf7PwCUj8TeTGaP//b9Lx1COtA4wJbR02QxYTKbWHh8IbNjZgPQ2L8x6+5exy8Jv+Dr4cuRjCOsOL0Cs8V82fUQKmYPnE2/RvrVqmaLmR9P/KiZcFRsuncTg5cPBqBBjQaaGa1ZYLPLRoSMbjmapXFLAXgh4gVd25H3R2oEIDYjllJzqbb2Yn/afqZsnaKNx1246wi/v4c/Hu4elJpLnZoIgryCyC7NZtO9m5jw2wQeafsI70a+q6vj4ebBwQcP8szWZ9iWvI0OIR1YdPvlw0i/if2Gzw99DigaRl2/uryz7x1dncFNBnNvy3t19n2AZ7s8i9Fs5MvDXwIwudNk/t3x35Xe73zBeV7c+SKxGbGV1lPxUreX+HC/fj+kOr51uFik5N45/NBhfkv6jYPpB1lyaonTNpaPWM7cI3Mva5Ov7VubZoHNKvR1vNP7HUa1+GNba7sI/d8AmcWZrI5fzSNtH6FMlulseAA7U3by+aHP+WHYDzrH1rVCkakIk8VEoFcgr+1+jVXxq2js35i1d63V+pdnzCPyQiSjbxqNlBIPdw/yjHkUmYo4X3AeH4MPLWq2ICZDsRXvStnF052f5kTWCc22OjxsOB/c8gHL45azP20/H9zygUNfVNXZGd64+Q3e2vuWRnQqwrK4Zby9920APh/4Of0b9Xeok5ibyJ2r7tSOWwe31hyeNb1q6qJcNt27ibp+zlfpXiq+xNbkrTQLbKZEQrV9mCJTEYWmQnw9fMktzSXUNxSDMDA9ajrpRelsPrdZI64q7m91P6/0eIWVp1fSoEYDetTrwW9Jv2l+nnf7vOv0/iqKTEV8HP0xS+OW8lrP15h9aLbWvpe7FytHruTAxQN8sP8Dnu78NF7uXpSaS+lRtwfBPsFkFGVwU7AtO6q9iWrNqDVIKWlWsxlRF6KYuHEij7V/jGe6PFNpnwC2nN3Cs9ufBWDjPRspKiti1OpR+Bp8Ncm+R90ezBsyj7jsOFbEreCRto+QUZxBh1Bl9fPhjMPU96tPqG/VQkQLjAWMWTuGc/m2EOP1d6+n0FTInvN7NDPekKZDeKjNQ7oAhP4N+zOtxzTmHpnL8LDhRNS10U71majzcFyrcWw4s4Gt921lTcIaTSsd1nQY+aZ8UvJTOJN3hsmdJvNFzBeMbD6SN3u9SVphGsNXDgfg0IOHOHDxAH4efrQLaVel8TlDZYQeKeVf7q9r167ShRuH5Lxk2fmHznLWgVk3tA/t5rfT/X0d87WUUsq5sXPlkYwjlV5/qfiSnPDbBHku71yFdUrLSuU9q++Rty27TX575FsppZR7UvfIgxcPyjJzmSwwFsgNSRvkKztfkRaL5doNTkp5Ouu0NJYZ5a6UXXJ1/Gr54PoHZWZR5jW9R3x2vBy3dpxsN7+d/PTAp1p5VceyLmGd/OHYD/JCwQWHc8l5ybLYVFyldswWs5z420Q5bdc0rSwlP0WaLWaZkp8i281vJzed2VSltq4EFotFFpuK5UdRH8mntzytO6fOKSmlLDOXya9jvpbJeclyZdxKaTQbK2zz16Rf5eYzm6WUUhYaCx3uV1JWIo9kHNGecVJOktx8ZrM0mU3y+yPfy0vFl7T6z29/Xs6NnXtNxiqllEC0rICmVkmiF0IMBT4F3IF5Usrp5c57AT8AXYFLwBgp5RnruVeAiYAZeEZKedl4o3+iRP9XQ3J+MrV9aztoFn8mLhZexMfDh3mx85jQbgI1vWr+JZbM/52QUZTB98e+56lOT13zfEt/ZyTlJuHp7kmDGtc2yeCNxFWZboQQ7kAcMBhIQdksfJy02/tVCPEk0EFK+W8hxFjgLinlGCFEG+BnoDtQH9gMtJSykvy/uAi9Cy644MKVojJCX5UFU92BeCllopTSCCwG7ixX505AXRK2HLhVKKLXncBiKWWplDIJiLe254ILLrjgwp+EqhD6BkCy3XGKtcxpHSllGZAL1KritQAIIR4XQkQLIaIzMv74RtQuuOCCCy7o8ZdJgSCl/EZKGSGljAgNvf6Jp1xwwQUX/imoCqFPBexzdTa0ljmtI4QwAIEoTtmqXOuCCy644MJ1RFUI/X4gXAgRJoTwBMYCa8rVWQM8bP19L7DVGu6zBhgrhPASQoQB4UDFO3C44IILLrhwzXHZpGZSyjIhxFPABpTwyu+klMeEEG+jxG2uAb4FFgoh4oEsFGaAtd5S4DhQBky+XMSNCy644IIL1xaulbEuuOCCC9UAVxte6YILLrjgwt8Yf0mJXgiRAZy9bEXnCAEq3kWgesI15n8GXGP+Z+CPjrmJlNJpyOJfktBfDYQQ0RWpL9UVrjH/M+Aa8z8D12PMLtONCy644EI1h4vQu+CCCy5Uc1RHQv/Nje7ADYBrzP8MuMb8z8A1H3O1s9G74IILLrigR3WU6F1wwQUXXLCDi9C74IILLlRzVBtCL4QYKoQ4JYSIF0K8fKP7c60ghPhOCJEuhDhqVxYshNgkhDht/R9kLRdCiM+szyBWCNHlxvX8j0MI0UgIsU0IcVwIcUwIMcVaXm3HLYTwFkJECSEOW8f8lrU8TAgRaR3bEmu+Kaz5o5ZYyyOFEE1vZP+vBkIIdyHEISHEWutxtR6zEOKMEOKIECJGCBFtLbuuc7taEHrrLlhfAMOANsA46+5W1QHzgaHlyl4Gtkgpw4Et1mNQxh9u/Xsc+OpP6uO1RhnwvJSyDdATmGx9n9V53KXAQCllR6ATMFQI0RP4APhEStkCyEbZlhPr/2xr+SfWen9XTAFO2B3/E8Y8QErZyS5e/vrO7Yo2k/07/QE3Axvsjl8BXrnR/bqG42sKHLU7PgXUs/6uB5yy/p6Dss2jQ72/8x+wGmUry3/EuAFf4CDQA2WFpMFars1zlCSDN1t/G6z1xI3u+x8Ya0MrYRsIrAXEP2DMZ4CQcmXXdW5XC4meK9jJqpqgjpTygvV3GlDH+rvaPQeret4ZiKSaj9tqwogB0oFNQAKQI5Vd20A/rop2dfu7YRbwEmCxHtei+o9ZAhuFEAeEEI9by67r3L5smmIX/tqQUkohRLWMkRVC1ABWAM9KKfOUbYgVVMdxSyWFdychRE3gf0CrG9yl6wohxB1AupTygBCi/43uz5+IPlLKVCFEbWCTEOKk/cnrMberi0T/T9vJ6qIQoh6A9X+6tbzaPAchhAcKkV8kpVxpLa724waQUuYA21DMFjWtu7aBflwV7er2d0JvYKQQ4gywGMV88ynVe8xIKVOt/9NRGHp3rvPcri6Eviq7YFUn2O/o9TCKDVstf8jqqe8J5Nqpg38bCEV0/xY4IaWcaXeq2o5bCBFqleQRQvig+CROoBD8e63Vyo/Z2a5ufxtIKV+RUjaUUjZF+Wa3SinHU43HLITwE0L4q7+B24CjXO+5faMdE9fQwTEciEOxa/7nRvfnGo7rZ+ACYEKxz01EsUtuAU4Dm4Fga12BEn2UABwBIm50///gmPug2DFjgRjr3/DqPG6gA3DIOuajwOvW8mYo22/GA8sAL2u5t/U43nq+2Y0ew1WOvz+wtrqP2Tq2w9a/Yyqtut5z25UCwQUXXHChmqO6mG5ccMEFF1yoAC5C74ILLrhQzeEi9C644IIL1RwuQu+CCy64UM3hIvQuuOCCC9UcLkLvggsuuFDN4SL0LrjgggvVHP8PfrDt6u+lQDcAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nwwq0nSdmsOL"
      },
      "source": [
        "# 2 DeepSNAP - основы\n",
        "\n",
        "В предыдущих блокнотиках мы использовали представления графов в виде классов (NetworkX) и тензоров (PyG) раздельно. Класс `nx.Graph` предоставляет богатый функционал для анализа и манипуляций с графами, таких как вычисления коэффициента кластеризации и PageRank. Для того, чтобы передать граф в модель, нам нужно преобразовать его в тензорное представление, включающее тензор рёбер `edge_index` и тензоры аттрибутов вершин `x` и `y`. Однако использование одних только тензоров (как графы в PyG `datasets` и `data`) делает многие манипуляции с графами и их анализ менее эффективными, а также сложными. В этом блокнотике мы используем DeepSNAP, который совмещает оба представления и предлагает полный функционал для обучения, валидации и тестирования графовых нейронных сетей.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf7vUmdNKCjA"
      },
      "source": [
        "В общем, [DeepSNAP](https://github.com/snap-stanford/deepsnap) - это библиотека для Python, помогающая эффективному глубокому обучению на графах. DeepSNAP включает поддержку разнообразных манипуляций с графами, стандартный поток операций обработки (pipeline), работу с гетерогенными графами и простой API.\n",
        "\n",
        "1. DeepSNAP легко использовать для уточённых манипуляций с графами, таких как вычисление признаков, предобучение, экстракция субграфов и т.д. во время/до обучения.\n",
        "2. В большинстве фреймворков стандартные потоки операций для задач на уровне вершин, рёбер (ориентированных и не-), графов в индуктивных или трансдуктивных сценариях - оставлены за рамками функционала и пользователям приходится их реализовывать самостоятельно. На приктике это включает дизайнерские решения (такие как метод разбиения выборки для задачи предсказания связи). DeepSNAP предоставляет стандартный поток операций, который здорово сохраняет усилия и позволяет честное сравнение моделей.\n",
        "3. Многие графы в реальном мире - гетерогенные. Однако наблюдается дефицит пакетов для гетерогенных графов, включая хранение данных и гибкую передачу сообщений. DeepSNAP предоставляет эффективные и гибкие гетерогенные графы, которые поддерживают гетерогенность вершин и рёбер.\n",
        "\n",
        "[DeepSNAP](https://github.com/snap-stanford/deepsnap) - это недавно выпущенный проект и он всё ещё в разработке. Если вы столкнётесь с багами или же если у вас есть предложения по улучшению, поднимайте issues или создавайте pull request непосредственно в репозитории на GitHub :)\n",
        "\n",
        "В этом блокнотике мы сосредоточимся на манипуляции с графами в DeepSNAP и настройках разбиения выборок."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20SvvngpQmmQ"
      },
      "source": [
        "## Установка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfbBVFmAQlwz"
      },
      "source": [
        "import torch\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from deepsnap.graph import Graph\n",
        "from deepsnap.batch import Batch\n",
        "from deepsnap.dataset import GraphDataset\n",
        "from torch_geometric.datasets import Planetoid, TUDataset\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def visualize(G, color_map=None, seed=123):\n",
        "  if color_map is None:\n",
        "    color_map = '#c92506'\n",
        "  plt.figure(figsize=(8, 8))\n",
        "  nodes = nx.draw_networkx_nodes(G, pos=nx.spring_layout(G, seed=seed), \\\n",
        "                                 label=None, node_color=color_map, node_shape='o', node_size=150)\n",
        "  edges = nx.draw_networkx_edges(G, pos=nx.spring_layout(G, seed=seed), alpha=0.5)\n",
        "  if color_map is not None:\n",
        "    plt.scatter([],[], c='#c92506', label='Nodes with label 0', edgecolors=\"black\", s=140)\n",
        "    plt.scatter([],[], c='#fcec00', label='Nodes with label 1', edgecolors=\"black\", s=140)\n",
        "    plt.legend(prop={'size': 13}, handletextpad=0)\n",
        "  nodes.set_edgecolor('black')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic-o1P3r6hr2"
      },
      "source": [
        "## DeepSNAP Graph\n",
        "\n",
        "Класс `deepsnap.graph.Graph` - самое сердце DeepSNAP. В нём граф не только хранится в тензорном формате, но и ссылается на графовый объект в пакете для манипуляций с графами.\n",
        "\n",
        "В данный момент DeepSNAP поддерживает [NetworkX](https://networkx.org/) и [Snap.py](https://snap.stanford.edu/snappy/doc/index.html) в качестве движка для операций на графах.\n",
        "\n",
        "В этом блокнотике мы будем использовать NetworkX."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ispq_lIoJl_z"
      },
      "source": [
        "Попробуем для начала конвертировать простой случайный граф NetworkX в граф DeepSNAP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zT5qca3x6XpG"
      },
      "source": [
        "num_nodes = 100\n",
        "p = 0.05\n",
        "seed = 100\n",
        "\n",
        "# Пусть G - случайный граф networkx (модели Эрдоша-Реньи)\n",
        "G = nx.gnp_random_graph(num_nodes, p, seed=seed)\n",
        "\n",
        "# Сгенерируем какие-то случайные признаки и метки классов для вершин\n",
        "node_feature = {node : torch.rand([5, ]) for node in G.nodes()}\n",
        "node_label = {node : torch.randint(0, 2, ()) for node in G.nodes()}\n",
        "\n",
        "# Присвоим сгенерированные выше признаки и метки графу G\n",
        "nx.set_node_attributes(G, node_feature, name='node_feature')\n",
        "nx.set_node_attributes(G, node_label, name='node_label')\n",
        "\n",
        "# Посмотрим на одну из вершин\n",
        "for node in G.nodes(data=True):\n",
        "  print(node)\n",
        "  break\n",
        "\n",
        "color_map = ['#c92506' if node[1]['node_label'].item() == 0 else '#fcec00' for node in G.nodes(data=True)]\n",
        "\n",
        "# Визуализируем граф\n",
        "visualize(G, color_map=color_map)\n",
        "\n",
        "# Трансформируем граф networkx в граф deepsnap\n",
        "graph = Graph(G)\n",
        "\n",
        "# Выведем общую информацию о графе deepsnap\n",
        "print(graph)\n",
        "\n",
        "# DeepSNAP конвертирует аттрибуты вершин в тензоры\n",
        "# Обратите внимание на тип тензоров\n",
        "print(\"Node feature (node_feature) has shape {} and type {}\".format(graph.node_feature.shape, graph.node_feature.dtype))\n",
        "print(\"Node label (node_label) has shape {} and type {}\".format(graph.node_label.shape, graph.node_label.dtype))\n",
        "\n",
        "# DeepSNAP также сгенерирует тензор edge_index\n",
        "print(\"Edge index (edge_index) has shape {} and type {}\".format(graph.edge_index.shape, graph.edge_index.dtype))\n",
        "\n",
        "# В отличие от простого хранения тензоров, граф deepsnap также ссылается на граф networkx\n",
        "# Мы обсудим почему ссылка будет полезна чуть позже\n",
        "print(\"The DeepSNAP graph has {} as the internal manupulation graph\".format(type(graph.G)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNMbc307KOQD"
      },
      "source": [
        "В DeepSNAP доступны аттрибуты трёх уровней. В этом примере у нас есть аттрибуты **уровня вершин**, включающие `node_feature` и `node_label`. Оставшиеся два уровня аттрибутов - относятся к графам и рёбрам. Использование подобно таковому для уровня вершин за исключением того, что признаки становятся `edge_feature` или `graph_feature` и метка класса становится `edge_label` или `graph_label` и т.д."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8Xz58_Da0qL"
      },
      "source": [
        "Подобно графу NetworkX, мы можем получить базовые свойства графа непосредственно через свойства класса."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLo4zWAoeg6S"
      },
      "source": [
        "# Количество вершин\n",
        "print(\"The random graph has {} nodes\".format(graph.num_nodes))\n",
        "\n",
        "# Количество рёбер\n",
        "print(\"The random graph has {} edges\".format(graph.num_edges))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po7IaRmwblI5"
      },
      "source": [
        "DeepSNAP также предоставляет функционал, позволяющий автоматически преобразовывать наборы данных PyG в списки графов DeepSNAP.\n",
        "\n",
        "Здесь мы преобразуем набор данных CORA в список графов DeepSNAP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFkg2kCgcFwR"
      },
      "source": [
        "root = './tmp/cora'\n",
        "name = 'Cora'\n",
        "\n",
        "# Набор данных Cora\n",
        "pyg_dataset= Planetoid(root, name)\n",
        "\n",
        "# Преобразуем набор данных PyG в сприсок графов deepsnap\n",
        "graphs = GraphDataset.pyg_to_graphs(pyg_dataset)\n",
        "\n",
        "# Получим первый граф deepsnap (CORA содержит лишь один граф)\n",
        "graph = graphs[0]\n",
        "print(graph)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLm5vVYMAP2x"
      },
      "source": [
        "## Вопрос 2.1: Чему равно количество классов и количество признаков в графе CORA? (5 баллов)\n",
        "\n",
        "Submit your answers on Gradescope."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iF_Kyqr_JbY"
      },
      "source": [
        "def get_num_node_classes(graph):\n",
        "  # ЗАДАЧА: Реализуйте функцию, принимающую объект графа deepsnap\n",
        "  # и возвращающую количество классов вершин для этого графа.\n",
        "\n",
        "  num_node_classes = 0\n",
        "\n",
        "  ############# Ваш код здесь ##############\n",
        "  ## (~1 строчка кода)\n",
        "  ## Обратите внимание\n",
        "  ## (1) Вам может пригодиться функционал автодополнения Colab\n",
        "  ## (2) Также может пригодиться документация DeepSNAP https://snap.stanford.edu/deepsnap/modules/graph.html\n",
        "\n",
        "\n",
        "  ##########################################\n",
        "\n",
        "  return num_node_classes\n",
        "\n",
        "def get_num_node_features(graph):\n",
        "  # ЗАДАЧА: Реализуйте функцию, принимающую объект графа deepsnap\n",
        "  # и возвращающую количество признаков вершин для этого графа.\n",
        "\n",
        "  num_node_features = 0\n",
        "\n",
        "  ############# Ваш код здесь ##############\n",
        "  ## (~1 строчка кода)\n",
        "  ## Обратите внимание\n",
        "  ## (1) Вам может пригодиться функционал автодополнения Colab\n",
        "  ## (2) Также может пригодиться документация DeepSNAP https://snap.stanford.edu/deepsnap/modules/graph.html\n",
        "\n",
        "\n",
        "  ##########################################\n",
        "\n",
        "  return num_node_features\n",
        "\n",
        "num_node_classes = get_num_node_classes(graph)\n",
        "num_node_features = get_num_node_features(graph)\n",
        "print(\"{} has {} classes\".format(name, num_node_classes))\n",
        "print(\"{} has {} features\".format(name, num_node_features))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwKbzhHUAckZ"
      },
      "source": [
        "## DeepSNAP Dataset\n",
        "\n",
        "Теперь поговорим о наборах данных в DeepSNAP. Всякий `deepsnap.dataset.GraphDataset` содержит список `deepsnap.graph.Graph` объектов. В дополнение к списку графов, вы также можете определить, для какой задачи предназначен набор данных, таких как задачи уровня вершин (`task=node`), задачи уровня рёбер (`task=link_pred`) и задачи уровня графа (`task=graph`).\n",
        "\n",
        "Он также содержит много прочих полезных параметров инициализации и прочий функционал. Чтобы узнать больше, обратитесь к [документации](https://snap.stanford.edu/deepsnap/modules/dataset.html#deepsnap-graphdataset)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSidf9E0hn2s"
      },
      "source": [
        "Теперь воспользуемся набором данных COX2, содержащим список графов и определим задачу как `graph` во время инициализации набора данных DeepSNAP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4kqUldyoaS_"
      },
      "source": [
        "root = './tmp/cox2'\n",
        "name = 'COX2'\n",
        "\n",
        "# Загрузим набор данных посредством PyG\n",
        "pyg_dataset = TUDataset(root, name)\n",
        "\n",
        "# Конвертируем в список графов deepsnap\n",
        "graphs = GraphDataset.pyg_to_graphs(pyg_dataset)\n",
        "\n",
        "# Конвертируем список графов deepsnap в набор данных deepsnap для задачи task=graph\n",
        "dataset = GraphDataset(graphs, task='graph')\n",
        "print(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sCV3xJWCddX"
      },
      "source": [
        "## Вопрос 2.2.: Какова метка графа (номер 100 в наборе данных COX2)? (5 баллов)\n",
        "\n",
        "Submit your answers on Gradescope."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIis9oTZAfs3"
      },
      "source": [
        "def get_graph_class(dataset, idx):\n",
        "  # ЗАДАЧА: Реализуйте функцию, принимающую объект набора данных deepsnap, а также\n",
        "  # индекс графа в наборе данных и возвращающую класс/метку (class/label) \n",
        "  # этого графа (как целое число).\n",
        "\n",
        "  label = -1\n",
        "\n",
        "  ############# Ваш код здесь ##############\n",
        "  ## (~1 строчка кода)\n",
        "  ## Обратите внимание\n",
        "  ## 1. Метка относится к аттрибутам уровня графа\n",
        "\n",
        "\n",
        "  #########################################\n",
        "\n",
        "  return label\n",
        "\n",
        "graph_0 = dataset[0]\n",
        "print(graph_0)\n",
        "idx = 100\n",
        "label = get_graph_class(dataset, idx)\n",
        "print('Graph with index {} has label {}'.format(idx, label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKhcVeAhCwoY"
      },
      "source": [
        "## Вопрос 2.3: Чему равно количество вершин графа (номер 200 в наборе данных COX2)? (5 баллов)\n",
        "\n",
        "Submit your answers on Gradescope."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5m2DOfhBtWv"
      },
      "source": [
        "def get_graph_num_edges(dataset, idx):\n",
        "  # ЗАДАЧА: Реализуйте функцию, принимающую объект набора данных deepsnap, а также\n",
        "  # индекс графа в наборе данных и возвращающую количество\n",
        "  # рёбер в этом графе (как целое число).\n",
        "\n",
        "  num_edges = 0\n",
        "\n",
        "  ############# Ваш код здесь ##############\n",
        "  ## (~1 строчка кода)\n",
        "  ## Обратите внимание\n",
        "  ## 1. Вы можетет непосредственно использовать свойство класса\n",
        "\n",
        "\n",
        "  #########################################\n",
        "\n",
        "  return num_edges\n",
        "\n",
        "idx = 200\n",
        "num_edges = get_graph_num_edges(dataset, idx)\n",
        "print('Graph with index {} has {} edges'.format(idx, num_edges))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXa7yIG4E0Fp"
      },
      "source": [
        "# 3 DeepSNAP Advanced\n",
        "\n",
        "Мы ознакомились с базовыми функциями графов и наборов данных DeepSNAP :)\n",
        "\n",
        "Приступим же к более продвинутому функционалу.\n",
        "\n",
        "В данной секции мы воспользуемся DeepSNAP для вычисления признаков и трансдуктивного/индуктивного разбиения выборки для обучения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5fsGBLY8cxa"
      },
      "source": [
        "## Установка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-jgRLiQ8cSj"
      },
      "source": [
        "import torch\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from deepsnap.graph import Graph\n",
        "from deepsnap.batch import Batch\n",
        "from deepsnap.dataset import GraphDataset\n",
        "from torch_geometric.datasets import Planetoid, TUDataset\n",
        "\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnazPGGAJAZN"
      },
      "source": [
        "## Разбиение данных в графах\n",
        "\n",
        "Подготовка выборок для обучение и валидации в случае с графами может быть намного сложнее, чем в областях компьютерного зрения или обрработки естественного языка.\n",
        "\n",
        "В общем, можно выделить два сценария разбиения данных - **индуктивный** и **трансдуктивный**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9KG_MhqsWBp"
      },
      "source": [
        "## Индуктивное разбиение\n",
        "\n",
        "Как говорилось в лекции (НАЙТИ БЫ КОНКРЕТНУЮ ССЫЛКУ), индуктивный сценарий будет разбивать множество графов на обучающую/валидационные части. \n",
        "\n",
        "Вот пример индуктивного разбиения в DeepSNAP для списка графов в задаче уровня графа (классификация графов и т.п.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gpc6bTm3GF02"
      },
      "source": [
        "root = './tmp/cox2'\n",
        "name = 'COX2'\n",
        "\n",
        "pyg_dataset = TUDataset(root, name)\n",
        "\n",
        "graphs = GraphDataset.pyg_to_graphs(pyg_dataset)\n",
        "\n",
        "# Здесь мы определяем задачу как задачу уровня графа, например, классификции графов\n",
        "task = 'graph'\n",
        "dataset = GraphDataset(graphs, task=task)\n",
        "\n",
        "# Зададим transductive=False (inductive)\n",
        "dataset_train, dataset_val, dataset_test = dataset.split(transductive=False, split_ratio=[0.8, 0.1, 0.1])\n",
        "\n",
        "print(\"COX2 train dataset: {}\".format(dataset_train))\n",
        "print(\"COX2 validation dataset: {}\".format(dataset_val))\n",
        "print(\"COX2 test dataset: {}\".format(dataset_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWKQwa4WsgQp"
      },
      "source": [
        "## Трансдуктивное разбиение\n",
        "\n",
        "В трансдуктивном сценарии обучающая/валидационная выборки определяются на одном и том же графе.\n",
        "\n",
        "Здесь мы трансдуктивно разделим граф CORA для задач уровня вершин.\n",
        "\n",
        "(Обратите внимание: по умолчанию DeepSnap настроен разбивать выборки случайным образом, но вы также можете зафиксировать выборки, установив `fixed_split=True` во время загрузки набора данных из PyG или непосредственно изменив `node_label_index`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5OdxSg4sfyR"
      },
      "source": [
        "root = './tmp/cora'\n",
        "name = 'Cora'\n",
        "\n",
        "pyg_dataset = Planetoid(root, name)\n",
        "\n",
        "graphs = GraphDataset.pyg_to_graphs(pyg_dataset)\n",
        "\n",
        "# Здесь мы определим задачу как задачу уровня вершин, например, классификации вершин\n",
        "task = 'node'\n",
        "\n",
        "dataset = GraphDataset(graphs, task=task)\n",
        "\n",
        "# Укажем, что мы хотим произвести трансдуктивное разбиение\n",
        "dataset_train, dataset_val, dataset_test = dataset.split(transductive=True, split_ratio=[0.8, 0.1, 0.1])\n",
        "\n",
        "print(\"Cora train dataset: {}\".format(dataset_train))\n",
        "print(\"Cora validation dataset: {}\".format(dataset_val))\n",
        "print(\"Cora test dataset: {}\".format(dataset_test))\n",
        "\n",
        "print(\"Original Cora has {} nodes\".format(dataset.num_nodes[0]))\n",
        "\n",
        "# Вершины, оказавшиеся в каждой выборке, можно найти в node_label_index\n",
        "print(\"After the split, Cora has {} training nodes\".format(dataset_train[0].node_label_index.shape[0]))\n",
        "print(\"After the split, Cora has {} validation nodes\".format(dataset_val[0].node_label_index.shape[0]))\n",
        "print(\"After the split, Cora has {} test nodes\".format(dataset_test[0].node_label_index.shape[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7ePKgM00lGE"
      },
      "source": [
        "## Разбиение на уровне рёбер\n",
        "\n",
        "По сравнению с разбиением на уровне вершин и графов, разделение на уровне рёбер не так уж и тривиально ;)\n",
        "\n",
        "Обыкновенно в разбиении данных на уровне рёбер, нам требуется подготовить выборку негативных (отсутствующих) рёбер, разбить позитивные (существующие) рёбра в различные выборки (обучающая/валидационная/тестовая), разбить рёбра в обучающей выборке на передающие сообщения и supervision edges, а также проводить resample для негативных рёбер и т.п."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnzISX5RoiR6"
      },
      "source": [
        "### All Mode\n",
        "\n",
        "Начнём с простого разбиения на уровне рёбер, режимом `edge_train_mode=\"all\"` в DeepSNAP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D104xO6137n"
      },
      "source": [
        "root = './tmp/cora'\n",
        "name = 'Cora'\n",
        "\n",
        "pyg_dataset = Planetoid(root, name)\n",
        "\n",
        "graphs = GraphDataset.pyg_to_graphs(pyg_dataset)\n",
        "\n",
        "# Определим задачу как link_pred задачи уровня рёбер\n",
        "task = 'link_pred'\n",
        "\n",
        "# Определим режим обучения, \"all\" - является стандартным для набора данных deepsnap\n",
        "edge_train_mode = \"all\"\n",
        "\n",
        "dataset = GraphDataset(graphs, task=task, edge_train_mode=edge_train_mode)\n",
        "\n",
        "# Трансдуктивное разбиение для link prediction\n",
        "dataset_train, dataset_val, dataset_test = dataset.split(transductive=True, split_ratio=[0.8, 0.1, 0.1])\n",
        "\n",
        "print(\"Cora train dataset: {}\".format(dataset_train))\n",
        "print(\"Cora validation dataset: {}\".format(dataset_val))\n",
        "print(\"Cora test dataset: {}\".format(dataset_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GscopwOXC_Y7"
      },
      "source": [
        "В DeepSNAP, индексы для supervision edges хранятся в тензоре `edge_label_index` и соответствующие метки рёбер хранятся в тензоре `edge_label`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJF8fZnA2eLR"
      },
      "source": [
        "print(\"Original Cora graph has {} edges\".format(dataset[0].num_edges))\n",
        "print(\"Because Cora graph is undirected, the original edge_index has shape {}\".format(dataset[0].edge_index.shape))\n",
        "\n",
        "print(\"The training set has message passing edge index shape {}\".format(dataset_train[0].edge_index.shape))\n",
        "print(\"The training set has supervision edge index shape {}\".format(dataset_train[0].edge_label_index.shape))\n",
        "\n",
        "print(\"The validation set has message passing edge index shape {}\".format(dataset_val[0].edge_index.shape))\n",
        "print(\"The validation set has supervision edge index shape {}\".format(dataset_val[0].edge_label_index.shape))\n",
        "\n",
        "print(\"The test set has message passing edge index shape {}\".format(dataset_test[0].edge_index.shape))\n",
        "print(\"The test set has supervision edge index shape {}\".format(dataset_test[0].edge_label_index.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6BX-I_oEKQX"
      },
      "source": [
        "Как видим, в обучающей и валидационной выборках - одни и те же рёбра для передачи сообщений (message passing edges) (`edge_index`) в режиме `all`. Также, в обучающей выборке, позитивные supervision edges (`edge_label_index`) совпадают с рёбрами для передачи сообщений. Однако, в тестовой выборке рёбра для передачи сообщений являются комбинацией рёбер для передачи сообщений из обучающей и валидационных выборок.\n",
        "\n",
        "Обратите внимание, что`edge_label` и `edge_label_index` включают негативные рёбра (по умолчанию количество отсутствующих рёбер идентично количеству позитивных рёбер).\n",
        "\n",
        "Теперь реализуем функцию, которая проверяет, являются ли два тензора индоксов рёбер непересекающимися(disjoint) и исследуем больше свойств разбиения рёбер, используя эту функцию."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOZHDskbAKN6"
      },
      "source": [
        "## Вопросы 3.1 - 3.5: Реализуйте функцию, проверяющую, являются ли два тензора edge_index непересекающимися (disjoint). Затем подтвердите либо опровергните утверждения ниже. (5 баллов)\n",
        "\n",
        "Submit your answers on Gradescope."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgRYdyPp8EmO"
      },
      "source": [
        "def edge_indices_disjoint(edge_index_1, edge_index_2):\n",
        "  # ЗАДАЧА: Реализуйте функцию, принимающую два тензора индексов рёбер \n",
        "  # и возвращающую суждение о том, являются ли эти тензоры непересекающимися множествами.\n",
        "  # \n",
        "  #TODO: Implement this function that takes two edge index tensors,\n",
        "  # and returns whether these two edge index tensors are disjoint.\n",
        "  disjoint = None\n",
        "\n",
        "  ############# Ваш код здесь ##############\n",
        "  ## (~5 строчек кода)\n",
        "  ## Обратите внимание:\n",
        "  ## (1) Здесь под непересекающимися множествами подразумевается что ни одно ребро не принадлежит обоим тензорам\n",
        "  ## (2) Вам не нужно рассматривать случай неориентированного графа. Например, если edge_index_1 содержит\n",
        "  ##     ребро (a, b) и edge_index_2 содержит ребро (b, a). В данной функции мы будем рассматривать\n",
        "  ##     как непересекающиеся множества.\n",
        "  ##\n",
        "  ## 1. Here disjoint means that there is no single edge belongs to either edge index tensors\n",
        "  ## 2. You do not need to consider the undirected case. For example, if edge_index_1 contains\n",
        "  ## edge (a, b) and edge_index_2 contains edge (b, a). We will treat them as disjoint in this\n",
        "  ## function.\n",
        "\n",
        "\n",
        "  #########################################\n",
        "\n",
        "  return disjoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL4ASIDDEIUf"
      },
      "source": [
        "num_train_edges = dataset_train[0].edge_label_index.shape[1] // 2\n",
        "train_pos_edge_index = dataset_train[0].edge_label_index[:, :num_train_edges]\n",
        "train_neg_edge_index = dataset_train[0].edge_label_index[:, num_train_edges:]\n",
        "print(\"3.1 Training (supervision) positve and negative edges are disjoint = {}\"\\\n",
        "        .format(edge_indices_disjoint(train_pos_edge_index, train_neg_edge_index)))\n",
        "\n",
        "num_val_edges = dataset_val[0].edge_label_index.shape[1] // 2\n",
        "val_pos_edge_index = dataset_val[0].edge_label_index[:, :num_val_edges]\n",
        "val_neg_edge_index = dataset_val[0].edge_label_index[:, num_val_edges:]\n",
        "print(\"3.2 Validation (supervision) positve and negative edges are disjoint = {}\"\\\n",
        "        .format(edge_indices_disjoint(val_pos_edge_index, val_neg_edge_index)))\n",
        "\n",
        "num_test_edges = dataset_test[0].edge_label_index.shape[1] // 2\n",
        "test_pos_edge_index = dataset_test[0].edge_label_index[:, :num_test_edges]\n",
        "test_neg_edge_index = dataset_test[0].edge_label_index[:, num_test_edges:]\n",
        "print(\"3.3 Test (supervision) positve and negative edges are disjoint = {}\"\\\n",
        "        .format(edge_indices_disjoint(test_pos_edge_index, test_neg_edge_index)))\n",
        "\n",
        "print(\"3.4 Test (supervision) positve and validation (supervision) positve edges are disjoint = {}\"\\\n",
        "        .format(edge_indices_disjoint(test_pos_edge_index, val_pos_edge_index)))\n",
        "print(\"3.5 Validation (supervision) positve and training (supervision) positve edges are disjoint = {}\"\\\n",
        "        .format(edge_indices_disjoint(val_pos_edge_index, train_pos_edge_index)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jLoVN5ZBTuA"
      },
      "source": [
        "### Disjoint Mode\n",
        "\n",
        "Теперь посмотрим на относительно более сложный режим трансдуктивного разбиения рёбер, то есть режим `edge_train_mode=\"disjoint\"` в DeepSNAP (также трансдуктивное разбиение для link prediction обсуждалось в лекции - ХОРОШО БЫ НАЙТИ ТОЧНУЮ ССЫЛКУ)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Rqzfb-0BTBm"
      },
      "source": [
        "edge_train_mode = \"disjoint\"\n",
        "\n",
        "dataset = GraphDataset(graphs, task='link_pred', edge_train_mode=edge_train_mode)\n",
        "orig_edge_index = dataset[0].edge_index\n",
        "dataset_train, dataset_val, dataset_test = dataset.split(\n",
        "    transductive=True, split_ratio=[0.8, 0.1, 0.1])\n",
        "\n",
        "train_message_edge_index = dataset_train[0].edge_index\n",
        "train_sup_edge_index = dataset_train[0].edge_label_index\n",
        "val_sup_edge_index = dataset_val[0].edge_label_index\n",
        "test_sup_edge_index = dataset_test[0].edge_label_index\n",
        "\n",
        "print(\"The edge index of original graph has shape: {}\".format(orig_edge_index.shape))\n",
        "print(\"The edge index of training message edges has shape: {}\".format(train_message_edge_index.shape))\n",
        "print(\"The edge index of training supervision edges has shape: {}\".format(train_sup_edge_index.shape))\n",
        "print(\"The edge index of validation message edges has shape: {}\".format(dataset_val[0].edge_index.shape))\n",
        "print(\"The edge index of validation supervision edges has shape: {}\".format(val_sup_edge_index.shape))\n",
        "print(\"The edge index of test message edges has shape: {}\".format(dataset_test[0].edge_index.shape))\n",
        "print(\"The edge index of test supervision edges has shape: {}\".format(test_sup_edge_index.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUkBhiJNciol"
      },
      "source": [
        "You can see that the training / validation message passing edges and training supervision edges are splitted differently in those two modes!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WKfRjqAJHtK"
      },
      "source": [
        "### Resample Negative Edges\n",
        "\n",
        "Во время каждой итерации обучения нам обычно требуется ресемплинг негативных рёбер.\n",
        "\n",
        "Ниже мы посмотрим на обучающие и валидационные наборы рёбер для двух итераций обучения.\n",
        "\n",
        "Вы должны обнаружить, что негативные рёбра в обучающей выборке будут изменяться."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMEbnx63JHWj"
      },
      "source": [
        "dataset = GraphDataset(graphs, task='link_pred', edge_train_mode=\"disjoint\")\n",
        "datasets = {}\n",
        "follow_batch = []\n",
        "datasets['train'], datasets['val'], datasets['test'] = dataset.split(\n",
        "    transductive=True, split_ratio=[0.8, 0.1, 0.1])\n",
        "dataloaders = {\n",
        "  split: DataLoader(\n",
        "    ds, collate_fn=Batch.collate(follow_batch),\n",
        "    batch_size=1, shuffle=(split=='train')\n",
        "  )\n",
        "  for split, ds in datasets.items()\n",
        "}\n",
        "neg_edges_1 = None\n",
        "for batch in dataloaders['train']:\n",
        "  num_edges = batch.edge_label_index.shape[1] // 2\n",
        "  neg_edges_1 = batch.edge_label_index[:, num_edges:]\n",
        "  print(\"First iteration training negative edges:\")\n",
        "  print(neg_edges_1)\n",
        "  break\n",
        "neg_edges_2 = None\n",
        "for batch in dataloaders['train']:\n",
        "  num_edges = batch.edge_label_index.shape[1] // 2\n",
        "  neg_edges_2 = batch.edge_label_index[:, num_edges:]\n",
        "  print(\"Second iteration training negative edges:\")\n",
        "  print(neg_edges_2)\n",
        "  break\n",
        "\n",
        "neg_edges_1 = None\n",
        "for batch in dataloaders['val']:\n",
        "  num_edges = batch.edge_label_index.shape[1] // 2\n",
        "  neg_edges_1 = batch.edge_label_index[:, num_edges:]\n",
        "  print(\"First iteration validation negative edges:\")\n",
        "  print(neg_edges_1)\n",
        "  break\n",
        "neg_edges_2 = None\n",
        "for batch in dataloaders['val']:\n",
        "  num_edges = batch.edge_label_index.shape[1] // 2\n",
        "  neg_edges_2 = batch.edge_label_index[:, num_edges:]\n",
        "  print(\"Second iteration validation negative edges:\")\n",
        "  print(neg_edges_2)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEzqh7wEdrh0"
      },
      "source": [
        "Если вас интересуют настройки разбиения графов, обратитесь к [документации](https://snap.stanford.edu/deepsnap/modules/dataset.html) по работе с наборами данных в DeepSNAP."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkrYyeSUI_9_"
      },
      "source": [
        "## Трансформации графов и вычисление признаков\n",
        "\n",
        "Ещё одна ключевая функциональность DeepSNAP - это трансформации графов и вычисление признаков.\n",
        "\n",
        "В DeepSNAP мы разделяем трансформацию графов / вычисление признаков в два различных типа. Первый - трансформация до обучения (изменяющая весь набор данных непосредственно перед обучением) и второй - трансформация во время обучения (изменяющая партии (batches) графов).\n",
        "\n",
        "Вот пример, который использует NetworkX для вычисления значений PageRank и обновляет значения в тензорах перед обучением (трансформация набора данных)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnAVbZINLZ4I"
      },
      "source": [
        "def pagerank_transform_fn(graph):\n",
        "\n",
        "  # Получим входной граф / Get the referenced networkx graph\n",
        "  G = graph.G\n",
        "\n",
        "  # Вычислим значения PageRank в NetworkX / Calculate the pagerank by using networkx\n",
        "  pr = nx.pagerank(G)\n",
        "\n",
        "  # Трансформируем полученные значения PageRank в тензор\n",
        "  pr_feature = torch.tensor([pr[node] for node in range(graph.num_nodes)], dtype=torch.float32)\n",
        "  pr_feature = pr_feature.view(graph.num_nodes, 1)\n",
        "\n",
        "  # Конкатенируем значения PageRank с признаками вершин\n",
        "  graph.node_feature = torch.cat([graph.node_feature, pr_feature], dim=-1)\n",
        "\n",
        "root = './tmp/cox2'\n",
        "name = 'COX2'\n",
        "pyg_dataset = TUDataset(root, name)\n",
        "graphs = GraphDataset.pyg_to_graphs(pyg_dataset)\n",
        "dataset = GraphDataset(graphs, task='graph')\n",
        "print(\"Number of features before transformation: {}\".format(dataset.num_node_features))\n",
        "dataset.apply_transform(pagerank_transform_fn, update_tensor=False)\n",
        "print(\"Number of features after transformation: {}\".format(dataset.num_node_features))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHByE87SQkUw"
      },
      "source": [
        "## Вопрос 3.6: Реализуйте трансформацию ниже и сообщите коэффициент кластеризации для вершины (номер 3) графа (номер 406) в наборе данных COX2. Округлите ответ до двух десятичных знаков. (5 баллов)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNEjfOZRNjYb"
      },
      "source": [
        "def cluster_transform_fn(graph):\n",
        "  # ЗАДАЧА: Реализуйте функцию, принимающую объект графа deepsnap и\n",
        "  # трансформирующую граф путём добавления коэффициента кластеризации\n",
        "  # в graph.node_feature\n",
        "  #\n",
        "  #TODO: Implement this function that takes an deepsnap graph object,\n",
        "  # transform the graph by adding nodes clustering coefficient into the \n",
        "  # graph.node_feature\n",
        "\n",
        "  ############# Ваш код здесь ##############\n",
        "  ## (~5 строчек кода)\n",
        "  ## Обратите внимание:\n",
        "  ## (1) Вычислите коэффициент кластеризации для каждой вершины и \n",
        "  ## конкатенируйте полученные значения справа с вектором признаков\n",
        "  ## (to the last dimension of graph.node_feature)\n",
        "\n",
        "\n",
        "  #########################################\n",
        "\n",
        "root = './cox2'\n",
        "name = 'COX2'\n",
        "pyg_dataset = TUDataset(root, name)\n",
        "graphs = GraphDataset.pyg_to_graphs(pyg_dataset)\n",
        "dataset = GraphDataset(graphs, task='graph')\n",
        "\n",
        "# Трансформируем набор данных\n",
        "dataset.apply_transform(cluster_transform_fn, update_tensor=False)\n",
        "\n",
        "node_idx = 3\n",
        "graph_idx = 406\n",
        "node_feature = dataset[graph_idx].node_feature\n",
        "\n",
        "print(\"The node has clustering coefficient: {}\".format(round(node_feature[node_idx][-1].item(), 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P5Ig7XaPYzp"
      },
      "source": [
        "Кроме трансформации набора данных, DeepSNAP также может трансформировать граф (обыкновенно `deepsnap.batch.Batch`) во время каждой итерации обучения.\n",
        "\n",
        "Также DeepSNAP поддерживает синхронизацию трансформации между связанными объектами графов и их тензорными представлениями. Например, вы можете просто обновить граф в NetworkX в трансформирующей функции и, задав `update_tensor=True`, автоматически обновить тензорные представления.\n",
        "\n",
        "За более подробной информацией, пожалуйста обращайтесь к [документации](https://snap.stanford.edu/deepsnap/) DeepSNAP."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-YLYMLFQYqp"
      },
      "source": [
        "# 4 Edge Level Prediction\n",
        "\n",
        "Из предыдущей секции мы знаем каким образом DeepSNAP производит трансдуктивное разбиение рёбер для задачи предсказания связи (link prediction).\n",
        "\n",
        "Теперь используем DeepSNAP и PyG вместе для реализации задачи предсказания на уровне рёбер (link prediction)!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrKCNtvERypQ"
      },
      "source": [
        "import copy\n",
        "import torch\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from deepsnap.graph import Graph\n",
        "from deepsnap.batch import Batch\n",
        "from deepsnap.dataset import GraphDataset\n",
        "from torch_geometric.datasets import Planetoid, TUDataset\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv\n",
        "\n",
        "class LinkPredModel(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_classes, dropout=0.2):\n",
        "        super(LinkPredModel, self).__init__()\n",
        "\n",
        "        self.conv1 = SAGEConv(input_dim, hidden_dim)\n",
        "        self.conv2 = SAGEConv(hidden_dim, num_classes)\n",
        "\n",
        "        self.loss_fn = None\n",
        "\n",
        "        ############# Ваш код здесь ##############\n",
        "        ## (~1 строчка кода)\n",
        "        ## Обратите внимание:\n",
        "        ## (1) Инициализируйте функцию потерь как BCEWithLogitsLoss\n",
        "\n",
        "\n",
        "        ##########################################\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.conv1.reset_parameters()\n",
        "        self.conv2.reset_parameters()\n",
        "\n",
        "    def forward(self, batch):\n",
        "        node_feature, edge_index, edge_label_index = batch.node_feature, batch.edge_index, batch.edge_label_index\n",
        "        \n",
        "        ############# Ваш код здесь ##############\n",
        "        ## (~6 строчек кода)\n",
        "        ## Обратите внимание:\n",
        "        ## (1) Отправьте признаки вершин в первый слой свёртки (conv layer)\n",
        "        ## (2) Добавьте ReLU после слоя свёртки\n",
        "        ## (3) Добавьте dropout после ReLU (с вероятностью self.dropout)\n",
        "        ## (4) Направьте выход во второй слой свёртки\n",
        "        ## (5) Выберите эмбеддинги для начальных и конечных вершин,\n",
        "        ##     используя edge_label_index и вычислите подобие каждой пары\n",
        "        ##     как скалярное произведение\n",
        "        ##\n",
        "        ##\n",
        "        ##\n",
        "        ## 1. Feed the node feature into the first conv layer\n",
        "        ## 2. Add a ReLU after the first conv layer\n",
        "        ## 3. Add dropout after the ReLU (with probability self.dropout)\n",
        "        ## 4. Feed the output to the second conv layer\n",
        "        ## 5. Select the embeddings of the source nodes and destination nodes\n",
        "        ## by using the edge_label_index and compute the similarity of each pair\n",
        "        ## by dot product\n",
        "\n",
        "        \n",
        "        ##########################################\n",
        "\n",
        "        return pred\n",
        "    \n",
        "    def loss(self, pred, link_label):\n",
        "        return self.loss_fn(pred, link_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuKbGFOu1Ka8"
      },
      "source": [
        "from sklearn.metrics import *\n",
        "\n",
        "def train(model, dataloaders, optimizer, args):\n",
        "    val_max = 0\n",
        "    best_model = model\n",
        "\n",
        "    for epoch in range(1, args[\"epochs\"]):\n",
        "        for i, batch in enumerate(dataloaders['train']):\n",
        "            \n",
        "            batch.to(args[\"device\"])\n",
        "\n",
        "            ############# Ваш код здесь ##############\n",
        "            ## (~6 строчек кода)\n",
        "            ## Обратите внимание:\n",
        "            ## (1) Обнулите градиенты оптимизатора\n",
        "            ## (2) Вычислите функцию потерь и проведите обратное распространение\n",
        "            ## (3) Обновите параметры модели\n",
        "            ##\n",
        "            ## 1. Zero grad the optimizer\n",
        "            ## 2. Compute loss and backpropagate\n",
        "            ## 3. Update the model parameters\n",
        "\n",
        "\n",
        "            ##########################################\n",
        "\n",
        "            log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}, Loss: {}'\n",
        "            score_train = test(model, dataloaders['train'], args)\n",
        "            score_val = test(model, dataloaders['val'], args)\n",
        "            score_test = test(model, dataloaders['test'], args)\n",
        "\n",
        "            print(log.format(epoch, score_train, score_val, score_test, loss.item()))\n",
        "            if val_max < score_val:\n",
        "                val_max = score_val\n",
        "                best_model = copy.deepcopy(model)\n",
        "    return best_model\n",
        "\n",
        "def test(model, dataloader, args):\n",
        "    model.eval()\n",
        "\n",
        "    score = 0\n",
        "\n",
        "    ############# Ваш код здесь ##############\n",
        "    ## (~6 строчек кода)\n",
        "    ## Обратите внимание:\n",
        "    ## (1) Итерируйте по партиям в загрузчике данных\n",
        "    ## (2) Загрузите партию в модель\n",
        "    ## (3) Направьте выход модели в сигмоид\n",
        "    ## (4) Вычислите ROC-AUC score, используя функцию sklearn roc_auc_score\n",
        "    ## (5) Метки рёбер хранятся в batch.edge_label\n",
        "    ##\n",
        "    ## 1. Loop through batches in the dataloader\n",
        "    ## 2. Feed the batch to the model\n",
        "    ## 3. Feed the model output to sigmoid\n",
        "    ## 4. Compute the ROC-AUC score by using sklearn roc_auc_score function\n",
        "    ## 5. Edge labels are stored in batch.edge_label\n",
        "\n",
        "    \n",
        "    ##########################################\n",
        " \n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTKWYX1b33V3"
      },
      "source": [
        "# Пожалуйста не изменяйте параметры\n",
        "args = {\n",
        "    \"device\" : 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    \"hidden_dim\" : 128,\n",
        "    \"epochs\" : 200,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Klw_xYnE27xQ"
      },
      "source": [
        "pyg_dataset = Planetoid('./tmp/cora', 'Cora')\n",
        "graphs = GraphDataset.pyg_to_graphs(pyg_dataset)\n",
        "\n",
        "dataset = GraphDataset(\n",
        "        graphs,\n",
        "        task='link_pred',\n",
        "        edge_train_mode=\"disjoint\"\n",
        "    )\n",
        "datasets = {}\n",
        "datasets['train'], datasets['val'], datasets['test']= dataset.split(\n",
        "            transductive=True, split_ratio=[0.85, 0.05, 0.1])\n",
        "input_dim = datasets['train'].num_node_features\n",
        "num_classes = datasets['train'].num_edge_labels\n",
        "\n",
        "model = LinkPredModel(input_dim, args[\"hidden_dim\"], num_classes).to(args[\"device\"])\n",
        "model.reset_parameters()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "dataloaders = {split: DataLoader(\n",
        "            ds, collate_fn=Batch.collate([]),\n",
        "            batch_size=1, shuffle=(split=='train'))\n",
        "            for split, ds in datasets.items()}\n",
        "best_model = train(model, dataloaders, optimizer, args)\n",
        "log = \"Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\"\n",
        "best_train_roc = test(best_model, dataloaders['train'], args)\n",
        "best_val_roc = test(best_model, dataloaders['val'], args)\n",
        "best_test_roc = test(best_model, dataloaders['test'], args)\n",
        "print(log.format(best_train_roc, best_val_roc, best_test_roc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5brlsKElP0_"
      },
      "source": [
        "## Вопрос 4: Каково максимальное значение ROC-AUC score для best_model на тесте? (13 баллов)\n",
        "\n",
        "Submit your answers on Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7JXsMTBgeOI"
      },
      "source": [
        "# Submission\n",
        "\n",
        "In order to get credit, you must go submit your answers on Gradescope.\n",
        "\n",
        "Also, you need to submit the `ipynb` file of Colab 3, by clicking `File` and `Download .ipynb`. Please make sure that your output of each cell is available in your `ipynb` file."
      ]
    }
  ]
}