{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Assignment2_CNN_for_texts.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Py3 research env",
      "language": "python",
      "name": "py3_research"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexunderch/Bachelor_materials/blob/main/Assignment2_CNN_for_texts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13pL--6rycN3"
      },
      "source": [
        "## Homework01: Three headed network in PyTorch\n",
        "\n",
        "This notebook accompanies the [week02 seminar](https://github.com/girafe-ai/ml-mipt/blob/advanced/week02_CNN_n_Vanishing_gradient/week02_CNN_for_texts.ipynb). Refer to that notebook for more comments.\n",
        "\n",
        "All the preprocessing is the same as in the classwork. *Including the data leakage in the train test split (it's still for bonus points).*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8zS7m-gycN5"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import nltk\n",
        "from tqdm import  tqdm\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlypqeQIPM_P"
      },
      "source": [
        "If you have already downloaded the data on the Seminar, simply run through the next cells. Otherwise uncomment the next cell (and comment the another one ;)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T70QZj-_PM_Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfc36b03-2ff5-4870-cf19-036f5247d43a"
      },
      "source": [
        "#uncomment and run this cell, if you don't have data locally yet.\n",
        "\n",
        "!curl -L \"https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1\" -o Train_rev1.csv.tar.gz\n",
        "!tar -xvzf ./Train_rev1.csv.tar.gz\n",
        "\n",
        "\n",
        "!wget https://raw.githubusercontent.com/girafe-ai/ml-mipt/advanced_f20/homeworks_advanced/assignment1_02_Three_headed_network/network.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  119M  100  119M    0     0  46.9M      0  0:00:02  0:00:02 --:--:-- 84.4M\n",
            "Train_rev1.csv\n",
            "--2021-02-13 22:37:54--  https://raw.githubusercontent.com/girafe-ai/ml-mipt/advanced_f20/homeworks_advanced/assignment1_02_Three_headed_network/network.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1469 (1.4K) [text/plain]\n",
            "Saving to: ‘network.py’\n",
            "\n",
            "network.py          100%[===================>]   1.43K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-02-13 22:37:54 (32.2 MB/s) - ‘network.py’ saved [1469/1469]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuuKIKfrycOH"
      },
      "source": [
        "data = pd.read_csv(\"./Train_rev1.csv\", index_col = None)\n",
        "\n",
        "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
        "text_columns = [\"Title\", \"FullDescription\"]\n",
        "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
        "target_column = \"Log1pSalary\"\n",
        "\n",
        "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
        "\n",
        "data_for_autotest = data[-5000:]\n",
        "data = data[:-5000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9POaI5T8j5B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0df5d2b5-24e9-459b-f896-d4d8ac527432"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# see task above\n",
        "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
        "\n",
        "def normalize(text):\n",
        "    text = str(text).lower()\n",
        "    return ' '.join(tokenizer.tokenize(text))\n",
        "    \n",
        "data[text_columns] = data[text_columns].applymap(normalize)\n",
        "\n",
        "print(\"Tokenized:\")\n",
        "print(data[\"FullDescription\"][2::100000])\n",
        "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
        "assert data[\"Title\"][54321] == 'international digital account manager ( german )'\n",
        "\n",
        "data_train, data_val = train_test_split(data, test_size = 0.2, random_state = 42)\n",
        "data_train.index = range(len(data_train))\n",
        "data_val.index = range(len(data_val))\n",
        "\n",
        "print(\"Train size = \", len(data_train))\n",
        "print(\"Validation size = \", len(data_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenized:\n",
            "2         mathematical modeller / simulation analyst / o...\n",
            "100002    a successful and high achieving specialist sch...\n",
            "200002    web designer html , css , javascript , photosh...\n",
            "Name: FullDescription, dtype: object\n",
            "Train size =  191814\n",
            "Validation size =  47954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUWkpd7PycOQ"
      },
      "source": [
        "token_counts = Counter()# <YOUR CODE HERE>\n",
        "for txt in data_train[text_columns].values.flatten():\n",
        "    token_counts.update(txt.split(' ')) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiOWbc15ycOb",
        "outputId": "4235fdbd-c0fc-4d34-a3d6-37f36f422b18"
      },
      "source": [
        "min_count = 10\n",
        "import re\n",
        "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
        "tokens = list(set([re.sub(r'[^\\w\\s]','', token) for token, count in token_counts.items() if count >= min_count]))\n",
        "# Add a special tokens for unknown and empty words\n",
        "UNK, PAD = \"UNK\", \"PAD\"\n",
        "tokens = [UNK, PAD] + sorted(tokens)\n",
        "print(\"Vocabulary size:\", len(tokens))\n",
        "\n",
        "assert type(tokens) == list\n",
        "# assert len(tokens) in range(32000, 35000)\n",
        "# assert 'me' in tokens\n",
        "assert UNK in tokens\n",
        "print(\"Correct!\")\n",
        "\n",
        "token_to_id = {token: idx for idx, token in enumerate(tokens)}\n",
        "assert isinstance(token_to_id, dict)\n",
        "# assert len(token_to_id) == len(tokens)\n",
        "for tok in tokens:\n",
        "    assert tokens[token_to_id[tok]] == tok\n",
        "\n",
        "print(\"Correct!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size: 30034\n",
            "Correct!\n",
            "Correct!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEsLeBjVycOw"
      },
      "source": [
        "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
        "\n",
        "def as_matrix(sequences, max_len = None):\n",
        "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
        "    if isinstance(sequences[0], str):\n",
        "        sequences = list(map(str.split, sequences))\n",
        "        \n",
        "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
        "    \n",
        "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
        "    for i,seq in enumerate(sequences):\n",
        "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
        "        matrix[i, :len(row_ix)] = row_ix\n",
        "    \n",
        "    return matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiBlPkdKycOy",
        "outputId": "b57ae7c2-e983-4228-a806-a862942126e2"
      },
      "source": [
        "print(\"Lines:\")\n",
        "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
        "print(\"Matrix:\")\n",
        "print(as_matrix(data[\"Title\"][::100000]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lines:\n",
            "engineering systems analyst\n",
            "hr assistant\n",
            "senior ec & i engineer\n",
            "\n",
            "Matrix:\n",
            "[[ 9361 26521  1654     1     1]\n",
            " [13118  2266     1     1     1]\n",
            " [24289  8821     0 13291  9358]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpOlBp7ZycO6",
        "outputId": "0910d2aa-cbbb-45a9-fc1c-72018025d00a"
      },
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "# we only consider top-1k most frequent companies to minimize memory usage\n",
        "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
        "recognized_companies = set(top_companies)\n",
        "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
        "\n",
        "categorical_vectorizer = DictVectorizer(dtype = np.float32, sparse = False)\n",
        "categorical_vectorizer.fit(data_train[categorical_columns].apply(dict, axis = 1))\n",
        "categorical_vectorizer.transform(data_val[categorical_columns].apply(dict, axis = 1))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk4jmtAYycO8"
      },
      "source": [
        "### The deep learning part\n",
        "\n",
        "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
        "\n",
        "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
        "\n",
        "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes.\n",
        "\n",
        "\n",
        "#### Here comes the simple one-headed network from the seminar. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PXuKgOSycPB"
      },
      "source": [
        "def make_batch(data, max_len = None, word_dropout = 0):\n",
        "    \"\"\"\n",
        "    Creates a keras-friendly dict from the batch data.\n",
        "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
        "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
        "    \"\"\"\n",
        "    batch = {}\n",
        "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
        "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
        "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
        "    \n",
        "    if word_dropout != 0:\n",
        "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
        "    \n",
        "    if target_column in data.columns:\n",
        "        batch[target_column] = data[target_column].values\n",
        "    \n",
        "    return batch\n",
        "\n",
        "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
        "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
        "    dropout_mask &= matrix != pad_ix\n",
        "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6LpEQf0ycPD"
      },
      "source": [
        "a = make_batch(data_train[:3], max_len = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "immNQ9KGPM_u"
      },
      "source": [
        "But to start with let's build the simple model using only the part of the data. Let's create the baseline solution using only the description part (so it should definetely fit into the Sequential model)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wnKqcGNPM_v"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGsHx_lQPM_v"
      },
      "source": [
        "# You will need these to make it simple\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "class Reorder(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.permute((0, 2, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUMscCMQPM_v"
      },
      "source": [
        "To generate minibatches we will use simple pyton generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHFanf7QPM_v"
      },
      "source": [
        "def iterate_minibatches(data, batch_size = 256, shuffle = True, cycle = False, **kwargs):\n",
        "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
        "    while True:\n",
        "        indices = np.arange(len(data))\n",
        "        if shuffle:\n",
        "            indices = np.random.permutation(indices)\n",
        "\n",
        "        for start in range(0, len(indices), batch_size):\n",
        "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
        "            target = batch.pop(target_column)\n",
        "            yield batch, target\n",
        "        \n",
        "        if not cycle: break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Dv-Zi-UPM_w"
      },
      "source": [
        "iterator = iterate_minibatches(data_train, 3)\n",
        "batch, target = next(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoKitQYAPM_0"
      },
      "source": [
        "### Actual homework starts here\n",
        "__Your ultimate task is to code the three headed network described on the picture below.__ \n",
        "To make it closer to the real world, please store the network code in file `network.py` in this directory. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eI5h9UMycPF"
      },
      "source": [
        "#### Architecture\n",
        "\n",
        "Our main model consists of three branches:\n",
        "* Title encoder\n",
        "* Description encoder\n",
        "* Categorical features encoder\n",
        "\n",
        "We will then feed all 3 branches into one common network that predicts salary.\n",
        "\n",
        "<img src=\"https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png\" width=600px>\n",
        "\n",
        "This clearly doesn't fit into PyTorch __Sequential__ interface. To build such a network, one will have to use [__PyTorch nn.Module API__](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UjAxR0qPM_0"
      },
      "source": [
        "import network\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUvk-A6jPM_0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15076b0d-1232-4c95-c039-a579c5e6e440"
      },
      "source": [
        "# Re-run this cell if you updated the file with network source code\n",
        "import imp\n",
        "imp.reload(network)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'network' from '/content/network.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXvbObv-PM_0"
      },
      "source": [
        "model = network.ThreeInputsNet(\n",
        "    n_tokens = len(tokens),\n",
        "    n_cat_features = len(categorical_vectorizer.vocabulary_),\n",
        "\n",
        "    # this parameter defines the number of the inputs in the layer,\n",
        "    # which stands after the concatenation. In should be found out by you.\n",
        "    concat_number_of_features = 8 * 64 + 512).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw3erQ7HPM_1"
      },
      "source": [
        "testing_batch, _ = next(iterate_minibatches(data_train, 3))\n",
        "testing_batch = [\n",
        "    torch.tensor(testing_batch['Title'], dtype = torch.long).to(device),\n",
        "    torch.tensor(testing_batch['FullDescription'], dtype = torch.long).to(device),\n",
        "    torch.tensor(testing_batch['Categorical']).to(device)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOVLmtUEPM_1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcc945a6-4887-4952-8cd2-3866a4b74147"
      },
      "source": [
        "assert model(testing_batch).detach().cpu().numpy().shape == torch.Size([3, 1])\n",
        "assert model(testing_batch).dtype == torch.float32\n",
        "print('Seems fine!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seems fine!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRbrQpScPM_2"
      },
      "source": [
        "Now train the network for a while (100 batches would be fine)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXkeWESfPM_2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "ee6b4257-ce25-406e-b35e-2fdbbd5621c3"
      },
      "source": [
        "# Training pipeline comes here (almost the same as for the simple_model)\n",
        "epochs = 1\n",
        "from IPython.display import clear_output\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "loss_func = nn.MSELoss() # <YOUR CODE HERE>\n",
        "\n",
        "history = []\n",
        "_ = model.train()\n",
        "for epoch_num in range(epochs):\n",
        "    for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
        "        # Preprocessing the batch data and target\n",
        "        batch = (torch.tensor(batch['Title'], dtype = torch.long).to(device),\n",
        "                 torch.tensor(batch['FullDescription'], dtype = torch.long).to(device),\n",
        "                 torch.tensor(batch['Categorical'], dtype = torch.float).to(device))\n",
        "        target = torch.tensor(target).to(device)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        predictions = model(batch)\n",
        "        predictions = predictions.view(predictions.size(0))\n",
        "\n",
        "        loss = loss_func(predictions, target) # <YOUR CODE HERE>\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        # train with backprop\n",
        "        # <YOUR CODE HERE>\n",
        "\n",
        "        history.append(loss.item())\n",
        "        if (idx + 1) % 10 == 0:\n",
        "            clear_output(True)\n",
        "            plt.plot(history,label = 'loss')\n",
        "            plt.legend()\n",
        "            plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAdLElEQVR4nO3de5ScBZnn8e9Tl7530rm0IaSBJMLAIMplAuKiwQOjoOMgrCwHZs4YOFzOrMroMkfFdY+XWc8yyowo644sKzDhKAwsMgMCggziALMaaUJCbsTEmJAOuXQ66U76Wrdn/3jf6q4Kbyehqztdb/n7nNOnq956q+rpru5fPfXUW+9r7o6IiNSWxHQXICIik0/hLiJSgxTuIiI1SOEuIlKDFO4iIjUoNd0FAMydO9cXLlw43WWIiMTKK6+8stfd26Muq4pwX7hwIZ2dndNdhohIrJjZtvEu01hGRKQGKdxFRGqQwl1EpAZVxcxdRGQyZLNZurq6GB4enu5SJlVDQwMdHR2k0+mjvo7CXURqRldXF62trSxcuBAzm+5yJoW709PTQ1dXF4sWLTrq62ksIyI1Y3h4mDlz5tRMsAOYGXPmzHnbr0YU7iJSU2op2Ism8jPFOtxf3rqPb/9sI5lcYbpLERGpKrEO95Xb9nPnzzeTKyjcRWT6tbS0THcJo2Id7kU63oiISLlYh3sNjtZEpAa4O5///Oc544wzePe7381DDz0EwM6dO1m6dClnnXUWZ5xxBi+++CL5fJ5rr712dN077rhjUmqoiU0h1biLyKG+/pN1rH/zwKTe5unHz+Crf/quI6736KOPsmrVKlavXs3evXs599xzWbp0KQ888ACXXHIJX/7yl8nn8wwODrJq1Sp27NjB2rVrAejt7Z2UWuPduRO07joOrIhUk5deeolrrrmGZDLJvHnzuPDCC3n55Zc599xzue+++/ja177GmjVraG1tZfHixWzZsoWbb76Zp59+mhkzZkxKDbHu3DWWEZHxHE2HfawtXbqUF154gSeffJJrr72WW265hU9+8pOsXr2aZ555hrvuuouHH36Ye++9t+L7inXnXqS+XUSqyQc+8AEeeugh8vk83d3dvPDCC5x33nls27aNefPmceONN3LDDTewcuVK9u7dS6FQ4BOf+ATf+MY3WLly5aTUEOvOXUSkGl1xxRX88pe/5Mwzz8TM+Na3vsVxxx3H8uXLuf3220mn07S0tHD//fezY8cOrrvuOgrhJt233XbbpNRQE+GukbuIVIP+/n4g+ETp7bffzu233152+bJly1i2bNlbrjdZ3XqpWI9lavFjxiIikyHW4T5KnbuISJlYh7v6dhE5VC1uGj2RnynW4V7kat1FhOCgFj09PTUV8MX9uTc0NLyt68X6DVWN3EWkVEdHB11dXXR3d093KZOqeCSmtyPW4V5UQ0/SIlKBdDr9to5WVMuOOJYxs3vNbI+ZrS1ZNtvMnjWzTeH3WeFyM7M7zWyzmb1mZudMZfHFxl3ZLiJS7mhm7v8IXHrIsluB59z9FOC58DzAR4BTwq+bgO9PTpnRtCmkiEi0I4a7u78A7Dtk8ceB5eHp5cDlJcvv98CvgDYzmz9ZxR6mxqm+CxGRWJno1jLz3H1neHoXMC88vQDYXrJeV7jsLczsJjPrNLPOib75ocZdRCRaxZtCetA2v+3W2d3vdvcl7r6kvb29shoquraISO2ZaLjvLo5bwu97wuU7gBNK1usIl00JNe4iItEmGu6PA8W93ywDHitZ/slwq5nzgb6S8c2U0chdRKTcEbdzN7MHgQ8Cc82sC/gq8LfAw2Z2PbANuCpc/Sngo8BmYBC4bgpqLi1uSm9eRCSujhju7n7NOBddHLGuA5+utKi3S7sfEBEpF+t9y4z27cp2EZEy8Q53TWVERCLFOtyL1LiLiJSLdbibNoYUEYkU63Av0qaQIiLlYh3umrmLiESLdbgXaVNIEZFysQ53Ne4iItFiHe5FmrmLiJSLdbhr5i4iEi3W4V6kxl1EpFysw724nbuOxCQiUi7W4a53VEVEosU73ENq3EVEysU63NW4i4hEi3W4i4hItFiHu2lbSBGRSLEO9yLN3EVEysU63NW3i4hEi3W4F2nHYSIi5WId7hq5i4hEi3W4F2nmLiJSLtbhXuzcle0iIuXiHe56S1VEJFKsw71IOw4TESkX63DXG6oiItFiHe5F6ttFRMpVFO5m9l/MbJ2ZrTWzB82swcwWmdkKM9tsZg+ZWd1kFSsiIkdnwuFuZguAvwKWuPsZQBK4GvgmcIe7nwzsB66fjEIPRyN3EZFylY5lUkCjmaWAJmAncBHwSHj5cuDyCu9jXNpxmIhItAmHu7vvAP4OeIMg1PuAV4Bed8+Fq3UBC6Kub2Y3mVmnmXV2d3dPtIxiNRVeX0SktlQylpkFfBxYBBwPNAOXHu313f1ud1/i7kva29snVsPobU3o6iIiNauSscwfA79z9253zwKPAhcAbeGYBqAD2FFhjePSVEZEJFol4f4GcL6ZNVkw/L4YWA88D1wZrrMMeKyyEo9MjbuISLlKZu4rCN44XQmsCW/rbuCLwC1mthmYA9wzCXVG0u4HRESipY68yvjc/avAVw9ZvAU4r5Lbfft1HMt7ExGpfrH+hKpm7iIi0WId7kU6EpOISLlYh7sadxGRaLEO9yLN3EVEysU63DVzFxGJFutwL1LnLiJSLubhHrTuekNVRKRcrMNdYxkRkWixDvcijWVERMrFOtzVuIuIRIt1uIuISLRYh7uOxCQiEi3W4V6kmbuISLlYh7v6dhGRaLEO9yJt5y4iUi7W4a6Ru4hItFiHe5Fm7iIi5WId7sXOXdkuIlIu3uGut1RFRCLFOtyLXHMZEZEy8Q53Ne4iIpHiHe4h9e0iIuViHe5q3EVEosU63Is0chcRKRfrcNeOw0REosU63MeodRcRKRXrcC/27RrLiIiUqyjczazNzB4xs9fNbIOZvc/MZpvZs2a2Kfw+a7KKfev9T9Uti4jEW6Wd+3eBp939NOBMYANwK/Ccu58CPBeen1Jq3EVEyk043M1sJrAUuAfA3TPu3gt8HFgerrYcuLzSIsetQRtDiohEqqRzXwR0A/eZ2atm9gMzawbmufvOcJ1dwLyoK5vZTWbWaWad3d3dFZShmbuIyKEqCfcUcA7wfXc/GxjgkBGMBzt9iYxed7/b3Ze4+5L29vYJFaCZu4hItErCvQvocvcV4flHCMJ+t5nNBwi/76msxCPTjsNERMpNONzdfRew3cxODRddDKwHHgeWhcuWAY9VVOFhqHEXEYmWqvD6NwM/MrM6YAtwHcETxsNmdj2wDbiqwvs4IvXtIiLlKgp3d18FLIm46OJKbveoqXUXEYkU60+oFmnkLiJSLtbhXtzO3TWYEREpE+9w11hGRCRSrMN9lBp3EZEysQ53Ne4iItFiHe5FatxFRMrFOtx1JCYRkWixDvcibQopIlIu1uGuxl1EJFqsw71I27mLiJSLdbjrGKoiItHiHe4ay4iIRIp1uBepcRcRKRfzcFfrLiISJebhHtCRmEREysU63DVzFxGJFutwL1LfLiJSLtbhrsZdRCRarMN9lFp3EZEysQ537ThMRCRarMO9SLsfEBEpF+tw1+4HRESixTvcNZUREYkU63AvUucuIlIu1uFu2hhSRCRSrMO9SI27iEi5WIe7Zu4iItEqDnczS5rZq2b2RHh+kZmtMLPNZvaQmdVVXubhacdhIiLlJqNz/yywoeT8N4E73P1kYD9w/STch4iIvA0VhbuZdQB/AvwgPG/ARcAj4SrLgcsruY+job5dRKRcpZ37d4AvAIXw/Byg191z4fkuYEHUFc3sJjPrNLPO7u7uCd25Zu4iItEmHO5m9jFgj7u/MpHru/vd7r7E3Ze0t7dPtIzwtiq6uohIzamkc78AuMzMtgL/RDCO+S7QZmapcJ0OYEdFFR5GcTv3v/zhhJ5fRERq1oTD3d2/5O4d7r4QuBr4ubv/OfA8cGW42jLgsYqrHIfGMiIi0aZiO/cvAreY2WaCGfw9U3AfIiJyGKkjr3Jk7v4L4Bfh6S3AeZNxu0eizl1EJFqsP6EqIiLRYh3u2nGYiEi0WIe7iIhEi3W4a+YuIhIt1uEuIiLRYh3uatxFRKLFO9xL0j1f0D4IRESKYh3upXKFwpFXEhH5PRHzcB9r3dW5i4iMiXm4j8kp3EVERsU63Mtm7nmFu4hIUazDvZQ6dxGRMbEO99JNITVzFxEZE+twL6WtZURExsQ63K1k6J7TzF1EZFSsw72UZu4iImNiHe6auYuIRIt3uJeku2buIiJjYh3updS5i4iMiXW4lx6JSTN3EZExsQ73UurcRUTGxDrcy2bu2hRSRGRUrMO9lN5QFREZUzPhrrGMiMiYmgn3givcRUSKYh3u5YfZm746RESqTczDXUdiEhGJMuFwN7MTzOx5M1tvZuvM7LPh8tlm9qyZbQq/z5q8csensYyIyJhKOvcc8NfufjpwPvBpMzsduBV4zt1PAZ4Lz08J7VtGRCTahMPd3Xe6+8rw9EFgA7AA+DiwPFxtOXB5pUUeDXXuIiJjJmXmbmYLgbOBFcA8d98ZXrQLmDfOdW4ys04z6+zu7p7g/Y6dVucuIjKm4nA3sxbgx8Dn3P1A6WXu7kBk6rr73e6+xN2XtLe3V1qGwl1EpERF4W5maYJg/5G7Pxou3m1m88PL5wN7KivxMPdfMnXXWEZEZEwlW8sYcA+wwd2/XXLR48Cy8PQy4LGJl3f0tJ27iMiYVAXXvQD4C2CNma0Kl/1X4G+Bh83semAbcFVlJY6vfOaudBcRKZpwuLv7S5RvjVjq4one7kRp5i4iMiben1AtOa09/oqIjIl1uJeme0Gdu4jIqHiHe4m8tpYRERkV63Av3RRSM3cRkTGxDvdSGsuIiIyJdbiXbQqpsYyIyKhYh3spde4iImNiHe7lm0Iq3EVEimId7qW0+wERkTGxDvfSw+w9//oevv+L305jNSIi1SPW4V5q4+6DfPPp17VJpIgIMQ/3qB3bvLFv8JjXISJSbeId7hHpvrVn4NgXIiJSZWId7lGGM/npLkFEZNrFOtyjtn4cyWmzGRGRWId71KH1hrPq3EVEYh3uUdvFqHMXEYl7uEeOZdS5i4jEO9wjeveRrDp3EZF4h7veUBURiRTrcI+iN1RFRGIe7u9orefmi04uW7bid/umqRoRkeoR63A3M/76w6fy+UtOHV22Zkcf27ULAhH5PRfrcC/61AffybqvXzJ6fm//yDRWIwCf+tEr/NF/f3a6yxD5vVUT4W5mNNenRs//nxe38JPVb5at88NfbeMPvvxT7TXyGHlqzS56BjLTXYbI762aCPeiD58+DwiC5eYHX2Uwk6NvMMvq7b38zRPryeQLdB88uq5+694BXt91YCrLjbV8wVn/5pF/P64jZIlMi5oK9+/92Tll55fd+2u+/exGrviHfycTbiK5o/et8/hcvsBQyQ7HBjM5Pvh3v+DS77w4JXX2DWXZsPPonjj6R3Jcd9+v2dLdPyW1FBUKzg9/tY3+kdxRrX/nc5v46J0vsnHXwcOuN6gduYlMiykJdzO71Mw2mtlmM7t1Ku4jSl0qwbc+8R5++tkPcOc1Z/Py1v0s/+U2Sicx6948wPZ9g6Md5Uguz0V//2/84Vee5vVdB7jsey9x+leeGV2/OMbZ2z/CDcs72b5vkIPDWfpHcrzZOwQw+sQB8OKmbjbvGQvih1/ezsJbn6R3MMNl33uJhzu3c9P9nXzkuy+WPaGM54XfdPP8xm7+x1MbRpf1DWXfVkfcN5SNXL6rb3jsfjZ189/+ZS23P/165LruzjeeWM+arj4AOrcFWyX9wy8288grXbzwm26eXb8bCJ4sj3TfteoHL25h4a1P6pPSx5i7s3XvABt3HTzqBqXW2WS/bDazJPAb4ENAF/AycI27rx/vOkuWLPHOzs5JrQOCYL310de46LR5/OuG3WWXzWpK895Fc3h63a7D3sZFp72DjlmNPLNuF7sPvHWk82fvPZEHVrzBZWcez56Dw/xqSxB6D954PvXpBFfd9UtyBec/nr2AR1/dUXbdL156GvNnNvDjlV2cv3gOV/5RBwbMaq5j+75BnnxtJ9v3D/JwZxdNdUmeveVCegcz/MmdL3Htf1jIX174TjbsPMDWngH29o9wybuOY3ZzHcPZAgmDbN658f5O3tg3yP+85mwSZsxtqeOE2U2se/MAN97fyRVnL+CvLj6Fn63bxW0/DYI9mTDcnR9e/17eMaOezXv62dk3zNd/EjyEX/nY6fzNE9EP5xcuPZU7n9vEcPhJ4YTBuQtnc90FC5nZWEc6acyb0UAiYcxoSLF17yDN9Uma61M016doTCcZzubJ5Ar0DGSY0ZhiZmMad+gdzNJYlyRfcJJmHBgOzifNSCaNumSC+lTQrxQPwZgvOAkLPtxmBvWpJBC8UhnM5hnK5DkwnGVWUx2zmtKYBT+7RRws4K5/+y1ruvr4zEUn85PVb/Ku42dyzklt9PRnODCU5YFfv8ETr+0E4Ib3L+KmCxezq2+YxnSS49sa2dE7xHEzG8jmCjTXp8gVnHzeSSaN5f9vK//86g6uOHsBl5+9gHTC2LJ3AAMWt7fQUp9iMJNjTks9wGiNuXyBTXv6mdNSx9zmekZyBXKFAolD3ocC6D44QnN9kqa6VPA7TNjobblDz0CG4WyeVdt7edfxM6hPJ2mpT9F9cJjhbIF3trcAQRO1Y/8QW3sGOG1+KweHcyye2wxAruCkkwncneFsgXTSSCWPvofM5YPai8yCx7BvKMvKN3r53s838Z6ONprrU5w4u4nBTI76dJLHV+3g5a37Abjg5DnccdVZtDXV0TeUpa0pTTqZoFBwhnPB39aMhjRD2TxD2TyphNHWVDf6uyj9+4ky3t/HdDCzV9x9SeRlUxDu7wO+5u6XhOe/BODut413nakKdwj+iQGeWLOTVMLYsX+I13cd5Om1OxkYp3NuqksymAke9JzegI0Vs+CTy6mEkQ9Dqz6VYCQXBA1AwYN/0EMf2vpUYvSVWkM6eBLJu1MoeNX8HTTVJcnkChTcaapLlXWpCWP0ZzKDOeETfSZfwBj79HYyYeQLTltTmmyuwFA2/5bfxXjSSSOZsNEn76Ji1qUSxoyGNJlcgYMjORrSCdoa69g/mCGdTNBYl6RQcArh778Q/n6L95/JF8gXnLrwCSGdtHH/T4+k+HPWJRNg5a+wG9IJhrPBE74BMxrTJM3I5Atkwidfd2cgk2dGQxp3J5EwBkdyDOcKzGqqG33iyeUL5Z+Wt7JvmNno76d0WfH8rR85jf+05IQJ/YyHC/dU1MIKLQC2l5zvAt4bUdRNwE0AJ5544hSUEUiE3cllZx5ftvzvrzpztKszM7oPjtA3lGFuSz31qSTdB0c4vq2Bzd39tDakMYLOZ92bB/jQ6fOY3VzHqu29mAXLW+pTLG5vpj6V5Kdrg+5tdlMduYKTKxSoTyXZvm+QmY1p2lvraWtK88a+QU47bgZm8PrO4OVkJldgMJMjV3AWtDWSShoL2pqY0Zjixd/sxQx2HxjmpDnNZHIFkgnjvEWz2T+QoSscExnByCWRME6d10pTXZLN3f3UJRPUpRJkwn/o/uEcfzh/Bpv29FNw57xFs5k/s4HdB4bpPphhZ9/QaJf2no42coUCLfUpVm7bz8GRHH965vGMZAt0zGpka88AqUSCrT0DvHvBTNbvPEB7az3nnDCLn63fRV0qQe9glkTCMIIQ2D+YZfeBYdpb65nRmGYok2MwkydpRkM6SSJh7BsYGe00m8KufTCTp7Eu6PBbG9IMZ/OYBfsVKnZV2XxhtDMdGMnjBP/kiYQFjzlBZ9s3lCWZCJ4QhrMFGtIJnOC2kong7ydpQaClEgnOXTSLVdt7aa1PUXDI5gt07Q9+7x84ZS49Axne6BnkrBPa2Lj7IO0t9fQNZTkwnCURhseMhjQF9zAoE+QLBfKF4HfSMSvo8CEIPiMIhsFMnoI7B4dz1KcSmAU/16ymOlJJo38kRzoR3p47/cM5RnJ5GtJJUuGTWvG6zXUpzGDfQIaGdJLGdJJ8mE4NqSQnzWnizb4h6lNJegcz9I/kWNzewu6+YbL5Atm809qQYv9ghtnNdeGYEFobUgxm8qOPR2tDevSVUXNdCsfJF4InoWTCSIShV+zUs+GTkJlRn0owlM3jDjMaUxhGY10SM6hLJjhpTjMbdx2gIZ2kY1YjMxrSnDyvhZc27aWnP0PBnf2DWVrqk/QMZKhLJWhMJ4PfR8LY1jNIe2s9XfsHSSYSpJM2+sTemE4ykAl+hqZ0koFMjoQFlzfXp0gmjL7wbzmZgFQiET5J2Oj+rkrDvthA++j58Hu45MTZTRMPuMOYis79SuBSd78hPP8XwHvd/TPjXWcqO3cRkVp1uM59Kt5Q3QGUvsboCJeJiMgxMhXh/jJwipktMrM64Grg8Sm4HxERGcekz9zdPWdmnwGeAZLAve6+brLvR0RExjcVb6ji7k8BT03FbYuIyJHV1CdURUQkoHAXEalBCncRkRqkcBcRqUGT/iGmCRVh1g1sm+DV5wJ7J7GcqaAaK1ft9UH111jt9YFqfLtOcvf2qAuqItwrYWad431Cq1qoxspVe31Q/TVWe32gGieTxjIiIjVI4S4iUoNqIdzvnu4CjoJqrFy11wfVX2O11weqcdLEfuYuIiJvVQudu4iIHELhLiJSg2Id7tN1IO6IOu41sz1mtrZk2Wwze9bMNoXfZ4XLzczuDGt+zczOOQb1nWBmz5vZejNbZ2afrcIaG8zs12a2Oqzx6+HyRWa2IqzloXA30phZfXh+c3j5wqmuMbzfpJm9amZPVGl9W81sjZmtMrPOcFk1Pc5tZvaImb1uZhvM7H1VVt+p4e+u+HXAzD5XTTUeteDguPH7Itid8G+BxUAdsBo4fZpqWQqcA6wtWfYt4Nbw9K3AN8PTHwV+SnA0vPOBFcegvvnAOeHpVoIDmJ9eZTUa0BKeTgMrwvt+GLg6XH4X8J/D058C7gpPXw08dIwe61uAB4AnwvPVVt9WYO4hy6rpcV4O3BCergPaqqm+Q2pNAruAk6q1xsPWP90FVPCLfx/wTMn5LwFfmsZ6Fh4S7huB+eHp+cDG8PT/Bq6JWu8Y1voY8KFqrRFoAlYSHHt3L5A69DEnOF7A+8LTqXA9m+K6OoDngIuAJ8J/6KqpL7yvqHCviscZmAn87tDfQ7XUF1Hvh4F/r+YaD/cV57FM1IG4F0xTLVHmufvO8PQuYF54elrrDscDZxN0xlVVYzjyWAXsAZ4leGXW6+65iDpGawwv7wPmTHGJ3wG+ABTC83OqrD4IjsP8MzN7xYKD0EP1PM6LgG7gvnC09QMza66i+g51NfBgeLpaaxxXnMM9Njx4Sp/2bU7NrAX4MfA5dz9Qelk11OjueXc/i6BDPg84bTrrKWVmHwP2uPsr013LEbzf3c8BPgJ82syWll44zY9zimB8+X13PxsYIBhxjKqGv0OA8L2Ty4D/e+hl1VLjkcQ53Kv9QNy7zWw+QPh9T7h8Wuo2szRBsP/I3R+txhqL3L0XeJ5gzNFmZsUjhpXWMVpjePlMoGcKy7oAuMzMtgL/RDCa+W4V1QeAu+8Iv+8B/pngSbJaHucuoMvdV4TnHyEI+2qpr9RHgJXuvjs8X401Hlacw73aD8T9OLAsPL2MYM5dXP7J8F3284G+kpd7U8LMDLgH2ODu367SGtvNrC083UjwnsAGgpC/cpwai7VfCfw87KimhLt/yd073H0hwd/az939z6ulPgAzazaz1uJpgpnxWqrkcXb3XcB2Mzs1XHQxsL5a6jvENYyNZIq1VFuNhzfdQ/9Kvgjeqf4NwWz2y9NYx4PATiBL0J1cTzBffQ7YBPwrMDtc14D/Fda8BlhyDOp7P8HLyNeAVeHXR6usxvcAr4Y1rgW+Ei5fDPwa2EzwErk+XN4Qnt8cXr74GD7eH2Rsa5mqqS+sZXX4ta74P1Flj/NZQGf4OP8LMKua6gvvt5ngVdbMkmVVVePRfGn3AyIiNSjOYxkRERmHwl1EpAYp3EVEapDCXUSkBincRURqkMJdRKQGKdxFRGrQ/wdpc0LB2CvDaQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrRg9AC8PM_2"
      },
      "source": [
        "Now, to evaluate the model it can be switched to `eval` state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rHlZ4xePM_2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60b8f1f7-2454-4374-d40b-7dc16791aa97"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ThreeInputsNet(\n",
              "  (title_emb): Embedding(30034, 64)\n",
              "  (title_conv1): Conv1d(64, 128, kernel_size=(2,), stride=(1,), padding=(1,))\n",
              "  (title_relu1): ReLU()\n",
              "  (title_bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (title_amp): AdaptiveMaxPool1d(output_size=2)\n",
              "  (full_emb): Embedding(30034, 64)\n",
              "  (full_conv1): Conv1d(64, 128, kernel_size=(3,), stride=(1,))\n",
              "  (full_relu1): ReLU()\n",
              "  (full_bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (full_conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
              "  (full_relu2): ReLU()\n",
              "  (full_bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (full_amp): AdaptiveMaxPool1d(output_size=2)\n",
              "  (category_in): Linear(in_features=21232, out_features=512, bias=True)\n",
              "  (category_bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (category_dropout): Dropout(p=0.25, inplace=False)\n",
              "  (category_out): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (inter_dense): Linear(in_features=1024, out_features=192, bias=True)\n",
              "  (final_dense): Linear(in_features=192, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7_xPGtmPM_2"
      },
      "source": [
        "def generate_submission(model, data, batch_size = 256, name = \"\", three_inputs_mode = True):\n",
        "    squared_error = 0.; abs_error = 0.; num_samples = 0.0\n",
        "    output_list = []\n",
        "    for batch_x, batch_y in tqdm(iterate_minibatches(data, batch_size = batch_size, shuffle = False)): \n",
        "        if three_inputs_mode:\n",
        "            batch = [\n",
        "                torch.tensor(batch_x['Title'], dtype = torch.long),\n",
        "                torch.tensor(batch_x['FullDescription'], dtype = torch.long),\n",
        "                torch.tensor(batch_x['Categorical'])\n",
        "            ]\n",
        "        else:\n",
        "            batch = torch.tensor(batch_x['FullDescription'], dtype=torch.long)\n",
        "\n",
        "        batch_pred = model(batch)[:, 0].detach().numpy()\n",
        "        \n",
        "        output_list.append((list(batch_pred), list(batch_y)))\n",
        "        \n",
        "        squared_error += np.sum(np.square(batch_pred - batch_y))\n",
        "        abs_error += np.sum(np.abs(batch_pred - batch_y))\n",
        "        num_samples += len(batch_y)\n",
        "    print(\"%s results:\" % (name or \"\"))\n",
        "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
        "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
        "    \n",
        "\n",
        "    batch_pred = [c for x in output_list for c in x[0]]\n",
        "    batch_y = [c for x in output_list for c in x[1]]\n",
        "    output_df = pd.DataFrame(list(zip(batch_pred, batch_y)), columns=['batch_pred', 'batch_y'])\n",
        "    output_df.to_csv('submission.csv', index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00y7IznDPM_3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c3f236b-6abb-4f75-e615-57124fd26933"
      },
      "source": [
        "generate_submission(model.cpu(), data_for_autotest, name='Submission')\n",
        "print('Submission file generated')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20it [00:15,  1.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Submission results:\n",
            "Mean square error: 1.01137\n",
            "Mean absolute error: 0.76238\n",
            "Submission file generated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rtN-BbuPM_3"
      },
      "source": [
        "__To hand in this homework, please upload `network.py` file with code and `submission.csv` to the google form.__"
      ]
    }
  ]
}