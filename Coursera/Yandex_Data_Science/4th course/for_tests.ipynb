{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%pylab inline\n",
    "data = pd.read_csv(\"water.txt\",delimiter=\"\\s+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           mortality  hardness\n",
      "mortality     1.0000   -0.6548\n",
      "hardness     -0.6548    1.0000\n"
     ]
    }
   ],
   "source": [
    "data.head\n",
    "print(round(data.corr(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sperman corr: -0.631665 0.000000\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.weightstats import _zconfint_generic, _tconfint_generic\n",
    "from scipy.stats import spearmanr\n",
    "print(\"Sperman corr: %f %f\" % spearmanr(data.mortality, data.hardness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ = data.mortality.mean()\n",
    "std_ = data.mortality.std(ddof = 1)/sqrt(len(data.mortality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd model mean auc 95%% confidence interval (1476.0833413552848, 1572.2117406119285)\n"
     ]
    }
   ],
   "source": [
    "print(\"sgd model mean auc 95%% confidence interval\", _tconfint_generic(mean_, std_,\n",
    "                                                                       len(data.mortality) - 1,\n",
    "                                                                       0.05, 'two-sided'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           mortality  hardness\n",
      "mortality     1.0000   -0.6022\n",
      "hardness     -0.6022    1.0000\n",
      "           mortality  hardness\n",
      "mortality     1.0000   -0.3686\n",
      "hardness     -0.3686    1.0000\n"
     ]
    }
   ],
   "source": [
    "N = data[data.location == \"North\"]\n",
    "S = data[data.location == \"South\"]\n",
    "\n",
    "print(round(S.corr(), 4))\n",
    "print(round(N.corr(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1376.8076923076924 1633.6\n"
     ]
    }
   ],
   "source": [
    "S_mean = S.mortality.mean()\n",
    "S_std = S.mortality.std()/sqrt(len(S.mortality))\n",
    "\n",
    "N_mean = N.mortality.mean()\n",
    "N_std = N.mortality.std()/sqrt(len(N.mortality))\n",
    "\n",
    "print(S_mean, N_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd model mean auc 95%% confidence interval (1320.1517462936238, 1433.463638321761)\n",
      "sgd model mean auc 95%% confidence interval (1586.5605251961385, 1680.6394748038613)\n"
     ]
    }
   ],
   "source": [
    "print(\"sgd model mean auc 95%% confidence interval\", _tconfint_generic(S_mean, S_std,\n",
    "                                                                       len(S.mortality) - 1,\n",
    "                                                                       0.05, 'two-sided'))\n",
    "print(\"sgd model mean auc 95%% confidence interval\", _tconfint_generic(N_mean, N_std,\n",
    "                                                                       len(N.mortality) - 1,\n",
    "                                                                       0.05, 'two-sided'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_mean = S.hardness.mean()\n",
    "S_std = S.hardness.std()/sqrt(len(S.hardness))\n",
    "\n",
    "N_mean = N.hardness.mean()\n",
    "N_std = N.hardness.std()/sqrt(len(N.hardness))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd model mean auc 95%% confidence interval (53.467198692036106, 86.07126284642544)\n",
      "sgd model mean auc 95%% confidence interval (21.42248728572426, 39.37751271427574)\n"
     ]
    }
   ],
   "source": [
    "print(\"sgd model mean auc 95%% confidence interval\", _tconfint_generic(S_mean, S_std,\n",
    "                                                                       len(S.hardness) - 1,\n",
    "                                                                       0.05, 'two-sided'))\n",
    "print(\"sgd model mean auc 95%% confidence interval\", _tconfint_generic(N_mean, N_std,\n",
    "                                                                       len(N.hardness) - 1,\n",
    "                                                                       0.05, 'two-sided'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384.1599999999999"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1.960/0.1) ** 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 0.05880530708179099)\n",
      "(0.003539259271646236, 0.10495443589637815)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "\n",
    "\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "print(proportion_confint(1, 50, method = 'normal'))\n",
    "\n",
    "wilson_interval = proportion_confint(1, 50, method = 'wilson')\n",
    "print(wilson_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "752.9536"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((1.960/0.01) ** 2) * 0.02 *0.98\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9604"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.proportion import samplesize_confint_proportion\n",
    "from math import ceil\n",
    "ceil(samplesize_confint_proportion(0.5, 0.01, method='normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N(0,1) mean auc 99,7%% confidence interval (-2.9677379253417944, 2.9677379253417944)\n"
     ]
    }
   ],
   "source": [
    "print(\"N(0,1) mean auc 99,7%% confidence interval\", _zconfint_generic(0, 1, 0.3 / 100, 'two-sided'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0077"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(-104/11037 + 189/11034, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scipy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-b5a61e62534c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mleft_boundary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_boundary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"confidence interval: [%f, %f]\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mproportions_confint_diff_ind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplacebo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-b5a61e62534c>\u001b[0m in \u001b[0;36mproportions_confint_diff_ind\u001b[0;34m(sample1, sample2, alpha)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mproportions_confint_diff_ind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mppf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scipy' is not defined"
     ]
    }
   ],
   "source": [
    "asp = np.concatenate((np.ones(104), np.zeros(11037 - 104))) \n",
    "placebo = np.concatenate((np.ones(189), np.zeros(11034 - 189))) \n",
    "\n",
    "def proportions_confint_diff_ind(sample1, sample2, alpha = 0.05):    \n",
    "    z = scipy.stats.norm.ppf(1 - alpha / 2.)   \n",
    "    p1 = float(sum(sample1)) / len(sample1)\n",
    "    p2 = float(sum(sample2)) / len(sample2)\n",
    "    \n",
    "    left_boundary = (p1 - p2) - z * np.sqrt(p1 * (1 - p1)/ len(sample1) + p2 * (1 - p2)/ len(sample2))\n",
    "    right_boundary = (p1 - p2) + z * np.sqrt(p1 * (1 - p1)/ len(sample1) + p2 * (1 - p2)/ len(sample2))\n",
    "    \n",
    "    return (left_boundary, right_boundary)\n",
    "\n",
    "print(\"confidence interval: [%f, %f]\" % proportions_confint_diff_ind(placebo, asp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(104/(11037 - 104), 4))\n",
    "print(189/(11034 - 189) * (11037 - 104) / 104)\n",
    "print(0.0095/0.0174)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "def get_bootstrap_samples(data, n_samples):\n",
    "    indices = np.random.randint(0, len(data), (n_samples, len(data)))\n",
    "    samples = data[indices]\n",
    "    return samples\n",
    "def stat_intervals(stat, alpha):\n",
    "    boundaries = np.percentile(stat, [100 * alpha / 2., 100 * (1 - alpha / 2.)])\n",
    "    return boundaries\n",
    "def compute_odds(sample):\n",
    "    return sum(sample) / (len(sample) - sum(sample)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "scores_asp = list(map(compute_odds, get_bootstrap_samples(asp, 1000)))\n",
    "scores_placebo = list(map(compute_odds, get_bootstrap_samples(placebo, 1000)))\n",
    "delta_scores = list(map(lambda x: x[1] / x[0], zip(scores_asp, scores_placebo)))\n",
    "print(stat_intervals(stat = delta_scores, alpha = 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(stats.binom_test(67, 100, 0.75), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(stats.binom_test(22, 50, 0.75), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%pylab inline\n",
    "data = pd.read_csv(\"pines.txt\",delimiter=\"\\s+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binned_statistic_2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binx = np.linspace(0.0, 200, 6)\n",
    "biny = binx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = binned_statistic_2d(data['sn'].values.astype(float), data['we'].values.astype(float), None, \n",
    "                             statistic = 'count', bins = [binx, biny] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.statistic.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_frequences = np.concatenate((result.statistic[0], \n",
    "                                      result.statistic[1], result.statistic[2], result.statistic[3], result.statistic[4]), axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(stats.chisquare(observed_frequences, ddof = 0)[0], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.chisquare(observed_frequences, ddof = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "from scipy.stats import norm\n",
    "z = (9.57 - 9.5)/ (0.4 / sqrt(160) )\n",
    "print(\"Z = \", z) \n",
    "print(round(2 * (1- norm.cdf(abs(z))),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"diamonds.txt\",delimiter=\"\\s+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = data['price']\n",
    "X = data.drop(columns = 'price', inplace =  False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model1 = LinearRegression()\n",
    "model2 = RandomForestRegressor(random_state = 1)\n",
    "\n",
    "model1.fit(X_train, y_train)\n",
    "model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "out1 = model1.predict(X_test)\n",
    "out2 = model2.predict(X_test)\n",
    "mod1 = abs(y_test - out1)\n",
    "mod2 = abs(y_test - out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import probplot, shapiro, ttest_rel \n",
    "probplot(out1, dist = \"norm\", plot = pylab)\n",
    "print(\"Shapiro-Wilk normality test, W-statistic: %f, p-value: %f\" % shapiro(out1))\n",
    "show()\n",
    "probplot(out2, dist = \"norm\", plot = pylab)\n",
    "print(\"Shapiro-Wilk normality test, W-statistic: %f, p-value: %f\" % shapiro(out2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.weightstats import *\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "print(ttest_rel(mod1, mod2))\n",
    "a = mae(y_test, out1) \n",
    "b = mae(y_test, out2) \n",
    "print(a - b)\n",
    "\n",
    "print(\"95%% confidence interval: [%f, %f]\" %  zconfint(mod1-mod2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "def proportions_diff_confint_ind(sample1, sample2, alpha = 0.05):    \n",
    "    z = scipy.stats.norm.ppf(1 - alpha / 2.)\n",
    "    \n",
    "    p1 = float(sum(sample1)) / len(sample1)\n",
    "    p2 = float(sum(sample2)) / len(sample2)\n",
    "    \n",
    "    left_boundary = (p1 - p2) - z * np.sqrt(p1 * (1 - p1)/ len(sample1) + p2 * (1 - p2)/ len(sample2))\n",
    "    right_boundary = (p1 - p2) + z * np.sqrt(p1 * (1 - p1)/ len(sample1) + p2 * (1 - p2)/ len(sample2))\n",
    "    \n",
    "    return (left_boundary, right_boundary)\n",
    "\n",
    "def proportions_diff_z_stat_ind(sample1, sample2):\n",
    "    n1 = len(sample1)\n",
    "    n2 = len(sample2)\n",
    "    \n",
    "    p1 = float(sum(sample1)) / n1\n",
    "    p2 = float(sum(sample2)) / n2 \n",
    "    P = float(p1*n1 + p2*n2) / (n1 + n2)\n",
    "    \n",
    "    return (p1 - p2) / np.sqrt(P * (1 - P) * (1. / n1 + 1. / n2))\n",
    "\n",
    "def proportions_diff_z_test(z_stat, alternative = 'less'):\n",
    "    if alternative not in ('two-sided', 'less', 'greater'):\n",
    "        raise ValueError(\"alternative not recognized\\n\"\n",
    "                         \"should be 'two-sided', 'less' or 'greater'\")\n",
    "    \n",
    "    if alternative == 'two-sided':\n",
    "        return 2 * (1 - scipy.stats.norm.cdf(np.abs(z_stat)))\n",
    "    \n",
    "    if alternative == 'less':\n",
    "        return scipy.stats.norm.cdf(z_stat)\n",
    "\n",
    "    if alternative == 'greater':\n",
    "        return 1 - scipy.stats.norm.cdf(z_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from statsmodels.stats.weightstats import *\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "\n",
    "test = [1] * 10 + [0] * 24\n",
    "valid = [1] * 4 + [0] * 12\n",
    "\n",
    "print(\"p-value: %f\" % round(proportions_diff_z_test(proportions_diff_z_stat_ind(valid, test)), 4))\n",
    "\n",
    "print(\"95%% confidence interval for a difference between proportions: [%f, %f]\" %\\\n",
    "      proportions_diff_confint_ind(test, valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"banknotes.txt\",delimiter=\"\\s+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = data['real']\n",
    "X = data.drop(columns = 'real', inplace =  False)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)\n",
    "\n",
    "X1_train = X_train[X.columns[:3]]\n",
    "X2_train = X_train[X.columns[3:]]\n",
    "X1_test = X_test[X.columns[:3]]\n",
    "X2_test = X_test[X.columns[3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model1 = LogisticRegression()\n",
    "model2 = LogisticRegression()\n",
    "\n",
    "model1.fit(X1_train, y_train)\n",
    "model2.fit(X2_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred = model1.predict(X1_test)\n",
    "y2_pred = model2.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "err1 = 1 - accuracy_score(y_test, y1_pred)\n",
    "err2 = 1 - accuracy_score(y_test, y2_pred)\n",
    "print(err1 - err2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y__test = y_test.iloc \n",
    "def derandomize(x, y_pred):\n",
    "    for i in range(len(x)):\n",
    "        if y_pred[i] == int(y__test[i]):\n",
    "            x[i] = 0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportions_diff_z_stat_rel(sample1, sample2):\n",
    "    sample = list(zip(sample1, sample2))\n",
    "    n = len(sample)\n",
    "    \n",
    "    f = sum([1 if (x[0] == 1 and x[1] == 0) else 0 for x in sample])\n",
    "    g = sum([1 if (x[0] == 0 and x[1] == 1) else 0 for x in sample])\n",
    "    \n",
    "    return float(f - g) / np.sqrt(f + g - float((f - g)**2) / n )\n",
    "\n",
    "def proportions_diff_confint_rel(sample1, sample2, alpha = 0.05):\n",
    "    z = scipy.stats.norm.ppf(1 - alpha / 2.)\n",
    "    sample = list(zip(sample1, sample2))\n",
    "    n = len(sample)\n",
    "        \n",
    "    f = sum([1 if (x[0] == 1 and x[1] == 0) else 0 for x in sample])\n",
    "    g = sum([1 if (x[0] == 0 and x[1] == 1) else 0 for x in sample])\n",
    "    \n",
    "    left_boundary = float(f - g) / n  - z * np.sqrt(float((f + g)) / n**2 - float((f - g)**2) / n**3)\n",
    "    right_boundary = float(f - g) / n  + z * np.sqrt(float((f + g)) / n**2 - float((f - g)**2) / n**3)\n",
    "    return (left_boundary, right_boundary)\n",
    "\n",
    "a1 = np.random.randint(low = 1, high = 2, size = 50)\n",
    "a2 = np.random.randint(low = 1, high = 2, size = 50)\n",
    "\n",
    "a1 = derandomize(a1, y1_pred)\n",
    "a2 = derandomize(a2, y2_pred)\n",
    "\n",
    "print (\"95%% confidence interval for a difference between proportions: [%f, %f]\" \n",
    "       % proportions_diff_confint_rel(a1, a2))\n",
    "                                                                                                                \n",
    "print(\"p-value: %f\" % proportions_diff_z_test(proportions_diff_z_stat_rel(a1, a2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "0.0505\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from scipy.stats import norm\n",
    "std = 100\n",
    "n = 100 \n",
    "mean = 525\n",
    "x_mean = 541.4\n",
    "z = (x_mean - mean) / (std / sqrt (n))\n",
    "print( round (1 - norm.cdf(z), 4) )\n",
    "#x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2845\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "data = np.array([49, 58, 75, 110, 112, 132, 151, 276, 281, 362])\n",
    "median = 200\n",
    "stat = wilcoxon(data - median)\n",
    "print(round(stat[1], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "no = np.array([22, 22, 15, 13, 19, 19, 18, 20, 21, 13, 13, 15])\n",
    "yes = np.array([17, 18, 18, 15, 12, 4, 14, 15, 10])\n",
    "stat = mannwhitneyu(no, yes, alternative = 'greater')\n",
    "print(round(stat[1], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"challenger.txt\", delimiter = \"\\s+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Incident</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>20.860870</td>\n",
       "      <td>0.304348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>3.919501</td>\n",
       "      <td>0.470472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>21.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>27.200000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Temperature   Incident\n",
       "count    23.000000  23.000000\n",
       "mean     20.860870   0.304348\n",
       "std       3.919501   0.470472\n",
       "min      11.700000   0.000000\n",
       "25%      19.400000   0.000000\n",
       "50%      21.100000   0.000000\n",
       "75%      23.900000   1.000000\n",
       "max      27.200000   1.000000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 0., 1., 4., 2., 5., 3., 3., 2.]),\n",
       " array([11.7 , 13.25, 14.8 , 16.35, 17.9 , 19.45, 21.  , 22.55, 24.1 ,\n",
       "        25.65, 27.2 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pylab.hist(data.Temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "incident = data.Temperature[data.Incident == 1].values\n",
    "clear = data.Temperature[data.Incident == 0].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bootstrap_samples(data, n_samples):\n",
    "    indices = np.random.randint(0, len(data), (n_samples, len(data)))\n",
    "    samples = data[indices]\n",
    "    return samples\n",
    "def stat_intervals(stat, alpha):\n",
    "    boundaries = np.percentile(stat, [100 * alpha / 2., 100 * (1 - alpha / 2.)])\n",
    "    return boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval for the difference between medians [1.45040179 8.06457589]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "incident_scores = list(map(np.mean, get_bootstrap_samples(incident, 1000)))\n",
    "clear_scores = list(map(np.mean, get_bootstrap_samples(clear, 1000)))\n",
    "delta_scores = list(map(lambda x: x[0] - x[1], zip(clear_scores, incident_scores)))\n",
    "print(\"95% confidence interval for the difference between medians\",  stat_intervals(delta_scores, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def permutation_t_stat_ind(sample1, sample2):\n",
    "    return np.mean(sample1) - np.mean(sample2)\n",
    "\n",
    "def get_random_combinations(n1, n2, max_combinations):\n",
    "    index = list(range(n1 + n2))\n",
    "    indices = set([tuple(index)])\n",
    "    for i in range(max_combinations - 1):\n",
    "        np.random.shuffle(index)\n",
    "        indices.add(tuple(index))\n",
    "    return [(index[:n1], index[n1:]) for index in indices]\n",
    "\n",
    "def permutation_zero_dist_ind(sample1, sample2, max_combinations = None):\n",
    "    joined_sample = np.hstack((sample1, sample2))\n",
    "    n1 = len(sample1)\n",
    "    n = len(joined_sample)\n",
    "    \n",
    "    if max_combinations:\n",
    "        indices = get_random_combinations(n1, len(sample2), max_combinations)\n",
    "    else:\n",
    "        indices = [(list(index), list(filter(lambda i: i not in index, range(n)))) \\\n",
    "                    for index in itertools.combinations(range(n), n1)]\n",
    "    \n",
    "    distr = [joined_sample[list(i[0])].mean() - joined_sample[list(i[1])].mean() \\\n",
    "             for i in indices]\n",
    "    return distr\n",
    "\n",
    "def permutation_test(sample, mean, max_permutations = None, alternative = 'two-sided'):\n",
    "    if alternative not in ('two-sided', 'less', 'greater'):\n",
    "        raise ValueError(\"alternative not recognized\\n\"\n",
    "                         \"should be 'two-sided', 'less' or 'greater'\")\n",
    "    \n",
    "    t_stat = permutation_t_stat_ind(sample, mean)\n",
    "    \n",
    "    zero_distr = permutation_zero_dist_ind(sample, mean, max_permutations)\n",
    "    \n",
    "    if alternative == 'two-sided':\n",
    "        return sum([1. if abs(x) >= abs(t_stat) else 0. for x in zero_distr]) / len(zero_distr)\n",
    "    \n",
    "    if alternative == 'less':\n",
    "        return sum([1. if x <= t_stat else 0. for x in zero_distr]) / len(zero_distr)\n",
    "\n",
    "    if alternative == 'greater':\n",
    "        return sum([1. if x >= t_stat else 0. for x in zero_distr]) / len(zero_distr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.005700\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "print(\"p-value: %f\" % permutation_test(incident, clear, max_permutations = 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%pylab inline\n",
    "data = pd.read_csv(\"illiteracy.txt\", delimiter = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Illit</th>\n",
       "      <th>Births</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Albania</td>\n",
       "      <td>20.5</td>\n",
       "      <td>1.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>39.1</td>\n",
       "      <td>2.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Belize</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Benin</td>\n",
       "      <td>73.5</td>\n",
       "      <td>5.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country  Illit  Births\n",
       "0  Albania   20.5    1.78\n",
       "1  Algeria   39.1    2.44\n",
       "2  Bahrain   15.0    2.34\n",
       "3   Belize    5.9    2.97\n",
       "4    Benin   73.5    5.60"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Illit  Births\n",
      "Illit   1.0000  0.7687\n",
      "Births  0.7687  1.0000\n"
     ]
    }
   ],
   "source": [
    "print(round(data.corr(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.752962213732534, pvalue=2.0858571221460674e-18)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print (spearmanr(data.Illit, data.Births))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.109"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "a = 718.0\n",
    "b = 203.0\n",
    "c = 515.0\n",
    "d = 239.0\n",
    "mcc = (a * d - b * c)/math.sqrt((a + b)*(a + c)*(b + d)*(c + d))\n",
    "round(mcc, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19.40753078854304, 1.0558987006638725e-05, 1, array([[677.96597015, 243.03402985],\n",
      "       [555.03402985, 198.96597015]]))\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "print(chi2_contingency(numpy.array([[a, b], [c, d]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.053905233215813156, 0.13922183141523897)\n",
      "Ttest_indResult(statistic=4.485175262463444, pvalue=7.78139336142543e-06)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm, ttest_ind\n",
    "def proportions_confint_diff_ind(sample1, sample2, alpha = 0.05):    \n",
    "    z = norm.ppf(1 - alpha / 2.)   \n",
    "    p1 = float(sum(sample1)) / len(sample1)\n",
    "    p2 = float(sum(sample2)) / len(sample2)\n",
    "    \n",
    "    left_boundary = (p1 - p2) - z * np.sqrt(p1 * (1 - p1)/ len(sample1) + p2 * (1 - p2)/ len(sample2))\n",
    "    right_boundary = (p1 - p2) + z * np.sqrt(p1 * (1 - p1)/ len(sample1) + p2 * (1 - p2)/ len(sample2))\n",
    "    \n",
    "    return (left_boundary, right_boundary)\n",
    "\n",
    "print(proportions_confint_diff_ind([0] * 515 + [1] * 239, [0] * 718 + [1] * 203))\n",
    "print(ttest_ind([0] * 515 + [1] * 239, [0] * 718 + [1] * 203))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(293.68311039689746, 2.4964299580093467e-62, 4, array([[ 93.08597464, 153.74722662,  94.16679873],\n",
      "       [381.6251981 , 630.318542  , 386.0562599 ],\n",
      "       [214.28882726, 353.93423138, 216.77694136]]))\n"
     ]
    }
   ],
   "source": [
    "contingencies = np.array([[197, 111, 33], [382, 685, 331], [110, 342, 333]])\n",
    "chi2_ = chi2_contingency(contingencies)[0]\n",
    "print(chi2_contingency(contingencies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/al_cher/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2412"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = sum(sum(x) for x in contingencies)\n",
    "V = sqrt(chi2_ / (n * (min(contingencies.shape[0], contingencies.shape[1] - 1)) ))\n",
    "round(V, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%pylab inline\n",
    "data = pd.read_csv(\"AUCs.txt\", delimiter = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>C4.5</th>\n",
       "      <th>C4.5+m</th>\n",
       "      <th>C4.5+cf</th>\n",
       "      <th>C4.5+m+cf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>adult (sample)</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>breast cancer</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>breast cancer wisconsin</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>cmc</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ionosphere</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>iris</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>liver disorders</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>lung cancer</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>lymphography</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>mushroom</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>primary tumor</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>rheum</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>voting</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>wine</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Unnamed: 0   C4.5  C4.5+m  C4.5+cf  C4.5+m+cf\n",
       "0            adult (sample)  0.763   0.768    0.771      0.798\n",
       "1             breast cancer  0.599   0.591    0.590      0.569\n",
       "2   breast cancer wisconsin  0.954   0.971    0.968      0.967\n",
       "3                       cmc  0.628   0.661    0.654      0.657\n",
       "4                ionosphere  0.882   0.888    0.886      0.898\n",
       "5                      iris  0.936   0.931    0.916      0.931\n",
       "6           liver disorders  0.661   0.668    0.609      0.685\n",
       "7               lung cancer  0.583   0.583    0.563      0.625\n",
       "8              lymphography  0.775   0.838    0.866      0.875\n",
       "9                  mushroom  1.000   1.000    1.000      1.000\n",
       "10            primary tumor  0.940   0.962    0.965      0.962\n",
       "11                    rheum  0.619   0.666    0.614      0.669\n",
       "12                   voting  0.972   0.981    0.975      0.975\n",
       "13                     wine  0.957   0.978    0.946      0.970"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "slice_ = data.iloc[:, 1:]\n",
    "cols = list(slice_.columns)\n",
    "result = list()\n",
    "for i, col1 in enumerate(cols):\n",
    "    for j, col2 in enumerate(cols[i + 1:]):\n",
    "        w = wilcoxon(slice_[col1], slice_[col2])\n",
    "        result.append((col1 + \" vs \" + col2, w[0], w[1]))\n",
    "        \n",
    "R = pd.DataFrame.from_records(result, columns = [\"Vs\", 'Statistics', 'p-Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Vs  Statistics   p-Value\n",
      "0        C4.5 vs C4.5+m         6.5  0.010757\n",
      "1       C4.5 vs C4.5+cf        43.0  0.861262\n",
      "2     C4.5 vs C4.5+m+cf        11.0  0.015906\n",
      "3     C4.5+m vs C4.5+cf        17.0  0.046333\n",
      "4   C4.5+m vs C4.5+m+cf        22.0  0.327826\n",
      "5  C4.5+cf vs C4.5+m+cf        10.0  0.022909\n",
      "                     Vs  Statistics   p-Value\n",
      "0        C4.5 vs C4.5+m         6.5  0.010757\n",
      "2     C4.5 vs C4.5+m+cf        11.0  0.015906\n",
      "3     C4.5+m vs C4.5+cf        17.0  0.046333\n",
      "5  C4.5+cf vs C4.5+m+cf        10.0  0.022909\n"
     ]
    }
   ],
   "source": [
    "print(R)\n",
    "print(R[R['p-Value'] < 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Vs  Statistics   p-Value  Reject  p_corrected\n",
      "0        C4.5 vs C4.5+m         6.5  0.010757   False     0.064543\n",
      "1       C4.5 vs C4.5+cf        43.0  0.861262   False     0.861262\n",
      "2     C4.5 vs C4.5+m+cf        11.0  0.015906   False     0.079532\n",
      "3     C4.5+m vs C4.5+cf        17.0  0.046333   False     0.138998\n",
      "4   C4.5+m vs C4.5+m+cf        22.0  0.327826   False     0.655651\n",
      "5  C4.5+cf vs C4.5+m+cf        10.0  0.022909   False     0.091636\n",
      "Empty DataFrame\n",
      "Columns: [Vs, Statistics, p-Value, Reject, p_corrected]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "reject, p_corrected, _, _ = multipletests(R['p-Value'], \n",
    "                                            alpha = 0.05, \n",
    "                                            method = 'holm')\n",
    "R['p_corrected'] = p_corrected\n",
    "R['Reject'] = reject\n",
    "print(R)\n",
    "print(R[R.p_corrected < 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Vs  Statistics   p-Value  Reject  p_corrected\n",
      "0        C4.5 vs C4.5+m         6.5  0.010757    True     0.045818\n",
      "1       C4.5 vs C4.5+cf        43.0  0.861262   False     0.861262\n",
      "2     C4.5 vs C4.5+m+cf        11.0  0.015906    True     0.045818\n",
      "3     C4.5+m vs C4.5+cf        17.0  0.046333   False     0.069499\n",
      "4   C4.5+m vs C4.5+m+cf        22.0  0.327826   False     0.393391\n",
      "5  C4.5+cf vs C4.5+m+cf        10.0  0.022909    True     0.045818\n",
      "                     Vs  Statistics   p-Value  Reject  p_corrected\n",
      "0        C4.5 vs C4.5+m         6.5  0.010757    True     0.045818\n",
      "2     C4.5 vs C4.5+m+cf        11.0  0.015906    True     0.045818\n",
      "5  C4.5+cf vs C4.5+m+cf        10.0  0.022909    True     0.045818\n"
     ]
    }
   ],
   "source": [
    "reject, p_corrected, _, _ = multipletests(R['p-Value'], \n",
    "                                            alpha = 0.05, \n",
    "                                            method = 'fdr_bh')\n",
    "R['p_corrected'] = p_corrected\n",
    "R['Reject'] = reject\n",
    "print(R)\n",
    "print(R[R.p_corrected < 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%pylab inline\n",
    "raw = pd.read_csv(\"botswana.tsv\", delimiter = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ceb</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>religion</th>\n",
       "      <th>idlnchld</th>\n",
       "      <th>knowmeth</th>\n",
       "      <th>usemeth</th>\n",
       "      <th>evermarr</th>\n",
       "      <th>agefm</th>\n",
       "      <th>heduc</th>\n",
       "      <th>urban</th>\n",
       "      <th>electric</th>\n",
       "      <th>radio</th>\n",
       "      <th>tv</th>\n",
       "      <th>bicycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>catholic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "      <td>protestant</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>spirit</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>other</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>other</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ceb  age  educ    religion  idlnchld  knowmeth  usemeth  evermarr  agefm  \\\n",
       "0    0   18    10    catholic       4.0       1.0      1.0         0    NaN   \n",
       "1    2   43    11  protestant       2.0       1.0      1.0         1   20.0   \n",
       "2    0   49     4      spirit       4.0       1.0      0.0         1   22.0   \n",
       "3    0   24    12       other       2.0       1.0      0.0         0    NaN   \n",
       "4    3   32    13       other       3.0       1.0      1.0         1   24.0   \n",
       "\n",
       "   heduc  urban  electric  radio   tv  bicycle  \n",
       "0    NaN      1       1.0    1.0  1.0      1.0  \n",
       "1   14.0      1       1.0    1.0  1.0      1.0  \n",
       "2    1.0      1       1.0    1.0  0.0      0.0  \n",
       "3    NaN      1       1.0    1.0  1.0      1.0  \n",
       "4   12.0      1       1.0    1.0  1.0      1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = raw\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ceb</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>idlnchld</th>\n",
       "      <th>knowmeth</th>\n",
       "      <th>usemeth</th>\n",
       "      <th>evermarr</th>\n",
       "      <th>agefm</th>\n",
       "      <th>heduc</th>\n",
       "      <th>urban</th>\n",
       "      <th>electric</th>\n",
       "      <th>radio</th>\n",
       "      <th>tv</th>\n",
       "      <th>bicycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>4361.000000</td>\n",
       "      <td>4361.000000</td>\n",
       "      <td>4361.000000</td>\n",
       "      <td>4241.000000</td>\n",
       "      <td>4354.000000</td>\n",
       "      <td>4290.000000</td>\n",
       "      <td>4361.000000</td>\n",
       "      <td>2079.000000</td>\n",
       "      <td>1956.000000</td>\n",
       "      <td>4361.000000</td>\n",
       "      <td>4358.000000</td>\n",
       "      <td>4359.000000</td>\n",
       "      <td>4359.000000</td>\n",
       "      <td>4358.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>2.441642</td>\n",
       "      <td>27.405182</td>\n",
       "      <td>5.855996</td>\n",
       "      <td>4.615892</td>\n",
       "      <td>0.963252</td>\n",
       "      <td>0.577622</td>\n",
       "      <td>0.476726</td>\n",
       "      <td>20.686388</td>\n",
       "      <td>5.144683</td>\n",
       "      <td>0.516625</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.701766</td>\n",
       "      <td>0.092911</td>\n",
       "      <td>0.275815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2.406861</td>\n",
       "      <td>8.685233</td>\n",
       "      <td>3.927075</td>\n",
       "      <td>2.219303</td>\n",
       "      <td>0.188164</td>\n",
       "      <td>0.493996</td>\n",
       "      <td>0.499515</td>\n",
       "      <td>5.002383</td>\n",
       "      <td>4.803028</td>\n",
       "      <td>0.499781</td>\n",
       "      <td>0.347236</td>\n",
       "      <td>0.457535</td>\n",
       "      <td>0.290341</td>\n",
       "      <td>0.446975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ceb          age         educ     idlnchld     knowmeth  \\\n",
       "count  4361.000000  4361.000000  4361.000000  4241.000000  4354.000000   \n",
       "mean      2.441642    27.405182     5.855996     4.615892     0.963252   \n",
       "std       2.406861     8.685233     3.927075     2.219303     0.188164   \n",
       "min       0.000000    15.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000    20.000000     3.000000     3.000000     1.000000   \n",
       "50%       2.000000    26.000000     7.000000     4.000000     1.000000   \n",
       "75%       4.000000    33.000000     8.000000     6.000000     1.000000   \n",
       "max      13.000000    49.000000    20.000000    20.000000     1.000000   \n",
       "\n",
       "           usemeth     evermarr        agefm        heduc        urban  \\\n",
       "count  4290.000000  4361.000000  2079.000000  1956.000000  4361.000000   \n",
       "mean      0.577622     0.476726    20.686388     5.144683     0.516625   \n",
       "std       0.493996     0.499515     5.002383     4.803028     0.499781   \n",
       "min       0.000000     0.000000    10.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000    17.000000     0.000000     0.000000   \n",
       "50%       1.000000     0.000000    20.000000     6.000000     1.000000   \n",
       "75%       1.000000     1.000000    23.000000     8.000000     1.000000   \n",
       "max       1.000000     1.000000    46.000000    20.000000     1.000000   \n",
       "\n",
       "          electric        radio           tv      bicycle  \n",
       "count  4358.000000  4359.000000  4359.000000  4358.000000  \n",
       "mean      0.140202     0.701766     0.092911     0.275815  \n",
       "std       0.347236     0.457535     0.290341     0.446975  \n",
       "min       0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     1.000000     0.000000     0.000000  \n",
       "75%       0.000000     1.000000     0.000000     1.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "religion feature value counts:  4\n"
     ]
    }
   ],
   "source": [
    "print(\"religion feature value counts: \", len(set(data.religion.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1834, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = data.dropna(how = 'any', inplace = False)\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/al_cher/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "data['nevermarr'] = data['agefm'].apply(lambda x : 1 if x != x else 0)\n",
    "data.drop('evermarr', axis = 1, inplace = True)\n",
    "data['agefm'].fillna(0, inplace =  True)\n",
    "data['heduc'].loc[data['nevermarr'] == 1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs residual  in heduc feature:  123\n"
     ]
    }
   ],
   "source": [
    "print (\"NaNs residual  in heduc feature: \", \n",
    "       data[data.heduc.isna()].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape is: (4348, 18)\n",
      "78264\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ceb</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>idlnchld</th>\n",
       "      <th>knowmeth</th>\n",
       "      <th>usemeth</th>\n",
       "      <th>agefm</th>\n",
       "      <th>heduc</th>\n",
       "      <th>urban</th>\n",
       "      <th>electric</th>\n",
       "      <th>radio</th>\n",
       "      <th>tv</th>\n",
       "      <th>bicycle</th>\n",
       "      <th>nevermarr</th>\n",
       "      <th>idlnchld_noans</th>\n",
       "      <th>heduc_noans</th>\n",
       "      <th>usemeth_noans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>4348.000000</td>\n",
       "      <td>4348.000000</td>\n",
       "      <td>4348.000000</td>\n",
       "      <td>4348.000000</td>\n",
       "      <td>4348.000000</td>\n",
       "      <td>4348.000000</td>\n",
       "      <td>4348.000000</td>\n",
       "      <td>4348.000000</td>\n",
       "      <td>4348.000000</td>\n",
       "      <td>4348.000000</td>\n",
       "      <td>4348.000000</td>\n",
       "      <td>4348.000000</td>\n",
       "      <td>4348.000000</td>\n",
       "      <td>4348.000000</td>\n",
       "      <td>4348.000000</td>\n",
       "      <td>4348.000000</td>\n",
       "      <td>4348.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>2.437443</td>\n",
       "      <td>27.393514</td>\n",
       "      <td>5.863155</td>\n",
       "      <td>4.466191</td>\n",
       "      <td>0.963431</td>\n",
       "      <td>0.553818</td>\n",
       "      <td>9.850736</td>\n",
       "      <td>1.730451</td>\n",
       "      <td>0.517249</td>\n",
       "      <td>0.140064</td>\n",
       "      <td>0.701702</td>\n",
       "      <td>0.092916</td>\n",
       "      <td>0.275299</td>\n",
       "      <td>0.523919</td>\n",
       "      <td>0.027139</td>\n",
       "      <td>0.028059</td>\n",
       "      <td>0.015179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2.401785</td>\n",
       "      <td>8.675630</td>\n",
       "      <td>3.922694</td>\n",
       "      <td>2.372879</td>\n",
       "      <td>0.187722</td>\n",
       "      <td>0.526808</td>\n",
       "      <td>10.897246</td>\n",
       "      <td>4.459982</td>\n",
       "      <td>0.499760</td>\n",
       "      <td>0.347094</td>\n",
       "      <td>0.457564</td>\n",
       "      <td>0.290348</td>\n",
       "      <td>0.446716</td>\n",
       "      <td>0.499485</td>\n",
       "      <td>0.162507</td>\n",
       "      <td>0.165160</td>\n",
       "      <td>0.122280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ceb          age         educ     idlnchld     knowmeth  \\\n",
       "count  4348.000000  4348.000000  4348.000000  4348.000000  4348.000000   \n",
       "mean      2.437443    27.393514     5.863155     4.466191     0.963431   \n",
       "std       2.401785     8.675630     3.922694     2.372879     0.187722   \n",
       "min       0.000000    15.000000     0.000000    -1.000000     0.000000   \n",
       "25%       1.000000    20.000000     3.000000     3.000000     1.000000   \n",
       "50%       2.000000    26.000000     7.000000     4.000000     1.000000   \n",
       "75%       4.000000    33.000000     8.000000     6.000000     1.000000   \n",
       "max      13.000000    49.000000    20.000000    20.000000     1.000000   \n",
       "\n",
       "           usemeth        agefm        heduc        urban     electric  \\\n",
       "count  4348.000000  4348.000000  4348.000000  4348.000000  4348.000000   \n",
       "mean      0.553818     9.850736     1.730451     0.517249     0.140064   \n",
       "std       0.526808    10.897246     4.459982     0.499760     0.347094   \n",
       "min      -1.000000     0.000000    -2.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000    -1.000000     0.000000     0.000000   \n",
       "50%       1.000000     0.000000    -1.000000     1.000000     0.000000   \n",
       "75%       1.000000    19.000000     4.000000     1.000000     0.000000   \n",
       "max       1.000000    46.000000    20.000000     1.000000     1.000000   \n",
       "\n",
       "             radio           tv      bicycle    nevermarr  idlnchld_noans  \\\n",
       "count  4348.000000  4348.000000  4348.000000  4348.000000     4348.000000   \n",
       "mean      0.701702     0.092916     0.275299     0.523919        0.027139   \n",
       "std       0.457564     0.290348     0.446716     0.499485        0.162507   \n",
       "min       0.000000     0.000000     0.000000     0.000000        0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000        0.000000   \n",
       "50%       1.000000     0.000000     0.000000     1.000000        0.000000   \n",
       "75%       1.000000     0.000000     1.000000     1.000000        0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000        1.000000   \n",
       "\n",
       "       heduc_noans  usemeth_noans  \n",
       "count  4348.000000    4348.000000  \n",
       "mean      0.028059       0.015179  \n",
       "std       0.165160       0.122280  \n",
       "min       0.000000       0.000000  \n",
       "25%       0.000000       0.000000  \n",
       "50%       0.000000       0.000000  \n",
       "75%       0.000000       0.000000  \n",
       "max       1.000000       1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"idlnchld_noans\"] = data['idlnchld'].apply(lambda x : 1 \n",
    "                                        if x != x else 0)\n",
    "data[\"idlnchld\"].fillna(-1, inplace =  True)\n",
    "data[\"heduc_noans\"] = data['heduc'].apply(lambda x : 1 \n",
    "                                        if x != x else 0)\n",
    "data[\"heduc\"].fillna(-2, inplace =  True)\n",
    "data[\"usemeth_noans\"] = data['usemeth'].apply(lambda x : 1 \n",
    "                                        if x != x else 0)\n",
    "data[\"usemeth\"].fillna(-1, inplace =  True)\n",
    "\n",
    "data.dropna(how = 'any', subset = ['knowmeth', 'electric', 'tv', 'radio', 'bicycle'],\n",
    "           inplace = True)\n",
    "\n",
    "print('New shape is: (%d, %d)' % data.shape)\n",
    "print(data.shape[0] * data.shape[1])\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ceb', 'age', 'educ', 'religion', 'idlnchld', 'knowmeth', 'usemeth',\n",
      "       'agefm', 'heduc', 'urban', 'electric', 'radio', 'tv', 'bicycle',\n",
      "       'nevermarr', 'idlnchld_noans', 'heduc_noans', 'usemeth_noans'],\n",
      "      dtype='object')\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    ceb   R-squared:                       0.644\n",
      "Model:                            OLS   Adj. R-squared:                  0.643\n",
      "Method:                 Least Squares   F-statistic:                     412.5\n",
      "Date:                Sat, 28 Mar 2020   Prob (F-statistic):               0.00\n",
      "Time:                        21:38:14   Log-Likelihood:                -7732.1\n",
      "No. Observations:                4348   AIC:                         1.550e+04\n",
      "Df Residuals:                    4328   BIC:                         1.563e+04\n",
      "Df Model:                          19                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "Intercept                 -1.0263      0.212     -4.835      0.000      -1.443      -0.610\n",
      "religion[T.other]         -0.0830      0.083     -1.001      0.317      -0.245       0.080\n",
      "religion[T.protestant]    -0.0149      0.082     -0.181      0.857      -0.176       0.146\n",
      "religion[T.spirit]        -0.0191      0.077     -0.248      0.804      -0.171       0.132\n",
      "age                        0.1703      0.003     51.891      0.000       0.164       0.177\n",
      "educ                      -0.0724      0.007     -9.843      0.000      -0.087      -0.058\n",
      "idlnchld                   0.0760      0.011      6.923      0.000       0.054       0.098\n",
      "knowmeth                   0.5564      0.121      4.580      0.000       0.318       0.795\n",
      "usemeth                    0.6473      0.048     13.424      0.000       0.553       0.742\n",
      "agefm                     -0.0604      0.007     -9.213      0.000      -0.073      -0.048\n",
      "heduc                     -0.0551      0.008     -6.838      0.000      -0.071      -0.039\n",
      "urban                     -0.2137      0.047     -4.527      0.000      -0.306      -0.121\n",
      "electric                  -0.2685      0.077     -3.479      0.001      -0.420      -0.117\n",
      "radio                     -0.0235      0.051     -0.461      0.645      -0.123       0.076\n",
      "tv                        -0.1451      0.093     -1.566      0.118      -0.327       0.037\n",
      "bicycle                    0.2139      0.050      4.260      0.000       0.115       0.312\n",
      "nevermarr                 -2.2393      0.148    -15.143      0.000      -2.529      -1.949\n",
      "idlnchld_noans             0.6539      0.153      4.286      0.000       0.355       0.953\n",
      "heduc_noans               -0.8724      0.145     -6.026      0.000      -1.156      -0.589\n",
      "usemeth_noans              0.7652      0.196      3.910      0.000       0.382       1.149\n",
      "==============================================================================\n",
      "Omnibus:                      224.411   Durbin-Watson:                   1.887\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              859.014\n",
      "Skew:                           0.003   Prob(JB):                    2.93e-187\n",
      "Kurtosis:                       5.178   Cond. No.                         361.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "print(data.columns)\n",
    "m1 = smf.ols('ceb ~ age + educ + religion + idlnchld + knowmeth + usemeth +' \\\n",
    "             ' agefm + heduc + urban + electric + radio + tv +'\\\n",
    "             ' bicycle + nevermarr + idlnchld_noans + heduc_noans + usemeth_noans', data = data)\n",
    "fitted = m1.fit()\n",
    "print(fitted.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breusch-Pagan test: (1120.1205909391385, 1.1452927633437192e-225, 79.04622432815994, 2.0791008841131832e-262)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.graphics.regressionplots import plot_leverage_resid2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('Breusch-Pagan test:', \n",
    "      sms.het_breuschpagan(fitted.resid, fitted.model.exog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    ceb   R-squared:                       0.644\n",
      "Model:                            OLS   Adj. R-squared:                  0.643\n",
      "Method:                 Least Squares   F-statistic:                     345.0\n",
      "Date:                Sat, 28 Mar 2020   Prob (F-statistic):               0.00\n",
      "Time:                        21:38:14   Log-Likelihood:                -7732.1\n",
      "No. Observations:                4348   AIC:                         1.550e+04\n",
      "Df Residuals:                    4328   BIC:                         1.563e+04\n",
      "Df Model:                          19                                         \n",
      "Covariance Type:                  HC1                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "Intercept                 -1.0263      0.266     -3.863      0.000      -1.547      -0.506\n",
      "religion[T.other]         -0.0830      0.078     -1.067      0.286      -0.235       0.069\n",
      "religion[T.protestant]    -0.0149      0.078     -0.192      0.848      -0.167       0.137\n",
      "religion[T.spirit]        -0.0191      0.071     -0.268      0.789      -0.159       0.121\n",
      "age                        0.1703      0.004     38.627      0.000       0.162       0.179\n",
      "educ                      -0.0724      0.007     -9.924      0.000      -0.087      -0.058\n",
      "idlnchld                   0.0760      0.015      5.236      0.000       0.048       0.104\n",
      "knowmeth                   0.5564      0.174      3.190      0.001       0.215       0.898\n",
      "usemeth                    0.6473      0.052     12.478      0.000       0.546       0.749\n",
      "agefm                     -0.0604      0.010     -6.174      0.000      -0.080      -0.041\n",
      "heduc                     -0.0551      0.009     -6.126      0.000      -0.073      -0.037\n",
      "urban                     -0.2137      0.046     -4.667      0.000      -0.303      -0.124\n",
      "electric                  -0.2685      0.072     -3.732      0.000      -0.410      -0.128\n",
      "radio                     -0.0235      0.053     -0.446      0.656      -0.127       0.080\n",
      "tv                        -0.1451      0.082     -1.766      0.077      -0.306       0.016\n",
      "bicycle                    0.2139      0.048      4.412      0.000       0.119       0.309\n",
      "nevermarr                 -2.2393      0.202    -11.082      0.000      -2.635      -1.843\n",
      "idlnchld_noans             0.6539      0.216      3.029      0.002       0.231       1.077\n",
      "heduc_noans               -0.8724      0.191     -4.556      0.000      -1.248      -0.497\n",
      "usemeth_noans              0.7652      0.213      3.590      0.000       0.347       1.183\n",
      "==============================================================================\n",
      "Omnibus:                      224.411   Durbin-Watson:                   1.887\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              859.014\n",
      "Skew:                           0.003   Prob(JB):                    2.93e-187\n",
      "Kurtosis:                       5.178   Cond. No.                         361.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC1)\n"
     ]
    }
   ],
   "source": [
    "fitted = m1.fit(cov_type = \"HC1\")\n",
    "print(fitted.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    ceb   R-squared:                       0.644\n",
      "Model:                            OLS   Adj. R-squared:                  0.643\n",
      "Method:                 Least Squares   F-statistic:                     559.5\n",
      "Date:                Sat, 28 Mar 2020   Prob (F-statistic):               0.00\n",
      "Time:                        21:38:15   Log-Likelihood:                -7734.5\n",
      "No. Observations:                4348   AIC:                         1.550e+04\n",
      "Df Residuals:                    4333   BIC:                         1.559e+04\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept         -1.0698      0.198     -5.393      0.000      -1.459      -0.681\n",
      "age                0.1702      0.003     52.271      0.000       0.164       0.177\n",
      "educ              -0.0729      0.007    -10.285      0.000      -0.087      -0.059\n",
      "idlnchld           0.0770      0.011      7.042      0.000       0.056       0.098\n",
      "knowmeth           0.5610      0.121      4.628      0.000       0.323       0.799\n",
      "usemeth            0.6516      0.048     13.537      0.000       0.557       0.746\n",
      "agefm             -0.0606      0.007     -9.240      0.000      -0.073      -0.048\n",
      "heduc             -0.0573      0.008     -7.186      0.000      -0.073      -0.042\n",
      "urban             -0.2190      0.047     -4.682      0.000      -0.311      -0.127\n",
      "electric          -0.3207      0.070     -4.584      0.000      -0.458      -0.184\n",
      "bicycle            0.2046      0.049      4.154      0.000       0.108       0.301\n",
      "nevermarr         -2.2501      0.148    -15.231      0.000      -2.540      -1.961\n",
      "idlnchld_noans     0.6565      0.152      4.310      0.000       0.358       0.955\n",
      "heduc_noans       -0.8853      0.145     -6.122      0.000      -1.169      -0.602\n",
      "usemeth_noans      0.7732      0.196      3.955      0.000       0.390       1.156\n",
      "==============================================================================\n",
      "Omnibus:                      224.096   Durbin-Watson:                   1.886\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              856.760\n",
      "Skew:                           0.004   Prob(JB):                    9.06e-187\n",
      "Kurtosis:                       5.175   Cond. No.                         345.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "m2 = smf.ols('ceb ~ age + educ + idlnchld + knowmeth + ' + \n",
    "             'usemeth + agefm + heduc + urban + electric + bicycle + '\n",
    "                + 'nevermarr + idlnchld_noans + heduc_noans + usemeth_noans', data = data)\n",
    "fitted2 = m2.fit()\n",
    "print(fitted2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breusch-Pagan test: (1112.4700385717542, 1.1197458896534061e-228, 106.4151718706295, 3.592611312533355e-265)\n"
     ]
    }
   ],
   "source": [
    "print('Breusch-Pagan test:', \n",
    "      sms.het_breuschpagan(fitted2.resid, fitted2.model.exog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    ceb   R-squared:                       0.644\n",
      "Model:                            OLS   Adj. R-squared:                  0.643\n",
      "Method:                 Least Squares   F-statistic:                     463.4\n",
      "Date:                Sat, 28 Mar 2020   Prob (F-statistic):               0.00\n",
      "Time:                        21:38:15   Log-Likelihood:                -7734.5\n",
      "No. Observations:                4348   AIC:                         1.550e+04\n",
      "Df Residuals:                    4333   BIC:                         1.559e+04\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:                  HC1                                         \n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept         -1.0698      0.258     -4.152      0.000      -1.575      -0.565\n",
      "age                0.1702      0.004     38.746      0.000       0.162       0.179\n",
      "educ              -0.0729      0.007    -10.311      0.000      -0.087      -0.059\n",
      "idlnchld           0.0770      0.014      5.323      0.000       0.049       0.105\n",
      "knowmeth           0.5610      0.174      3.224      0.001       0.220       0.902\n",
      "usemeth            0.6516      0.052     12.571      0.000       0.550       0.753\n",
      "agefm             -0.0606      0.010     -6.192      0.000      -0.080      -0.041\n",
      "heduc             -0.0573      0.009     -6.440      0.000      -0.075      -0.040\n",
      "urban             -0.2190      0.045     -4.814      0.000      -0.308      -0.130\n",
      "electric          -0.3207      0.063     -5.076      0.000      -0.445      -0.197\n",
      "bicycle            0.2046      0.048      4.279      0.000       0.111       0.298\n",
      "nevermarr         -2.2501      0.202    -11.158      0.000      -2.645      -1.855\n",
      "idlnchld_noans     0.6565      0.216      3.043      0.002       0.234       1.079\n",
      "heduc_noans       -0.8853      0.191     -4.638      0.000      -1.259      -0.511\n",
      "usemeth_noans      0.7732      0.212      3.639      0.000       0.357       1.190\n",
      "==============================================================================\n",
      "Omnibus:                      224.096   Durbin-Watson:                   1.886\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              856.760\n",
      "Skew:                           0.004   Prob(JB):                    9.06e-187\n",
      "Kurtosis:                       5.175   Cond. No.                         345.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC1)\n"
     ]
    }
   ],
   "source": [
    "fitted2 = m2.fit(cov_type = \"HC1\")\n",
    "print(fitted2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F=0.919236, p=0.467231, k1=5.000000\n"
     ]
    }
   ],
   "source": [
    "print(\"F=%f, p=%f, k1=%f\" % m1.fit().compare_f_test(m2.fit()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    ceb   R-squared:                       0.629\n",
      "Model:                            OLS   Adj. R-squared:                  0.628\n",
      "Method:                 Least Squares   F-statistic:                     396.0\n",
      "Date:                Sat, 28 Mar 2020   Prob (F-statistic):               0.00\n",
      "Time:                        21:38:18   Log-Likelihood:                -7825.7\n",
      "No. Observations:                4348   AIC:                         1.568e+04\n",
      "Df Residuals:                    4335   BIC:                         1.576e+04\n",
      "Df Model:                          12                                         \n",
      "Covariance Type:                  HC2                                         \n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept         -1.1931      0.262     -4.551      0.000      -1.707      -0.679\n",
      "age                0.1776      0.004     41.549      0.000       0.169       0.186\n",
      "educ              -0.0560      0.007     -7.782      0.000      -0.070      -0.042\n",
      "idlnchld           0.0705      0.015      4.738      0.000       0.041       0.100\n",
      "knowmeth           0.8739      0.174      5.012      0.000       0.532       1.216\n",
      "agefm             -0.0649      0.010     -6.471      0.000      -0.085      -0.045\n",
      "heduc             -0.0521      0.009     -5.653      0.000      -0.070      -0.034\n",
      "urban             -0.1866      0.046     -4.016      0.000      -0.278      -0.096\n",
      "electric          -0.3218      0.065     -4.948      0.000      -0.449      -0.194\n",
      "bicycle            0.1979      0.048      4.081      0.000       0.103       0.293\n",
      "nevermarr         -2.3625      0.206    -11.471      0.000      -2.766      -1.959\n",
      "idlnchld_noans     0.5266      0.226      2.333      0.020       0.084       0.969\n",
      "heduc_noans       -0.7947      0.196     -4.054      0.000      -1.179      -0.411\n",
      "==============================================================================\n",
      "Omnibus:                      250.641   Durbin-Watson:                   1.910\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              936.515\n",
      "Skew:                          -0.158   Prob(JB):                    4.35e-204\n",
      "Kurtosis:                       5.251   Cond. No.                         345.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC2)\n"
     ]
    }
   ],
   "source": [
    "m3 = smf.ols('ceb ~ age + educ + idlnchld + knowmeth + ' + \n",
    "             'agefm + heduc + urban + electric + bicycle + '\n",
    "                + 'nevermarr + idlnchld_noans + heduc_noans', data = data)\n",
    "fitted3 = m3.fit(cov_type = \"HC2\")\n",
    "print(fitted3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92.89058230109713, 3.155200948040263e-40, 2.0)\n"
     ]
    }
   ],
   "source": [
    "print(m2.fit().compare_f_test(m3.fit()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
