{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"coursera_sessions_train.txt\", \"r\") as f:\n",
    "    train = f.read().splitlines()\n",
    "with open(\"coursera_sessions_test.txt\", \"r\") as f:\n",
    "    test = f.read().splitlines()\n",
    "def save_answerArray(fname, array):\n",
    "    with open(fname,\"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in array]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Описание задачи**\n",
    "\n",
    "Небольшой интернет-магазин попросил вас добавить ранжирование товаров в блок \"Смотрели ранее\" - в нем теперь надо показывать не последние просмотренные пользователем товары, а те товары из просмотренных, которые он наиболее вероятно купит. Качество вашего решения будет оцениваться по количеству покупок в сравнении с прошлым решением в ходе А/В теста, т.к. по доходу от продаж статзначимость будет достигаться дольше из-за разброса цен. Таким образом, ничего заранее не зная про корреляцию оффлайновых и онлайновых метрик качества, в начале проекта вы можете лишь постараться оптимизировать recall@k и precision@k.\n",
    "\n",
    "Это задание посвящено построению простых бейзлайнов для этой задачи: ранжирование просмотренных товаров по частоте просмотров и по частоте покупок. Эти бейзлайны, с одной стороны, могут помочь вам грубо оценить возможный эффект от ранжирования товаров в блоке - например, чтобы вписать какие-то числа в коммерческое предложение заказчику, а с другой стороны, могут оказаться самым хорошим вариантом, если данных очень мало (недостаточно для обучения даже простых моделей).\n",
    "\n",
    "**Входные данные**\n",
    "\n",
    "Вам дается две выборки с пользовательскими сессиями - id-шниками просмотренных и id-шниками купленных товаров. Одна выборка будет использоваться для обучения (оценки популярностей товаров), а другая - для теста.\n",
    "\n",
    "В файлах записаны сессии по одной в каждой строке. Формат сессии: id просмотренных товаров через , затем идёт ; после чего следуют id купленных товаров (если такие имеются), разделённые запятой. Например, 1,2,3,4; или 1,2,3,4;5,6.\n",
    "\n",
    "Гарантируется, что среди id купленных товаров все различные.\n",
    "\n",
    "**Важно:**\n",
    "\n",
    "* Сессии, в которых пользователь ничего не купил, исключаем из оценки качества.\n",
    "* Если товар не встречался в обучающей выборке, его популярность равна 0.\n",
    "* Рекомендуем разные товары. И их число должно быть не больше, чем количество различных просмотренных пользователем товаров.\n",
    "* Рекомендаций всегда не больше, чем минимум из двух чисел: количество просмотренных пользователем товаров и k в recall@k / precision@k.\n",
    "\n",
    "**Задание**\n",
    "\n",
    "1. На обучении постройте частоты появления id в просмотренных и в купленных (id может несколько раз появляться в просмотренных, все появления надо учитывать)\n",
    "2. Реализуйте два алгоритма рекомендаций:\n",
    "    * сортировка просмотренных id по популярности (частота появления в просмотренных),\n",
    "    * сортировка просмотренных id по покупаемости (частота появления в покупках).\n",
    "3. Для данных алгоритмов выпишите через пробел **AverageRecall@1, AveragePrecision@1, AverageRecall@5, AveragePrecision@5** на обучающей и тестовых выборках, округляя до 2 знака после запятой. Это будут ваши ответы в этом задании. Посмотрите, как они соотносятся друг с другом. Где качество получилось выше? Значимо ли это различие? Обратите внимание на различие качества на обучающей и тестовой выборке в случае рекомендаций по частотам покупки.\n",
    "\n",
    "Если частота одинаковая, то сортировать нужно по возрастанию момента просмотра (чем раньше появился в просмотренных, тем больше приоритет)\n",
    "\n",
    "**Дополнительные вопросы**\n",
    "\n",
    "* Обратите внимание, что при сортировке по покупаемости возникает много товаров с одинаковым рангом - это означает, что значение метрик будет зависеть от того, как мы будем сортировать товары с одинаковым рангом. Попробуйте убедиться, что при изменении сортировки таких товаров **recall@k** меняется. Подумайте, как оценить минимальное и максимальное значение **recall@k** в зависимости от правила сортировки.\n",
    "* Мы обучаемся и тестируемся на полных сессиях (в которых есть все просмотренные за сессию товары). Подумайте, почему полученная нами оценка качества рекомендаций в этом случае несколько завышена.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split to looks and purchases sorting by freq of of looks/purchases\n",
    "def make_split(x):\n",
    "    purchases = []\n",
    "    looks = []\n",
    "    for session in x:\n",
    "        l, p = session.split(';')\n",
    "        l = [int(t) for t in l.split(',')]\n",
    "        if len(p) > 0:\n",
    "            p = [int(t) for t in p.split(',')]\n",
    "        else:\n",
    "            p = []\n",
    "        looks.append(l)\n",
    "        purchases.append(p)    \n",
    "    looks_unique = np.transpose(np.unique(np.array([id_ for sess in looks for id_ in sess]),\n",
    "                                              return_counts = True))\n",
    "    purchases_unique = np.transpose(np.unique(np.array([id_ for sess in purchases for id_ in sess]),\n",
    "                                              return_counts = True))\n",
    "    return looks_unique, purchases_unique, purchases, looks\n",
    "\n",
    "looks_unique, purchases_unique, purchases, looks = make_split(train)\n",
    "looks_unique = looks_unique[looks_unique[:, 1].argsort()][::-1]\n",
    "purchases_unique = purchases_unique[purchases_unique[:, 1].argsort()][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_looks_unique, test_purchases_unique, test_purchases, test_looks = make_split(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining metrics\n",
    "def precision_recall_metrics(session, reccomendations, k):\n",
    "    purchase = 0\n",
    "    for ind in reccomendations:\n",
    "        if ind in session:\n",
    "            purchase += 1 \n",
    "    precision = purchase / k\n",
    "    recall = purchase / len(session)\n",
    "    return(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#by populartity\n",
    "k1 = 1; k5 = 5\n",
    "prec_k1, prec_k5 = [], []\n",
    "recall_k1, recall_k5 = [], []\n",
    "\n",
    "for index, session in enumerate(purchases):\n",
    "    if session == []:\n",
    "        continue\n",
    "        \n",
    "    corresp_looks = looks[index]\n",
    "    looks_session = []\n",
    "    \n",
    "    for jndex in range(len(corresp_looks)):\n",
    "        looks_session.append(np.where(looks_unique[:, 0] == corresp_looks[jndex])[0][0])\n",
    "        \n",
    "    unique_looks_session = np.unique(looks_session)\n",
    "    \n",
    "    # k1 recommendations\n",
    "    num_of_recs_k1 = min(k1, len(corresp_looks))\n",
    "    if num_of_recs_k1 != 0: \n",
    "        recs_k1 = looks_unique[unique_looks_session[:num_of_recs_k1], 0]\n",
    "    \n",
    "    # k1 metrics\n",
    "    prec_1, rec_1 = precision_recall_metrics(session, recs_k1, k1)\n",
    "    prec_k1.append(prec_1)\n",
    "    recall_k1.append(rec_1)\n",
    "    \n",
    "    # k5 recommendations\n",
    "    num_of_recs_k5 = min(k5, len(corresp_looks))\n",
    "    if num_of_recs_k5 != 0:\n",
    "        recs_k5 = looks_unique[unique_looks_session[:num_of_recs_k5], 0]\n",
    "    \n",
    "    # k5 metrics\n",
    "    prec_5, rec_5 = precision_recall_metrics(session, recs_k5, k5)\n",
    "    prec_k5.append(prec_5)\n",
    "    recall_k5.append(rec_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44\n",
      "0.51\n",
      "0.83\n",
      "0.21\n"
     ]
    }
   ],
   "source": [
    "print(round(np.mean(recall_k1), 2))\n",
    "print(round(np.mean(prec_k1), 2))\n",
    "print(round(np.mean(recall_k5), 2))\n",
    "print(round(np.mean(prec_k5), 2))\n",
    "#save_answerArray(\"A__3.txt\", [0.40, 0.46, 0.79, 0.20])\n",
    "#save_answerArray(\"A__1.txt\", [0.44, 0.51, 0.83, 0.21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#by purchases\n",
    "prec_k1, prec_k5 = [], []\n",
    "recall_k1, recall_k5 = [], []\n",
    "\n",
    "for index, _session in enumerate(purchases):\n",
    "    if _session == []:\n",
    "        continue\n",
    "        \n",
    "    corresp_looks = looks[index]\n",
    "    session = []\n",
    "    \n",
    "    for jndex in range(len(corresp_looks)):\n",
    "        if corresp_looks[jndex] in purchases_unique[:, 0]: \n",
    "            session.append(np.where(purchases_unique[:, 0] == corresp_looks[jndex])[0][0])\n",
    "            \n",
    "    unique_session = np.unique(session)\n",
    "\n",
    "    # k1 recommendations\n",
    "    num_of_recs_k1 = min(k1, len(unique_session))\n",
    "    if num_of_recs_k1 != 0:\n",
    "        recs_k1 = purchases_unique[unique_session[:num_of_recs_k1], 0]\n",
    "\n",
    "    # k1 metrics\n",
    "    prec_1, rec_1 = precision_recall_metrics(_session, recs_k1, k1)\n",
    "    prec_k1.append(prec_1)\n",
    "    recall_k1.append(rec_1)\n",
    "\n",
    "    # k5 recommendations\n",
    "    num_of_recs_k5 = min(k5, len(unique_session))\n",
    "    if num_of_recs_k5 != 0:\n",
    "        recs_k5 = purchases_unique[unique_session[:num_of_recs_k5], 0]\n",
    "\n",
    "    # k5 metrics\n",
    "    prec_5, rec_5 = precision_recall_metrics(_session, recs_k5, k5)\n",
    "    prec_k5.append(prec_5)\n",
    "    recall_k5.append(rec_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67\n",
      "0.79\n",
      "0.93\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "print(round(np.mean(recall_k1), 2))\n",
    "print(round(np.mean(prec_k1), 2))\n",
    "print(round(np.mean(recall_k5), 2))\n",
    "print(round(np.mean(prec_k5), 2))\n",
    "#save_answerArray(\"A__4.txt\", [0.64, 0.74, 0.91, 0.25])\n",
    "#save_answerArray(\"A__2.txt\", [0.68, 0.79, 0.93, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#by populartity -- test\n",
    "k1 = 1; k5 = 5\n",
    "prec_k1, prec_k5 = [], []\n",
    "recall_k1, recall_k5 = [], []\n",
    "for index, session in enumerate(test_purchases):\n",
    "    if session == []:\n",
    "        continue\n",
    "        \n",
    "    corresp_looks = test_looks[index]\n",
    "    looks_session = []\n",
    "    new_ids = []\n",
    "    \n",
    "    for jndex in range(len(corresp_looks)):\n",
    "        if corresp_looks[jndex] not in looks_unique[:, 0]:\n",
    "            new_ids.append(corresp_looks[jndex])\n",
    "            continue\n",
    "        looks_session.append(np.where(looks_unique[:, 0] == corresp_looks[jndex])[0][0])\n",
    "        \n",
    "    unique_looks_session = np.unique(looks_session)\n",
    "    \n",
    "    # k1 recommendations\n",
    "    num_of_recs_k1 = min(k1, len(corresp_looks))\n",
    "    if num_of_recs_k1 != 0: \n",
    "        if looks_session != []:\n",
    "            recs_k1 = looks_unique[unique_looks_session[:num_of_recs_k1],0]\n",
    "        else:\n",
    "            recs_k1 = []\n",
    "        recs_k1 = np.concatenate((np.array(recs_k1),\n",
    "                                  np.unique(np.array(new_ids))))[:num_of_recs_k1]    \n",
    "  \n",
    "    # k1 metrics\n",
    "    prec_1, rec_1 = precision_recall_metrics(session, recs_k1, k1)\n",
    "    prec_k1.append(prec_1)\n",
    "    recall_k1.append(rec_1)\n",
    "    \n",
    "    # k5 recommendations\n",
    "    num_of_recs_k5 = min(k5, len(corresp_looks))\n",
    "    if num_of_recs_k5 != 0: \n",
    "        if looks_session != []:\n",
    "            recs_k5 = looks_unique[unique_looks_session[:num_of_recs_k5], 0]\n",
    "        else:\n",
    "            recs_k5 = []\n",
    "        recs_k5 = np.concatenate((np.array(recs_k5),\n",
    "                                  np.unique(np.array(new_ids))))[:num_of_recs_k5]  \n",
    "    \n",
    "    # k5 metrics\n",
    "    prec_5, rec_5 = precision_recall_metrics(session, recs_k5, k5)\n",
    "    prec_k5.append(prec_5)\n",
    "    recall_k5.append(rec_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42\n",
      "0.48\n",
      "0.8\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "print(round(np.mean(recall_k1), 2))\n",
    "print(round(np.mean(prec_k1), 2))\n",
    "print(round(np.mean(recall_k5), 2))\n",
    "print(round(np.mean(prec_k5), 2))\n",
    "save_answerArray(\"A__3.txt\", [0.42, 0.48, 0.80, 0.20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#by purchases -- test\n",
    "prec_k1, prec_k5 = [], []\n",
    "recall_k1, recall_k5 = [], []\n",
    "\n",
    "def f(seq):\n",
    "    seen = set()\n",
    "    return [x for x in seq if not (x in seen or seen.add(x))]\n",
    "\n",
    "for index, session in enumerate(test_purchases):\n",
    "    if session == []:\n",
    "        continue\n",
    "        \n",
    "    corresp_looks = test_looks[index]\n",
    "    looks_session = []\n",
    "    new_ids = []\n",
    "    \n",
    "    for jndex in range(len(corresp_looks)):\n",
    "        if corresp_looks[jndex] not in purchases_unique[:, 0]:\n",
    "            new_ids.append(corresp_looks[jndex])\n",
    "            continue\n",
    "        looks_session.append(np.where(purchases_unique[:, 0] == corresp_looks[jndex])[0][0])\n",
    "            \n",
    "    unique_session = np.unique(looks_session)\n",
    "\n",
    "    # k1 recommendations\n",
    "    num_of_recs_k1 = min(k1, len(corresp_looks))\n",
    "    if num_of_recs_k1 != 0: \n",
    "        if looks_session != []:\n",
    "            recs_k1 = purchases_unique[unique_session[:num_of_recs_k1],0]\n",
    "        else:\n",
    "            recs_k1 = []\n",
    "    \n",
    "        recs_k1 = np.concatenate((np.array(recs_k1),\n",
    "                                  np.array(f(new_ids))))[:num_of_recs_k1]    \n",
    "  \n",
    "    # k1 metrics\n",
    "    prec_1, rec_1 = precision_recall_metrics(session, recs_k1, k1)\n",
    "    prec_k1.append(prec_1)\n",
    "    recall_k1.append(rec_1)\n",
    "    \n",
    "    # k5 recommendations\n",
    "    num_of_recs_k5 = min(k5, len(corresp_looks))\n",
    "    if num_of_recs_k5 != 0: \n",
    "        if looks_session != []:\n",
    "            recs_k5 = purchases_unique[unique_session[:num_of_recs_k5], 0]\n",
    "        else:\n",
    "            recs_k5 = []\n",
    "   \n",
    "        recs_k5 = np.concatenate((np.array(recs_k5),\n",
    "                                  np.array(f(new_ids))))[:num_of_recs_k5]    \n",
    "    # k5 metrics\n",
    "    prec_5, rec_5 = precision_recall_metrics(session, recs_k5, k5)\n",
    "    prec_k5.append(prec_5)\n",
    "    recall_k5.append(rec_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46\n",
      "0.52\n",
      "0.82\n",
      "0.21\n"
     ]
    }
   ],
   "source": [
    "print(round(np.mean(recall_k1), 2))\n",
    "print(round(np.mean(prec_k1), 2))\n",
    "print(round(np.mean(recall_k5), 2))\n",
    "print(round(np.mean(prec_k5), 2))\n",
    "save_answerArray(\"A__4.txt\", [0.46, 0.52, 0.82, 0.21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
