{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "name": "Lab2_DL_part3_poetry.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexunderch/Bachelor_materials/blob/main/Lab2_DL_part3_poetry.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQHA7SXRf7g7"
      },
      "source": [
        "## Lab 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kjb4VH0Cf7g9"
      },
      "source": [
        "### Part 3. Poetry generation\n",
        "\n",
        "Let's try to generate some poetry using RNNs. \n",
        "\n",
        "You have several choices here: \n",
        "\n",
        "* The Shakespeare sonnets, file `sonnets.txt` available in the notebook directory.\n",
        "\n",
        "* Роман в стихах \"Евгений Онегин\" Александра Сергеевича Пушкина. В предобработанном виде доступен по [ссылке](https://github.com/attatrol/data_sources/blob/master/onegin.txt).\n",
        "\n",
        "* Some other text source, if it will be approved by the course staff.\n",
        "\n",
        "Text generation can be designed in several steps:\n",
        "    \n",
        "1. Data loading.\n",
        "2. Dictionary generation.\n",
        "3. Data preprocessing.\n",
        "4. Model (neural network) training.\n",
        "5. Text generation (model evaluation).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erIwlnwAf7g9"
      },
      "source": [
        "import string\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTQnutfJf7hA"
      },
      "source": [
        "### Data loading: Shakespeare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tX-V8hmqf7hA"
      },
      "source": [
        "Shakespeare sonnets are awailable at this [link](http://www.gutenberg.org/ebooks/1041?msg=welcome_stranger). In addition, they are stored in the same directory as this notebook (`sonnetes.txt`). Simple preprocessing is already done for you in the next cell: all technical info is dropped."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elwM07zPf7hA",
        "outputId": "f8f3de0e-9672-4507-955b-0d58c9aa0bf1"
      },
      "source": [
        "if not os.path.exists('sonnets.txt'):\n",
        "    !wget https://raw.githubusercontent.com/girafe-ai/ml-mipt/master/homeworks_basic/Lab2_DL/sonnets.txt\n",
        "\n",
        "with open('sonnets.txt', 'r') as iofile:\n",
        "    text = iofile.readlines()\n",
        "    \n",
        "TEXT_START = 45\n",
        "TEXT_END = -368\n",
        "text = text[TEXT_START : TEXT_END]\n",
        "assert len(text) == 2616\n",
        "maxlen_ = len(max(text, key = len))\n",
        "print(\"Max seq contains {} symbols\".format(maxlen_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max seq contains 63 symbols\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XMOLdwvf7hE"
      },
      "source": [
        "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
        "\n",
        "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1G4md2Nf7hE",
        "outputId": "5e373b70-d456-4389-93a4-e0db1f5c138d"
      },
      "source": [
        "text = \"\".join([x.lower() for x in text])\n",
        "\n",
        "# Your great code here\n",
        "\n",
        "assert len(text) == 100225, 'Are you sure you have concatenated all the strings?'\n",
        "assert not any([x in set(text) for x in string.ascii_uppercase]), 'Uppercase letters are present'\n",
        "print('OK!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6IQxWp_f7hE"
      },
      "source": [
        "### Data loading: \"Евгений Онегин\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RN7LJgdYf7hF",
        "outputId": "040055ee-847c-483b-ffc2-c2905d0ca95b"
      },
      "source": [
        "if not os.path.exists('onegin.txt'):\n",
        "    !wget https://raw.githubusercontent.com/attatrol/data_sources/master/onegin.txt\n",
        "    \n",
        "with open('onegin.txt', 'r') as iofile:\n",
        "    o_text = iofile.readlines()\n",
        "    \n",
        "o_text = [x.replace('\\t\\t', '') for x in o_text]\n",
        "maxlen = len(max(o_text, key = len))\n",
        "print(\"Max seq contains {} symbols\".format(maxlen))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-08 15:41:36--  https://raw.githubusercontent.com/attatrol/data_sources/master/onegin.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 262521 (256K) [text/plain]\n",
            "Saving to: ‘onegin.txt’\n",
            "\n",
            "onegin.txt          100%[===================>] 256.37K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-12-08 15:41:36 (13.1 MB/s) - ‘onegin.txt’ saved [262521/262521]\n",
            "\n",
            "Max seq contains 159 symbols\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoey6Eb-f7hF"
      },
      "source": [
        "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
        "\n",
        "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnH8-588f7hF"
      },
      "source": [
        "Put all the characters, that you've seen in the text, into variable `tokens`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWuhvALFf7hF",
        "outputId": "0ef51538-58c0-478a-c728-511fb0eefbd5"
      },
      "source": [
        "def prepare_data(text):\n",
        "    text = \"\".join([x.lower() for x in text])\n",
        "    print(\"The lenght of given tokens  = {}\".format(len(o_text)))\n",
        "\n",
        "    tokens = sorted(set(text))\n",
        "    print(\"Number of given tokens  = {}\".format(len(tokens)))\n",
        "\n",
        "    return tokens, text\n",
        "tokens, text = prepare_data(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The lenght of given tokens  = 141888\n",
            "Number of given tokens  = 38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OewJHGzf7hG"
      },
      "source": [
        "\n",
        "Create dictionary `token_to_idx = {<char>: <index>}` and dictionary `idx_to_token = {<index>: <char>}`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKULtmgxf7hG"
      },
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iubwpE3Xf7hH"
      },
      "source": [
        "*Comment: in this task we have only 38 different tokens, so let's use one-hot encoding.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10u_v8g1f7hH"
      },
      "source": [
        "batch_size = 512\n",
        "\n",
        "# def one_hot_encode(sequence, dict_size = len(tokens_sh)):\n",
        "#     seq_len = len(sequence)\n",
        "#     features = np.zeros((seq_len, dict_size), dtype = np.int64)\n",
        "#     features[np.arange(seq_len), [token_to_idx[s] for s in sequence]] = 1\n",
        "\n",
        "#     return features\n",
        "\n",
        "def create_mapping(tokens):\n",
        "    \"\"\"\n",
        "    INPUT: tokens -- sorted set of tokens\n",
        "    OUTPUT: \n",
        "    token_to_idx: dict <index>:<char>\n",
        "    idx_to_token:dict <char>:<index>\n",
        "    \"\"\"\n",
        "    token_to_idx = {token: idx for idx, token in enumerate(tokens)}\n",
        "    idx_to_token = dict(enumerate(tokens))\n",
        "    return token_to_idx, idx_to_token\n",
        "\n",
        "\n",
        "token_to_idx, idx_to_token = create_mapping(tokens)\n",
        "\n",
        "def prepare_set(text, tokens, maxlen, step = 1):\n",
        "    token_to_idx, idx_to_token = create_mapping(tokens)\n",
        "    sentences, next_tokens = [], []\n",
        "    for i in range(0, len(text) - maxlen, step):\n",
        "        sentences.append(text[i : i + maxlen])\n",
        "        next_tokens.append(text[i + maxlen])\n",
        "\n",
        "    print(\"Number of sequences:\", len(sentences))\n",
        "    x = np.zeros((len(sentences), maxlen, len(tokens)))\n",
        "    y = np.zeros((len(sentences), len(tokens)))\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        for t, token in enumerate(sentence):\n",
        "            x[i, t, token_to_idx[token]] = 1\n",
        "        y[i, token_to_idx[next_tokens[i]]] = 1  \n",
        "    return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kgpySksvMbd",
        "outputId": "9b492621-b403-4eda-d73d-505c00b1deb2"
      },
      "source": [
        "x, y = prepare_set(text, tokens, maxlen = 64)\n",
        "print(x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sequences: 100161\n",
            "(100161, 64, 38)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6NE1KLkf7hH"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaH570URf7hH"
      },
      "source": [
        "Now we want to build and train recurrent neural net which would be able to something similar to Shakespeare's poetry.\n",
        "\n",
        "Let's use vanilla RNN, similar to the one created during the lesson."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkWUEOiHf7hH"
      },
      "source": [
        "# Your code here  \n",
        "class VanillaRNN(nn.Module):\n",
        "    def __init__(self, n_tokens = len(tokens), hidden_dim = 128, emb_dim = 128,\n",
        "                 n_layers = 1):\n",
        "        super(VanillaRNN, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.n_tokens = n_tokens\n",
        "        \n",
        "        self.embed = nn.Embedding(n_tokens, self.emb_dim)\n",
        "        self.rnn = nn.RNN(self.emb_dim, self.hidden_dim, batch_first =  True)\n",
        "        self.dropout  = nn.Dropout(.35)\n",
        "        self.hid_to_logits = nn.Linear(self.hidden_dim, n_tokens)\n",
        "    \n",
        "    def forward(self, x, h_prev):\n",
        "        h_seq, h = self.rnn(self.embed(x), h_prev)\n",
        "        h_seq = self.dropout(h_seq)\n",
        "        next_logits = self.hid_to_logits(h_seq)\n",
        "        return next_logits, h\n",
        "    \n",
        "    def initial_state(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfOeS7iYQXBk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jH8TqiJ_f7hH"
      },
      "source": [
        "Plot the loss function (axis X: number of epochs, axis Y: loss function)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "YrxuuLSFjW_A",
        "outputId": "9ba6d33e-eb2d-441d-b2f1-f5ce2a8a4bea"
      },
      "source": [
        "# Your plot code here\n",
        "model_rnn = VanillaRNN()\n",
        "opt = torch.optim.Adam(model_rnn.parameters())\n",
        "model_rnn.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "n_epochs = 45\n",
        "history = []\n",
        "_ = model_rnn.train()\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    ep_history = []\n",
        "    hidden_state = model_rnn.initial_state(batch_size)\n",
        "    for batch_ind in range(batch_size, x.shape[0], batch_size):\n",
        "        \n",
        "        opt.zero_grad()\n",
        "        x_batch = torch.argmax(torch.Tensor(x[batch_ind - batch_size : batch_ind]), dim = -1).to(device)\n",
        "        y_batch = torch.argmax(torch.Tensor(y[batch_ind - batch_size : batch_ind]), dim = -1).to(device)\n",
        "\n",
        "        opt.zero_grad()\n",
        "    \n",
        "        seq, hidden_state = model_rnn(x_batch, hidden_state)\n",
        "        loss = criterion(seq[:, -1].contiguous(), y_batch.contiguous())  \n",
        "        \n",
        "        loss.backward()\n",
        "        opt.step()  \n",
        "        ep_history.append(loss.item())\n",
        "        hidden_state = hidden_state.detach()\n",
        "\n",
        "    history.append(np.mean(ep_history))\n",
        "    print(\"Loss after the epoch # {}\".format(epoch + 1), history[-1])\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label = 'loss')\n",
        "        plt.xlabel(\"n_epochs\")\n",
        "        plt.legend()\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEKCAYAAAACS67iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3RV5Z3/8fc3JyfXkwRIQiBADAjKVcACWkWs9ma91tGu1jq2OlqmM46jP53OtJ01bWdNuzq9jJ12pi1jW4s62tFW26pUrbW2iBcsYLh7odxMuIVALpALycn398fZwYAhCSHJuX1ea52VffZ5cvY3e8EnT56z9/OYuyMiIskvI94FiIjI4FCgi4ikCAW6iEiKUKCLiKQIBbqISIpQoIuIpIg+A93MJpjZ82a2ycw2mtntvbSdb2YdZnbt4JYpIiJ9yexHmw7gLndfY2YFwGoze9bdN3VvZGYh4BvAb4egThER6UOfge7uu4HdwXaTmW0GxgGbjmt6G/AoML8/By4pKfHKysqTKlZEJN2tXr16v7uX9vRaf3roR5lZJTAXWHnc/nHA1cBF9DPQKysrWbVq1ckcXkQk7ZnZjhO91u8PRc0sQqwHfoe7Nx738n8C/+TunX28x2IzW2Vmq2pra/t7aBER6Qfrz1wuZhYGngSecfe7e3h9G2DB0xKgGVjs7r860XvOmzfP1UMXETk5Zrba3ef19FqfQy5mZsBPgM09hTmAu0/s1n4p8GRvYS4iIoOvP2Po5wM3AOvNrCrY90WgAsDdlwxRbSIifWpvb6e6uprW1tZ4lzKocnJyGD9+POFwuN/f05+rXFbwznBKn9z9xn4fXUTkFFVXV1NQUEBlZSWxAYXk5+7U1dVRXV3NxIkT+/6GgO4UFZGk1traSnFxccqEOYCZUVxcfNJ/dSjQRSTppVKYdxnIz5R0gb59/2GWvriNxtb2eJciIpJQki7QN+9u5CtPbKL6QEu8SxERASASicS7BCAJA704kg3A/kNtca5ERCSxJF2gl0SyAKg7rEAXkcTi7nzuc59j5syZzJo1i4cffhiA3bt3s2jRIubMmcPMmTN54YUXiEaj3HjjjUfbfuc73znl45/UXC6JoKuHXnfoSJwrEZFE869PbGTTruNnJjk108sL+fIVM/rV9rHHHqOqqoq1a9eyf/9+5s+fz6JFi3jooYf48Ic/zD//8z8TjUZpbm6mqqqKmpoaNmzYAEB9ff0p15p0PfTCnEzCIWO/Al1EEsyKFSu47rrrCIVClJWVceGFF/KnP/2J+fPn89Of/pSvfOUrrF+/noKCAiZNmsTWrVu57bbbePrppyksLDzl4yddD93MKM7P1hi6iLxLf3vSw23RokUsX76cZcuWceONN3LnnXfyqU99irVr1/LMM8+wZMkSHnnkEe69995TOk7S9dABSgqyqFOgi0iCueCCC3j44YeJRqPU1tayfPlyFixYwI4dOygrK+Mzn/kMt9xyC2vWrGH//v10dnZyzTXX8NWvfpU1a9ac8vGTrocOUJyfTd1hDbmISGK5+uqrefnll5k9ezZmxje/+U3GjBnDfffdx7e+9S3C4TCRSIT777+fmpoabrrpJjo7Y7OOf/3rXz/l4/dr+tyhcCrT5975SBUrtx7gxc9fPMhViUiy2bx5M9OmTYt3GUOip5+tt+lzk3LIpTSSTe2hNuL1y0hEJBElZaAXR7I40tHJobaOeJciIpIwkjPQ83Utuoi8IxX/Wh/Iz5Scga67RUUkkJOTQ11dXUqFetd86Dk5OSf1fUl5lUtJcLdobZN66CLpbvz48VRXV5NqC893rVh0MpI60NVDF5FwOHxSq/qksqQcchmVHwy5aAxdROSoPgPdzCaY2fNmtsnMNprZ7T20ucrM1plZlZmtMrOFQ1NuTFZmBoU5mbpbVESkm/4MuXQAd7n7GjMrAFab2bPuvqlbm+eAx93dzews4BFg6hDUe1RJQbYm6BIR6abPHrq773b3NcF2E7AZGHdcm0P+zkfM+cCQf9xcogm6RESOcVJj6GZWCcwFVvbw2tVm9jqwDPirE3z/4mBIZtWpfiJdHMnSfC4iIt30O9DNLAI8Ctzh7u+aQd7df+nuU4GPAv/W03u4+z3uPs/d55WWlg60ZiAIdPXQRUSO6legm1mYWJg/6O6P9dbW3ZcDk8ysZBDqO6GSSDYHm9tpj3YO5WFERJJGf65yMeAnwGZ3v/sEbSYH7TCzs4FsoG4wCz1e11J0BzXsIiIC9O8ql/OBG4D1ZlYV7PsiUAHg7kuAa4BPmVk70AJ83If4PtyS4Fr0/YeOMLrw5G6PFRFJRX0GuruvAKyPNt8AvjFYRfVHse4WFRE5RlLeKQpQEunqoSvQRUQgiQP9aA9dNxeJiABJHOiFOZmEQ6a7RUVEAkkb6GYWWyxaQy4iIkASBzpASUGWxtBFRAJJHejF+dm6/V9EJJDcgR7J0oeiIiKBpA700khsxsVUWktQRGSgkjrQiyNZtHV0cqitI96liIjEXXIHer6uRRcR6ZLcgR7cLarb/0VEkjzQS4K7RXVzkYhIygS6eugiIkkd6KOCKXQ1hi4ikuSBnpWZQWFOpm7/FxEhyQMdoKQgm/26W1REJAUCPT+b/U3qoYuIJH2gF0eyNJ+LiAj9WyR6gpk9b2abzGyjmd3eQ5vrzWydma03s5fMbPbQlPtusflc1EMXEenPItEdwF3uvsbMCoDVZvasu2/q1mYbcKG7HzSzjwD3AOcMQb3vUhLJ5mBzOx3RTjJDSf8Hh4jIgPWZgO6+293XBNtNwGZg3HFtXnL3g8HTV4Dxg13oiXQtRXdAwy4ikuZOqktrZpXAXGBlL81uBp4aeEknpyS/a7FoBbqIpLf+DLkAYGYR4FHgDndvPEGbi4gF+sITvL4YWAxQUVFx0sX25Ohi0ZrPRUTSXL966GYWJhbmD7r7YydocxbwY+Aqd6/rqY273+Pu89x9Xmlp6UBrPkZJRHeLiohA/65yMeAnwGZ3v/sEbSqAx4Ab3P3NwS2xd8Waz0VEBOjfkMv5wA3AejOrCvZ9EagAcPclwJeAYuAHsfynw93nDX6571aYk0k4ZBpDF5G012egu/sKwPpocwtwy2AVdTLMLLZYtHroIpLmUuLC7ZIC3S0qIpISgV6cn60xdBFJe6kR6JEsXeUiImkvJQK9NBLrobt7vEsREYmblAj04kgWbR2dHD4SjXcpIiJxkxqBnh9ci6550UUkjaVGoHfdLarb/0UkjaVEoJccvVtUH4yKSPpKqUDXlS4iks5SItBHHZ1CV0MuIpK+UiLQszIzKMzJ1O3/IpLWUiLQAUoKstmv2/9FJI2lTqBrgi4RSXMpE+jFkSxd5SIiaS2lAl09dBFJZykT6CWRbA42t9MR7Yx3KSIicZEygd61FN2BZg27iEh6SplAL+m6Fr1JgS4i6SllAr2rh675XEQkXfUZ6GY2wcyeN7NNZrbRzG7voc1UM3vZzNrM7B+GptTelXRN0KUrXUQkTfW5SDTQAdzl7mvMrABYbWbPuvumbm0OAH8PfHQoiuyP4qMTdKmHLiLpqc8eurvvdvc1wXYTsBkYd1ybfe7+J6B9SKrsh8KcTMIh07XoIpK2TmoM3cwqgbnAyoEczMwWm9kqM1tVW1s7kLfo7b0p1t2iIpLG+h3oZhYBHgXucPfGgRzM3e9x93nuPq+0tHQgb9GrkoIs6jSfi4ikqX4FupmFiYX5g+7+2NCWNHDqoYtIOuvPVS4G/ATY7O53D31JA6f5XEQknfXnKpfzgRuA9WZWFez7IlAB4O5LzGwMsAooBDrN7A5g+kCHZgaqNJLN/kNtuDux30MiIumjz0B39xVAr+no7nuA8YNV1EAVR7Jo6+jk8JEokez+/K4SEUkdKXOnKMTG0AGNo4tIWkqtQI9obVERSV8pFeglR+8W1QejIpJ+UjLQNZ+LiKSjlAr0UfldE3RpyEVE0k9KBXpWZgaFOZkaQxeRtJRSgQ5QUpDNft3+LyJpKPUCXbf/i0iaSrlAL45k6UNREUlLKRnoGkMXkXSUcoE+uTTCweZ2tuw7FO9SRESGVcoF+qWzxmIGj6/dFe9SRESGVcoF+ujCHN47qZgn1u7C3eNdjojIsEm5QAe4ak452/YfZkPNsM7eKyISVykZ6JfMGEs4ZPy6qibepYiIDJuUDPSivDDvO3M0T6zbRbRTwy4ikh5SMtABrpxdzt7GNl7ddiDepYiIDIuUDfQPTCsjLyukq11EJG30Z5HoCWb2vJltMrONZnZ7D23MzL5nZlvMbJ2ZnT005fZfblaID00v4zfrd3OkozPe5YiIDLn+9NA7gLvcfTpwLnCrmU0/rs1HgCnBYzHww0GtcoCumjOOhpZ2XnirNt6liIgMuT4D3d13u/uaYLsJ2AyMO67ZVcD9HvMKMMLMxg56tSdp4ZQSRuaF+XWVhl1EJPWd1Bi6mVUCc4GVx700Dni72/Nq3h36wy4cyuAjs8by7Ka9NB/piHc5IiJDqt+BbmYR4FHgDncf0B07ZrbYzFaZ2ara2uEZBrlqdjkt7VGe3bR3WI4nIhIv/Qp0MwsTC/MH3f2xHprUABO6PR8f7DuGu9/j7vPcfV5paelA6j1p8ytHMbYohyd0tYuIpLj+XOViwE+Aze5+9wmaPQ58Krja5Vygwd13D2KdA5aRYVwxu5w/vllLfbPmSReR1NWfHvr5wA3AxWZWFTwuNbPPmtlngza/AbYCW4AfAX87NOUOzJWzy2mPOk9t2BPvUkREhkxmXw3cfQVgfbRx4NbBKmqwzSgvZFJpPr+uquG6BRXxLkdEZEik7J2i3ZkZV84uZ+W2A+xpaI13OSIiQyItAh1iwy7u8OQ6fTgqIqkpbQJ9UmmEWeOKNLeLiKSstAl0iC18sa66gW37D8e7FBGRQZdWgX75WeWx9UY1FYCIpKC0CvQxRbH1Rn/26k5NBSAiKSetAh3gzg+ewZ7GVpb8cWu8SxERGVRpF+jzKkdx5exy/uePf6b6YHO8yxERGTRpF+gAn//IVMzg60+9Hu9SREQGTVoGevmIXP7mwsksW7eblVvr4l2OiMigSMtAB1i8aBLjRuTyr09sItrp8S5HROSUpW2g52aF+MKlU9m0u5FHVr3d9zeIiCS4tA10gMtmjWVB5Si+/cwbNLS0x7scEZFTktaBbmZ86YrpHGg+wn8991a8yxEROSVpHegAM8cV8Yn5E1j60nb+XHso3uWIiAxY2gc6wF0fOpPccIivPrkp3qWIiAyYAh0oiWTz9++fwvNv1PL86/viXY6IyIAo0AOfPq+SiSX5/NuyTRzp6Ix3OSIiJ02BHsjKzOBfLp/G1trD3LP8z/EuR0TkpPUZ6GZ2r5ntM7MNJ3h9pJn90szWmdmrZjZz8MscHhedOZorZpfzH8++ydMbdse7HBGRk9KfHvpS4JJeXv8iUOXuZwGfAr47CHXFhZnxrWvPYu6EEdz+f1W8tvNgvEsSEem3PgPd3ZcDB3ppMh34fdD2daDSzMoGp7zhlxMO8aNPzaOsMIdb7lvFzjrNyCgiyWEwxtDXAn8BYGYLgNOA8YPwvnFTHMlm6U3zibpz49JXqW8+Eu+SRET6NBiB/u/ACDOrAm4DXgOiPTU0s8VmtsrMVtXW1g7CoYfOpNII99wwj+oDLfz1A6tp6+jxRxIRSRinHOju3ujuN7n7HGJj6KVAj8sBufs97j7P3eeVlpae6qGH3IKJo/jWx85i5bYD/NMv1uGuWRlFJHFlnuobmNkIoNndjwC3AMvdvfGUK0sQV80Zx9sHmvn2b9+kYlQed37ozHiXJCLSoz4D3cx+BrwPKDGzauDLQBjA3ZcA04D7zMyBjcDNQ1ZtnNx60WR2Hmjme7/fwoRReXxs3oR4lyQi8i59Brq7X9fH6y8DZwxaRQnIzPja1bPYVd/KFx5bT3Eki4unJu2FPCKSonSnaD+FQxn84C/PZtrYQv76gdU8vWFPvEsSETmGAv0kFOaE+d9bzmHWuCJufWgNv66qiXdJIiJHKdBPUlFumPtvPod5p43kjoereORPWr5ORBKDAn0AItmZLL1pAQsnl/CPj67j/pe3x7skEREF+kDlZoX48afn8YFpZXzp1xv50fIeL70XERk2CvRTkJ0Z4od/eTaXzRrL136zme8995ZuPhKRuDnlG4vSXTiUwXc/MYfscAZ3P/smre1RPvfhMzGzeJcmImlGgT4IMkMZfPva2eSEQ/zgD39me91hvnntbCLZOr0iMnw05DJIMjKMr310Jl+8dCrPbNzLlf+9grf2NsW7LBFJIwr0QWRmLF50Og/ecg6NLR1c9f0Xda26iAwbBfoQOHdSMcv+fiEzygu5/f+q+MrjG7XwtIgMOQX6ECkrzOGhz5zLzQsnsvSl7XzinpfZ3dAS77JEJIUp0IdQOJTBv1w+ne9/8mze2NPE5d9bwYtb9se7LBFJUQr0YXDZWWP59d8tZGR+Ftf/eCWf+/la9h9qi3dZIpJiFOjDZPLoCI//3fl89sLT+VVVDRd/+w/c99J2OqIaWxeRwaFAH0Z5WZl8/iNTeer2RZw1fgRffnwjV/z3i6zafiDepYlIClCgx8Hk0REeuHkBP7j+bBqaj3Dtkpe585Eqaps0DCMiA6dAjxMz49JZY/ndXRfyt+87nSfW7uLib/+BH7+wlbaOaLzLE5EkpECPs7ysTP7xkqk8c8ci5p42kq8u28zF3/4jj66uJtqpib5EpP/6DHQzu9fM9pnZhhO8XmRmT5jZWjPbaGY3DX6ZqW9SaYT7/2oBD9y8gJH5Ye76+Vou+94L/P71vZrBUUT6pT899KXAJb28fiuwyd1nA+8D/sPMsk69tPR0wZRSHr91If913Vxa2qP81dJVfPyeV1iz82C8SxORBNdnoLv7cqC3yzAcKLDYfLGRoG3H4JSXnjIyjCtml/O7Oy/k366awdbaw/zFD15i8f2r2FDTEO/yRCRBWX/+nDezSuBJd5/Zw2sFwOPAVKAA+Li7LzvB+ywGFgNUVFS8Z8eOHQMuPJ0cbuvg3hXb+J/lWznU1sHsCSO4/pwKrjirnNysULzLE5FhZGar3X1ej68NQqBfC5wP3AmcDjwLzHb3xt7ec968eb5q1ao+jy3vaGhu57HXqnlw5U627DtEQU4m15w9nk+eU8EZZQXxLk9EhkFvgT4YKzDcBPy7x34zbDGzbcR6668OwntLN0V5YW46fyI3nlfJq9sO8NCrO3lo5U6WvrSdBZWj+OQ5FXx4xhj12kXS1GAE+k7g/cALZlYGnAloxeQhZGacM6mYcyYV86XL2/jF6moeenUndzxcRW44xPvOLOWSmWO4eOpoCnLC8S5XRIZJn0MuZvYzYlevlAB7gS8DYQB3X2Jm5cSuhBkLGLHe+v/2dWANuQyuzk7nlW11PLV+D89s3MO+pjayQhksnFLCJTPH8MFpZYzM18VHIsnulMfQh4ICfeh0djprdh7kqQ17eHrDHmrqWwhlGOedXszH50/gwzPGEA7pnjKRZKRAT2PuzoaaRp7asJvH1+6i+mALpQXZXDd/AtedU8HYotx4lygiJ0GBLgBEO53lb9bywCs7eP6NfWSY8YFpo7nh3ErOn1xM7FYCEUlkQ32ViySJUIZx0dTRXDR1NG8faObBlTt5ZNXbPLNxL5NK8vnkORVcMbucssKceJcqIgOgHnqaa22P8tSG3Tzw8g7W7KzHDM6dWMwVs8v5yMwx+iBVJMFoyEX6Zcu+QzyxdhdPrN3F1v2HycwwLphSwhWzy/ng9DJdAimSABToclLcnU27G3l87S6eXLubmvoWsjIzuPjM0Vx21lgunjqa/GyN1onEgwJdBszdWbOznifW7mLZ+t3UNrWRE87g4qmjuWxWORdNLSUvS+EuMlwU6DIoop3Oqu0HWLZ+N79Zv4f9h9rIDYe4eNpoLp81lvOnlFCoYRmRIaVAl0EX7XRe3XaAZet38dT6PdQdPgLAacV5zCgvZEZ5EdPLC5lRXsjoAl01IzJYFOgypDqinby6/QCv7axn464GNu5qZEdd89HXSwuymVleyPyJo7hgcikzygvJyNA17yIDoUCXYdfY2s6mXY1s3NXIxl0NrK9u4K19hwAYmRfmvMklLAweE0blxblakeShG4tk2BXmhDl3UjHnTio+um9fUysvbtnPirfqWLGllmXrdgNQWZzHeZNLmFFeyNQxBUwpK9BYvMgAqIcuceHubNl3iBVb9rPirf2s3HaAQ23vrFxYXpTDmWMKOGNMAWeWFTB1TCFnjikgpKEaSXPqoUvCMTOmlMV64zedPxF3p6a+hTf2NPHG3ibe3NPEG3sP8eKWOo5EOwHIzwoxp2IE76kYydmnjWRuxUiKctWTF+miQJeEYGaMH5nH+JF5vH9a2dH9HdFOttc1s6GmgTU7D7J6x0H++/ktdDqYwZTREd5z2kjOLCtgZH4WRblhRuRlMSI3zIi8MAU5YfXqJW1oyEWSzuG2Dta+Xc/qHQdZvfMga3YcpLG1o8e2ZlCQncn4kXmcURY5OoRzRlkB40bk6mobSToacpGUkp+dyXmTSzhvcgkQW9DjQPMRGlraqW9up6Hlne3Y4wg7DjTz6rYD/Kpq1zvvkxViSlkBZ5RFmFgS4bTivOCRT0RTG0gS0r9aSXoZGUZJJJuSSHafbRtb23lrbxNv7DnEm3ubeGNPE89t3kfd4epj2hXnZ1FRnMdpo/KYWBJh4ZRi5kwYqeEbSWj9WVP0XuByYJ+7z+zh9c8B1wdPM4FpQKm7H+jtfTXkIomksbWdnXXN7DzQzI66ZnYeOMyOutj2roYW3GMhf9HU0XxgWhkXTCnRBGUSF6d0Y5GZLQIOAff3FOjHtb0C+H/ufnFfRSnQJVk0tLTzxzdreW7zXp5/fR+NrR1kZWZw3unFvH9aGQsnl1ASySKSnalVn2TIndIYursvN7PKfh7rOuBn/S9NJPEV5Ya5cnY5V84upz3ayZ+2H+C5zfv43ea9/MuvNhxtl2FQmBumKHgU5sS+jh+Zy4KJo5hXOUqXWcqQ6tdVLkGgP9lbD93M8oBqYHJfwy2gHrokP3fnz7WHWLOjnvrgg9jGlg4aWtqPPhpb2qk+2MKRaCdmMKO8kHMmFnPOxFEsmDiKEXlaEUpOznBd5XIF8GJvYW5mi4HFABUVFYN4aJHhZ2ZMHl3A5NEFvbZrbY/y2s56Vm6r45WtdTzwyg5+smIbZjB1TCGTR0coys082qMvPK6HX5CTGTzCZGVmDNNPJ8loMAP9E/Qx3OLu9wD3QKyHPojHFklYOeEQ7z29mPeeHpvXpq0jytq3G3hlax2vbjvAhpqGo735js7e/1tkZ2ZQkBOmMDcW8IU5mZQX5TJuZC7jRuQyfmRse0xhDpkhhX+6GZRAN7Mi4ELgLwfj/URSWXZmiAXBkEt37k7zkSiNre3HDN80tbbT1NpBU2s7jcd87aCh+Qiv72mitqntmPcKZRhjCnMoH5HDyLwsRuZlMSI/HGzH7qYdmZdF+Ygcxo3I1Ye5KaLPQDeznwHvA0rMrBr4MhAGcPclQbOrgd+6++EhqlMk5ZkZ+dmZ5GdnMrYo96S+t7U9yq76FmrqW6g+2ELNwRaqDzazq6GV7XWHqXq7nvrm9qPz4nRXEslmzoQRzK0YwdwJIzhrwgjdWJWkdOu/SJro+gvgYPMR6pvbOdh8hO37D/Pa2/VUvV3P1tpYf8wMzhhdwNyKEVQU5xHJziQ/KzP4ZRMiPzuTSHYmeVkhzIxo1Ono7KSj0+mIOtHO2PMMM6aXFxLW0M+g0q3/InLMXwDjR8b2XTCllBveG9tuaG6nqrqeqp31vPb2QZ7euIf65vZTOmZJJIsrZ4/jmveMY0Z50Sn+BNIX9dBFpEfuTltHJ4faOjjc1sHhtiiHj3R0e96BYYQyjMxQ8DXDCGVkkBkyDrV2sGzdbp57fS/tUWfqmAKuOXs8V80t1zqzp0BL0IlI3Bw8fIQn1+3iF2tqWPt2PaEMY9GUEj44fQwAzUdivyyaj3Rw+EgHzcEvDsMoLcimrDCb0QU5lBZmU1aQw+jCbEblZaXtTJkKdBFJCFv2NfHomhp+uaaGPY2tx7yWE84gPyuTvOwQ+VmZRDud2kNtPQ77ZGYYY4pyqCzOp6I4j8riPCpG5VNZkkfFqDzyso4dTe6IdtLcHqXlSJTmI1Hao51UjMojJxwa0p93KCjQRSShRDud6oPN5IRD5GWFyMvKPOFMlq3tUWqb2tjX1Mq+xjb2NbWxt7GVmvoWttc1s7PuMAePC/3SgmxCZrQEId7T1T2hDGPK6AgzxxUxs7yQWeOLmDa28F2/DBKNPhQVkYQSyjBOK87vV9uccIgJo/KYMCrvhG0aWmKzZe4IZsncWdeM4+SGQ+RmZQa/NELkZoXIDYcIZRhv7T3Ehl0N/OGNffxidWz6ZDM4vTTClNERMszo6Owk2gnRzk6iHnztdPKyMpk+tpCZ4wqZUV7E+JGJcS2/Al1Ekl5RbphZ44uYNf7kr6Rxd/Y2trGhpoH1NQ1s3NXAG3ubMCAzI4NQhr3rUXOwhT++WUs0uLO3KDfMjPJCZo4rYkZ5IacV5wfTN2RSmBsetks3FegiktbMYuPxY4py+MD0sr6/IdDaHuX1PU1s3NXAhppGNu5qYOlL2znS8e7hnbysEIXBlA1FuWGunjueT54z+PNZKdBFRAYgJxxizoQRzJkw4ui+9mgnW/YdYld9C42t70zf0NjSfsxzZ2g+u1Sgi4gMknAog2ljC5k2tjAux9c9uSIiKUKBLiKSIhToIiIpQoEuIpIiFOgiIilCgS4ikiIU6CIiKUKBLiKSIuI226KZ1QI7BvjtJcD+QSxnMKm2gUnk2iCx61NtA5OstZ3m7qU9vRC3QD8VZrbqRNNHxptqG5hErg0Suz7VNjCpWJuGXEREUoQCXUQkRSRroN8T7wJ6odoGJpFrg8SuT7UNTMrVlpRj6CIi8m7J2kMXEZHjJF2gm9klZvaGmW0xs8/Hu57uzGy7ma03syozi+sK2GZ2r5ntM7MN3faNMrNnzeyt4OvIBKrtK2ZWE5y7KjO7NE61TTCz5zNU2gIAAAXDSURBVM1sk5ltNLPbg/1xP3e91Bb3c2dmOWb2qpmtDWr712D/RDNbGfx/fdjMshKotqVmtq3beZsz3LV1qzFkZq+Z2ZPB84GdN3dPmgcQAv4MTAKygLXA9HjX1a2+7UBJvOsIalkEnA1s6Lbvm8Dng+3PA99IoNq+AvxDApy3scDZwXYB8CYwPRHOXS+1xf3cAQZEgu0wsBI4F3gE+ESwfwnwNwlU21Lg2nj/mwvquhN4CHgyeD6g85ZsPfQFwBZ33+ruR4D/A66Kc00Jyd2XAweO230VcF+wfR/w0WEtKnCC2hKCu+929zXBdhOwGRhHApy7XmqLO485FDwNBw8HLgZ+EeyP13k7UW0JwczGA5cBPw6eGwM8b8kW6OOAt7s9ryZB/kEHHPitma02s8XxLqYHZe6+O9jeA/R/Rdzh8Xdmti4YkonLcFB3ZlYJzCXWo0uoc3dcbZAA5y4YNqgC9gHPEvtrut7dO4Imcfv/enxt7t513r4WnLfvmFl2PGoD/hP4R6BrdeliBnjeki3QE91Cdz8b+Ahwq5ktindBJ+Kxv+USppcC/BA4HZgD7Ab+I57FmFkEeBS4w90bu78W73PXQ20Jce7cPeruc4DxxP6anhqPOnpyfG1mNhP4ArEa5wOjgH8a7rrM7HJgn7uvHoz3S7ZArwEmdHs+PtiXENy9Jvi6D/glsX/UiWSvmY0FCL7ui3M9R7n73uA/XSfwI+J47swsTCwwH3T3x4LdCXHueqotkc5dUE898DzwXmCEmXUtRh/3/6/darskGMJyd28Dfkp8ztv5wJVmtp3YEPLFwHcZ4HlLtkD/EzAl+AQ4C/gE8HicawLAzPLNrKBrG/gQsKH37xp2jwOfDrY/Dfw6jrUcoyssA1cTp3MXjF/+BNjs7nd3eynu5+5EtSXCuTOzUjMbEWznAh8kNsb/PHBt0Cxe562n2l7v9gvaiI1RD/t5c/cvuPt4d68klme/d/frGeh5i/enuwP4NPhSYp/u/xn453jX062uScSuulkLbIx3bcDPiP353U5sDO5mYmNzzwFvAb8DRiVQbQ8A64F1xMJzbJxqW0hsOGUdUBU8Lk2Ec9dLbXE/d8BZwGtBDRuALwX7JwGvAluAnwPZCVTb74PztgH4X4IrYeL1AN7HO1e5DOi86U5REZEUkWxDLiIicgIKdBGRFKFAFxFJEQp0EZEUoUAXEUkRCnQRkRShQBcZBMHUySXxrkPSmwJdRCRFKNAlaZlZpZltNrMfBQsX/Da4tbuntqeb2dPBTJgvmNnUYP9SM1tiZqvM7M1gsqSuRRF+arEFS14zs4uC/SEz+7aZbQhm6but22FuM7M1wfd0vf+F3RZQeK1regiRoaBAl2Q3Bfi+u88A6oFrTtDuHuA2d38P8A/AD7q9VklsYqbLgCVmlgPcSmxixVnAdcB9wf7FQfs57n4W8GC399nvsdk2fxgcg+DrrR6b6e8CoOXUflyRE8vsu4lIQtvm7lXB9mpiYXuMYLrZ84Cfx+ZhAqD73NePeGymwrfMbCuxKVUXAv8F4O6vm9kO4AzgA8ASD+aqdvfuC3V0zcy4GviLYPtF4G4zexB4zN2rT+FnFemVAl2SXVu37SjQ05BLBrEFA060ZuTxExoNdIKjrlqiBP+33P3fzWwZsUm0XjSzD7v76wN8f5FeachFUp7HFoHYZmYfg9h0qWY2u1uTj5lZhpmdTmyWuzeAF4Drg/ZnABXB/meBv+6aq9rMRvV2bDM73d3Xu/s3iE3/nDCLPkjqUaBLurgeuNnMuqY37r4W7U5iU5U+BXzW3VuJjbFnmNl64GHgRo8thPDjoP264L0+2cdx7+j6AJXYdMFPDeYPJdKdps+VtGZmS4nNQf2LvtqKJDr10EVEUoR66JJSzOz7xNZp7O677v7TeNQjMpwU6CIiKUJDLiIiKUKBLiKSIhToIiIpQoEuIpIiFOgiIini/wOBKOsidR7K5wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loss after the epoch # 41 1.64920705587436\n",
            "Loss after the epoch # 42 1.651544366738735\n",
            "Loss after the epoch # 43 1.6476189576662503\n",
            "Loss after the epoch # 44 1.6469092069528042\n",
            "Loss after the epoch # 45 1.6454708918547019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVRqAJm44zET"
      },
      "source": [
        "# _ = save_net(model_rnn, \"O_RNN.net\", opt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gI3M9bCf7hH"
      },
      "source": [
        "def generate_text(char_rnn, tokens = tokens, seed_phrase = 'fucking society! ', \n",
        "                    max_length = 100, temperature = 1., flag = False):\n",
        "  \n",
        "    def sample(preds, tokens, temperature = 1.):\n",
        "        preds =  F.softmax(preds / temperature, dim = -1).cpu().data.numpy().squeeze()\n",
        "        # print(preds.shape)\n",
        "        next_ix = np.random.choice(len(tokens), p = preds)\n",
        "        return torch.LongTensor([[next_ix]])\n",
        "\n",
        "    x_sequence = torch.Tensor([np.array([token_to_idx[token] for token in seed_phrase.lower()])]).to(device)\n",
        "    hid_state = char_rnn.initial_state(batch_size = 1)\n",
        "\n",
        "    if flag: hid_state = tuple([each.data for each in hid_state])\n",
        "\n",
        "    #feed the seed phrase, if any\n",
        "    for i in range(len(seed_phrase) - 1):\n",
        "        out, hid_state = char_rnn(torch.stack([x_sequence[:, i].long()]), hid_state)\n",
        "    \n",
        "    #start generating\n",
        "    for _ in range(max_length - len(seed_phrase)):\n",
        "        out, hid_state = char_rnn(torch.stack([x_sequence[:, -1].long()]), hid_state)\n",
        "        next_ix = sample(out, tokens, temperature)\n",
        "\n",
        "        x_sequence = torch.cat([x_sequence, next_ix.to(device)], dim = 1)\n",
        "    return ''.join([tokens[int(ix)] for ix in x_sequence.cpu().data.numpy()[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guTQ7mGjf7hH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "561828ff-ba2a-47b9-8dc8-2fb9e49c9cf7"
      },
      "source": [
        "# An example of generated text.\n",
        "# checkpoint = torch.load(\"ShRNN.net\")\n",
        "# model_rnn.load_state_dict(checkpoint['state_dict'])\n",
        "# opt.load_state_dict(checkpoint['opt_state_dict'])\n",
        "_ = model_rnn.eval()\n",
        "print(generate_text(char_rnn = model_rnn,  max_length = 500, temperature = 1.))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fucking society! where with shave thy sake thy self dietty pully is suibl'ds for me\n",
            "  te for-prim,\n",
            "  dome!\n",
            "  i my houts to thel, in mants libjens, art mine to dead lhal hid heast thy distrong doth forweati fift owol ckastisgrw,\n",
            "  make proos'd,\n",
            "  tair beaver, if being byes that rele;\n",
            "    and mming winking they yulitenthe that my conbliok thou betul, or froms,\n",
            "  mine her cheatifanftion ccewilad is nefites eacy lye pard'ming, swill'd,\n",
            "  thas thine shom thy's wiends, and love is my sol'd,\n",
            "  that my \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk29R_Muf7hH"
      },
      "source": [
        "### More poetic model\n",
        "\n",
        "Let's use LSTM instead of vanilla RNN and compare the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN88HUf6f7hH"
      },
      "source": [
        "Plot the loss function of the number of epochs. Does the final loss become better?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD7DK6clf7hH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "52d1e83c-4e10-4a28-8593-fa6e648b41f7"
      },
      "source": [
        "# Your beautiful code here\n",
        "class LSTM (nn.Module):\n",
        "    def __init__(self, n_tokens = len(tokens), hidden_dim = 256, emb_dim = 128,\n",
        "                 n_layers = 1):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.n_tokens = emb_dim\n",
        "        \n",
        "        self.embed = nn.Embedding(n_tokens, self.emb_dim)\n",
        "        self.lstm = nn.LSTM(self.emb_dim, self.hidden_dim, batch_first =  True)\n",
        "        self.hid_to_logits = nn.Linear(self.hidden_dim, n_tokens)\n",
        "    \n",
        "    def forward(self, x, hidden_state):\n",
        "        out, hidden_state = self.lstm(self.embed(x), hidden_state)\n",
        "        out = self.hid_to_logits(out)\n",
        "      \n",
        "        return out, hidden_state\n",
        "    \n",
        "    def initial_state(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
        "        weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
        "        return hidden\n",
        "\n",
        "model_lstm = LSTM()\n",
        "opt = torch.optim.Adam(model_lstm.parameters())\n",
        "model_lstm.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "n_epochs = 40\n",
        "history = []\n",
        "_ = model_lstm.train()\n",
        "for epoch in range(n_epochs):\n",
        "    ep_history = []\n",
        "    hidden_state = model_lstm.initial_state(batch_size)\n",
        "    for batch_ind in range(batch_size, x.shape[0], batch_size):\n",
        "        \n",
        "        x_batch = torch.argmax(torch.Tensor(x[batch_ind - batch_size : batch_ind]), dim = -1).to(device)\n",
        "        y_batch = torch.argmax(torch.Tensor(y[batch_ind - batch_size : batch_ind]), dim = -1).to(device)\n",
        "\n",
        "        hidden_state = tuple([each.data for each in hidden_state])\n",
        "\n",
        "        opt.zero_grad()\n",
        "    \n",
        "        seq, hidden_state = model_lstm(x_batch, hidden_state)\n",
        "        loss = criterion(seq[:, -1].contiguous(), y_batch.contiguous())  \n",
        "        loss.backward()\n",
        "        opt.step()  \n",
        "        ep_history.append(loss.item())\n",
        "    history.append(np.mean(ep_history))\n",
        "    print(\"Loss after the epoch # {}\".format(epoch + 1), history[-1])\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label = 'loss')\n",
        "        plt.xlabel(\"n_epochs\")\n",
        "        plt.legend()\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc6RQ2KMf7hH"
      },
      "source": [
        "Generate text using the trained net with different `temperature` parameter: `[0.1, 0.2, 0.5, 1.0, 2.0]`.\n",
        "\n",
        "Evaluate the results visually, try to interpret them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63nS_gTyIQSP"
      },
      "source": [
        "# _= save_net(model_lstm, \"O_LSTM.net\", opt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NtVAXbOf7hH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3469d4df-ddc6-4385-8af8-20f1d5b0b206"
      },
      "source": [
        "# Text generation with different temperature values here \n",
        "# checkpoint = torch.load(\"ShLSTM.net\")\n",
        "# model_lstm.load_state_dict(checkpoint['state_dict'])\n",
        "# opt.load_state_dict(checkpoint['opt_state_dict'])\n",
        "\n",
        "_ = model_lstm.eval()\n",
        "\n",
        "def entropy(labels, base = None):\n",
        "  values, counts = np.unique(labels, return_counts = True)\n",
        "  norm_counts = counts / counts.sum()\n",
        "  base = np.exp(1.) if base is None else base\n",
        "  return -(norm_counts * np.log(norm_counts)/np.log(base)).sum()\n",
        "\n",
        "for temperature in [0.1, 0.2, 0.5, 1.0, 2.0]:\n",
        "  print(\"TEMPERATURE = \", temperature)\n",
        "  poetry = generate_text(char_rnn = model_lstm, temperature = temperature,\n",
        "                      max_length = 400, seed_phrase = \"Listen, Bitch! \")\n",
        "  # print(\"Shannon entropy of given phrase = \", round(entropy(poetry), 3), '\\n')\n",
        "\n",
        "  print('\\t', poetry, '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TEMPERATURE =  0.1\n",
            "\t listen, bitch! kind,\n",
            "  on the sun is death, which thou art be so, tongue:\n",
            "  nor dead that feast, who let me not from me.\n",
            "\n",
            "  cxxxviii\n",
            "\n",
            "  what no man respore more base that from hend:\n",
            "  then thou thy self thou shouldst still,\n",
            "  one mine own love, thou mayst to me another delight.\n",
            "  i will in my self, all thy self desert,\n",
            "  and in the present me with thee to be replent,\n",
            "  which put for my sinful eart \n",
            "\n",
            "TEMPERATURE =  0.2\n",
            "\t listen, bitch! kind,\n",
            "  on the sun is double not thy side.\n",
            "    if thou thy self to his store;\n",
            "  doth spures is my love swears than love thee face,\n",
            "  for not do not so me that leaves me,\n",
            "  the world will be the counter take:\n",
            "  make me gones, and they do before,\n",
            "  the outward of thy self away,\n",
            "  deserve thou wilt not be feel in my sight,\n",
            "  deserve to proud hath possess she things to see;\n",
            "  for it dos \n",
            "\n",
            "TEMPERATURE =  0.5\n",
            "\t listen, bitch! kind;\n",
            "  and sittent touble and my poor praise.\n",
            "\n",
            "  cxliv\n",
            "\n",
            "  if it believe me thou lov'st else of thee,\n",
            "  which should makes my sinful earth to me of thy self,\n",
            "  and see the outs of my self i doun.\n",
            "  for i have sworn deeds must leaves make deceive,\n",
            "  the world's out of this mays in thee mine,\n",
            "  that had my soul thee is not says she thy defence:\n",
            "  for i have sworn defears men as good r \n",
            "\n",
            "TEMPERATURE =  1.0\n",
            "\t listen, bitch! kips thy heart,\n",
            "  though she abless and in my vux'st those kind,\n",
            "  a dauth of thine,'  whou drods one please,\n",
            "  some your easure of their youth against the figured.\n",
            "  thy light in thy will, is drire,' eyen\n",
            "  have better face never we it doth tell;\n",
            "  they find they live, and thy hand,\n",
            "  not-ind and so'bloke eyes, ever smort:\n",
            "  for sometime time was should my o'ermits?\n",
            "  who taught my \n",
            "\n",
            "TEMPERATURE =  2.0\n",
            "\t listen, bitch! we proud,\n",
            "  upon mokes title eqfeited of trupl.\n",
            "\n",
            "  xcxxix\n",
            "\n",
            "  qhief his uson physic! te falseit oneath;\n",
            "  agal's, tongue-tied to izew, what waiek eye.\n",
            "\n",
            "  xxvi\n",
            "\n",
            "  were danksly huch, and yate you.\n",
            "  look-no\n",
            "  kond-edy never quiled\n",
            "  suadows gabitly jucquapy: 'tis,\n",
            "  and in teally,--drinklives by kinf\n",
            " ; mine, not loin, bequig, me some in?lanives;\n",
            "  in donest both two abount of line's h \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7U8u_Fff7hH"
      },
      "source": [
        "### Saving and loading models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkzqZkVFf7hI"
      },
      "source": [
        "Save the model to the disk, then load it and generate text. Examples are available [here](https://pytorch.org/tutorials/beginner/saving_loading_models.html])."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCyfZCRDf7hI"
      },
      "source": [
        "# Saving and loading code here\n",
        "def save_net(net, name: str, opt):\n",
        "    checkpoint = {'state_dict': net.state_dict(),\n",
        "                  'opt_state_dict': opt.state_dict()}\n",
        "\n",
        "    with open(name, 'wb') as f:\n",
        "        torch.save(checkpoint, f)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHUPkn9Kf7hI"
      },
      "source": [
        "### References\n",
        "1. <a href='http://karpathy.github.io/2015/05/21/rnn-effectiveness/'> Andrew Karpathy blog post about RNN. </a> \n",
        "There are several examples of genration: Shakespeare texts, Latex formulas, Linux Sourse Code and children names.\n",
        "2. <a href='https://github.com/karpathy/char-rnn'> Repo with char-rnn code </a>\n",
        "3. Cool repo with PyTorch examples: [link](https://github.com/spro/practical-pytorch`)"
      ]
    }
  ]
}
